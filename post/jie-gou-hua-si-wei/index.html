<!DOCTYPE html>
<html>

<head>
  <meta charset="UTF-8" />

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
<meta name="keywords" content="zhangyao blog">
<meta name="description" content="生死看淡，不服就干">
<meta name="theme-color" content="#000">
<title>浅谈结构化思维 | will</title>
<link rel="shortcut icon" href="/favicon.ico?v=1648715461080">
<link rel="stylesheet" href="/media/css/pisces.css">
<link rel="stylesheet" href="/media/fonts/font-awesome.css">
<link
  href="//fonts.googleapis.com/css?family=Monda:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Rosario:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext"
  rel="stylesheet" type="text/css">

<link href="/media/hljs/styles/androidstudio.css"
  rel="stylesheet">

<link rel="stylesheet" href="/styles/main.css">

<script src="/media/hljs/highlight.js"></script>
<script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.0/velocity.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.0/velocity.ui.min.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css"
  integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">


<script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js"
  integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js"
  integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
  onload="renderMathInElement(document.body);"></script>





  <meta name="description" content="浅谈结构化思维" />
  <meta name="keywords" content="方法论" />
</head>

<body>
  <div class="head-top-line"></div>
  <div class="header-box">
    
<div class="pisces">
  <header class="header  ">
    <div class="blog-header box-shadow-wrapper bg-color " id="header">
      <div class="nav-toggle" id="nav_toggle">
        <div class="toggle-box">
          <div class="line line-top"></div>
          <div class="line line-center"></div>
          <div class="line line-bottom"></div>
        </div>
      </div>
      <div class="site-meta">       
        <div class="site-title">
          
            <a href="/" class="brand">
              <span>will</span>
            </a>  
          
        </div>
        
          <p class="subtitle">生死看淡，不服就干</p>
        
      </div>
      <nav class="site-nav" id="site_nav">
        <ul id="nav_ul">
          
            
            
              
            
            <li class="nav-item ">
              
              
                <a href="/" target="_self">
                  <i class="fa fa-home"></i> 首页
                </a>
              
            </li>
          
            
            
              
            
            <li class="nav-item ">
              
              
                <a href="/archives/" target="_self">
                  <i class="fa fa-archive"></i> 归档
                </a>
              
            </li>
          
            
            
              
            
            <li class="nav-item ">
              
              
                <a href="/tags/" target="_self">
                  <i class="fa fa-tags"></i> 标签
                </a>
              
            </li>
          
            
            
              
            
            <li class="nav-item ">
              
              
                <a href="/post/about/" target="_self">
                  <i class="fa fa-user"></i> 关于
                </a>
              
            </li>
          
          
            
              <li class="nav-item ">
                <a href="/friends/" target="_self">
                  
                    <i class="fa fa-address-book"></i> 友情链接
                  
                </a>
              </li>
            
          
          
            <li id="fa_search" class="nav-item">
              <a href="javascript:void(0);">
                <i class="fa fa-search"></i> <span class="language" data-lan="search">搜索</span>
              </a>
            </li>
          
        </ul>
      </nav>
    </div>
  </header>
</div>

<script type="text/javascript"> 
 
  let showNav = true;

  let navToggle = document.querySelector('#nav_toggle'),
  siteNav = document.querySelector('#site_nav');
  
  function navClick() {
    let sideBar = document.querySelector('.sidebar');
    let navUl = document.querySelector('#nav_ul');
    navToggle.classList.toggle('nav-toggle-active');
    siteNav.classList.toggle('nav-menu-active');
    if (siteNav.classList.contains('nav-menu-active')) {
      siteNav.style = "height: " + (navUl.children.length * 42) +"px !important";
    } else {
      siteNav.style = "";
    }
  }

  navToggle.addEventListener('click',navClick);  
</script>
  </div>
  <div class="main-continer">
    
    <div
      class="section-layout pisces ">
      <div class="section-layout-wrapper">
        

<div class="sidebar">
  
    <div class="sidebar-box box-shadow-wrapper bg-color right-motion" id="sidebar">
      
        <div class="post-list-sidebar">
          <div class="sidebar-title">
            <span id="tocSideBar" class="sidebar-title-item sidebar-title-active language" data-lan="index">文章目录</span>
            <span id="metaSideBar" class="sidebar-title-item language" data-lan="preview">站点概览</span>
          </div>
        </div>
      
      <div class="sidebar-body pisces" id="sidebar_body">
        
          
            <div class="post-side-meta" id="post_side_meta">
              
<div class="sidebar-wrapper box-shadow-wrapper bg-color">
  <div class="sidebar-item">
    <img class="site-author-image right-motion" src="/images/avatar.png"/>
    <p class="site-author-name">will</p>
    
  </div>
  <div class="sidebar-item side-item-stat right-motion">
    <div class="sidebar-item-box">
      <a href="/archives/">
        
        <span class="site-item-stat-count">16</span>
        <span class="site-item-stat-name language" data-lan="article">文章</span>
      </a>
    </div>
    <div class="sidebar-item-box">
      <a href="">
        <span class="site-item-stat-count">16</span>
        <span class="site-item-stat-name language" data-lan="category">分类</span>
      </a>
    </div>
    <div class="sidebar-item-box">
      <a href="/tags/">
        <span class="site-item-stat-count">16</span>
        <span class="site-item-stat-name language" data-lan="tag">标签</span>
      </a>
    </div>
  </div>
  
    
      <div class="sidebar-item">
        <span class="site-item-rss">
            <i class="fa fa-rss"></i>
            <a href="https://zhangyaoo.github.io/atom.xml" target="_blank">RSS</a>
        </span>
      </div>
    
  
  



</div>
            </div>
            <div class="post-toc sidebar-body-active" id="post_toc" style="opacity: 1;">
              <div class="toc-box right-motion">
  <div class="toc-wrapper auto-number auto"
    id="toc_wrapper">
    <ul class="markdownIt-TOC">
<li>
<ul>
<li>
<ul>
<li><a href="#what">what：</a></li>
<li><a href="#why">why:</a></li>
<li><a href="#how">how：</a>
<ul>
<li><a href="#%E5%85%B7%E4%BD%93%E7%9A%84%E6%AD%A5%E9%AA%A4">具体的步骤：</a></li>
</ul>
</li>
<li><a href="#example">example</a>
<ul>
<li><a href="#1-%E9%87%87%E8%B4%AD%E6%B8%85%E5%8D%95">1、采购清单</a></li>
<li><a href="#2-%E5%B8%A6%E5%9B%A2%E9%98%9F">2、带团队</a></li>
<li><a href="#3-%E4%BA%8B%E6%83%85%E5%88%92%E5%88%86%E6%96%B9%E6%B3%95">3、事情划分方法</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

  </div>
</div>

<script>

  let lastTop = 0, lList = [], hList = [], postBody, lastIndex = -1;
  let active = 'active-show', activeClass = 'active-current';
  let tocWrapper = document.querySelector('#toc_wrapper');
  let tocContent = tocWrapper.children[0];
  let autoNumber = tocWrapper && tocWrapper.classList.contains('auto-number');

  function addTocNumber(elem, deep) {
    if (!elem) {
      return;
    }
    let prop = elem.__proto__;

    if (prop === HTMLUListElement.prototype) {
      for (let i = 0; i < elem.children.length; i++) {
        addTocNumber(elem.children[i], deep + (i + 1) + '.');
      }
    } else if (prop === HTMLLIElement.prototype) {
      // 保存li元素
      if (elem.children[0] && elem.children[0].__proto__ === HTMLAnchorElement.prototype) {
        lList.push(elem);
      }
      for (let i = 0; i < elem.children.length; i++) {
        let cur = elem.children[i];
        if (cur.__proto__ === HTMLAnchorElement.prototype) {
          if (autoNumber) {
            cur.text = deep + ' ' + cur.text;
          }
        } else if (cur.__proto__ === HTMLUListElement.prototype) {
          addTocNumber(cur, deep);
        }
      }
    }
  }

  function removeParentActiveClass() {
    let parents = tocContent.querySelectorAll('.' + active)
    parents.forEach(function (elem) {
      elem.classList.remove(active);
    });
  }

  function addActiveClass(index) {
    if (index >= 0 && index < hList.length) {
      lList[index].classList.add(activeClass);
    }
  }

  function removeActiveClass(index) {
    if (index >= 0 && index < hList.length) {
      lList[index].classList.remove(activeClass);
    }
  }

  function addActiveLiElemment(elem, parent) {
    if (!elem || elem === parent) {
      return;
    } else {
      if (elem.__proto__ === HTMLLIElement.prototype) {
        elem.classList.add(active);
      }
      addActiveLiElemment(elem.parentElement, parent);
    }
  }

  function showToc() {
    if (tocWrapper) {
      postBody = document.querySelector('#post_body');
      for (let i = 0; i < postBody.children.length; i++) {
        if (postBody.children[i].__proto__ === HTMLHeadingElement.prototype) {
          hList.push(postBody.children[i]);
        }
      }
      if (tocWrapper.classList.contains('compress')) {
        tocContent.classList.add('closed');
      } else if (tocWrapper.classList.contains('no_compress')) {
        tocContent.classList.add('expanded');
      } else {
        if (hList.length > 10) {
          active = 'active-hidden'
          tocContent.classList.add('closed');
        } else {
          tocContent.classList.add('expanded');
        }
      }
    }
  }

  (function () {
    // 处理不是从#一级标题开始目录
    if (tocContent.children.length === 1 && tocContent.children[0].__proto__ === HTMLLIElement.prototype) {
      let con = tocContent.children[0].children[0];
      tocContent.innerHTML = con.innerHTML;
    }
    let markdownItTOC = document.querySelector('.markdownIt-TOC');
    let innerHeight = window.innerHeight;
    markdownItTOC.style = `max-height: ${innerHeight - 80 > 0 ? innerHeight - 80 : innerHeight}px`
    addTocNumber(tocContent, '');
  })();

  document.addEventListener('scroll', function (e) {
    if (lList.length <= 0) {
      return;
    }
    let scrollTop = document.scrollingElement.scrollTop + 10;
    let dir;

    if (lastTop - scrollTop > 0) {
      dir = 'up';
    } else {
      dir = 'down';
    }

    lastTop = scrollTop;
    if (scrollTop <= 0) {
      if (lastIndex >= 0 && lastIndex < hList.length) {
        lList[lastIndex].classList.remove(activeClass);
      }
      return;
    }

    let current = 0, hasFind = false;
    for (let i = 0; i < hList.length; i++) {
      if (hList[i].offsetTop > scrollTop) {
        current = i;
        hasFind = true;
        break;
      }
    }
    if (!hasFind && scrollTop > lList[lList.length - 1].offsetTop) {
      current = hList.length - 1;
    } else {
      current--;
    }
    if (dir === 'down') {
      if (current > lastIndex) {
        addActiveClass(current);
        removeActiveClass(lastIndex)
        lastIndex = current;
        removeParentActiveClass();
        lList[current] && addActiveLiElemment(lList[current].parentElement, tocContent);
      }
    } else {
      if (current < lastIndex) {
        addActiveClass(current);
        removeActiveClass(lastIndex);
        lastIndex = current;
        removeParentActiveClass();
        lList[current] && addActiveLiElemment(lList[current].parentElement, tocContent);
      }
    }
  });


  window.addEventListener('load', function () {
    showToc();
    document.querySelector('#sidebar').style = 'display: block;';
    tocWrapper.classList.add('toc-active');
    setTimeout(function () {
      if ("createEvent" in document) {
        let evt = document.createEvent("HTMLEvents");
        evt.initEvent("scroll", false, true);
        document.dispatchEvent(evt);
      }
      else {
        document.fireEvent("scroll");
      }
    }, 500)
  })

</script>
            </div>
          
        
      </div>
    </div>
  
</div>
<script>
  const SIDEBAR_TITLE_ACTIVE = 'sidebar-title-active';
  const SIDEBAR_BODY_ACTIVE = 'sidebar-body-active';
  const SLIDE_UP_IN = 'slide-up-in';

  let sidebar = document.querySelector('#sidebar'),
  tocSideBar = document.querySelector('#tocSideBar'),
  metaSideBar = document.querySelector('#metaSideBar'),
  postToc = document.querySelector('#post_toc'),
  postSiteMeta = document.querySelector('#post_side_meta'),
  sidebarTitle = document.querySelector('.sidebar-title'),
  sidebarBody = document.querySelector('#sidebar_body');

  tocSideBar && tocSideBar.addEventListener('click', (e) => {
    toggleSidebar(e);
  });

  metaSideBar && metaSideBar.addEventListener('click', (e) => {
    toggleSidebar(e);
  });

  function toggleSidebar(e) {
    let currentTitle = document.querySelector("."+SIDEBAR_TITLE_ACTIVE);
    if (currentTitle == e.srcElement) {
      return ;
    }
    let current, showElement, hideElement;
    if (e.srcElement == metaSideBar) {
      showElement = postSiteMeta;
      hideElement = postToc;
    } else if (e.srcElement == tocSideBar){
      showElement = postToc;
      hideElement = postSiteMeta;
    }
    currentTitle.classList.remove(SIDEBAR_TITLE_ACTIVE);
    e.srcElement.classList.add(SIDEBAR_TITLE_ACTIVE);

    window.Velocity(hideElement, 'stop');
    window.Velocity(hideElement, 'transition.slideUpOut', {
      display: 'none',
      duration: 200,
      complete: function () {
        window.Velocity(showElement, 'transition.slideDownIn', {
          duration: 200
        });
      }
    })
    hideElement.classList.remove(SIDEBAR_BODY_ACTIVE);
    showElement.classList.add(SIDEBAR_BODY_ACTIVE);
  }

  postToc && postToc.addEventListener('transitionend', function() {
    this.classList.remove(SLIDE_UP_IN);
  });

  if (sidebarBody) {
    if (sidebarBody.classList.contains('pisces') || sidebarBody.classList.contains('gemini')) {
      let hasFix = false;
      let scrollEl = document.querySelector('.main-continer');
      let limitTop = document.querySelector('#nav_ul').children.length * 42 + 162;
      window.addEventListener('scroll', function(e) {
        if (document.scrollingElement.scrollTop >= limitTop) {
          if (!hasFix) {
            sidebar.classList.add('sidebar-fixed');
            hasFix = true;
          }
        } else {
          if (hasFix) {
            sidebar.classList.remove('sidebar-fixed');
            hasFix = false;
          }
        }
      });
    }
  }
  
</script>
        <div class="section-box box-shadow-wrapper">
          <div class="section bg-color post post-page">
            <header class="post-header">
  <h1 class="post-title">
    <a class="post-title-link" href="https://zhangyaoo.github.io/post/jie-gou-hua-si-wei/">
      浅谈结构化思维
    </a>
  </h1>
  <div class="post-meta">
    
    <span class="meta-item pc-show">
      <i class="fa fa-calendar-o"></i>
      <span class="language" data-lan="publish">发布于</span>
      <span>2021-07-23</span>
      <span class="post-meta-divider pc-show">|</span>
    </span>
    
    <span class="meta-item">
      <i class="fa fa-folder-o"></i>
      <span class="pc-show language" data-lan="category-in">分类于</span>
      
      
      <a href="https://zhangyaoo.github.io/tag/8hWOBgAHN/">
        <span>方法论</span>
      </a>
      
      
    </span>
    <span class="post-meta-divider">|</span>
    
    <span class="meta-item">
      <i class="fa fa-clock-o"></i>
      <span>2<span class="language" data-lan="minute">分钟</span></span>
    </span>
    <span class="meta-item">
      <span class="post-meta-divider">|</span>
      <i class="fa fa-file-word-o"></i>
      <span>343<span class="pc-show language" data-lan="words">字数</span></span>
    </span>
    
  </div>
</header>
            <div class="post-body next-md-body" id="post_body">
              <h3 id="what">what：</h3>
<p>是一种以无序到有序的整理信息和构建结构化的思维方式，目的是减少认知复杂度，是的更加被容易理解和记忆，表达清晰</p>
<h3 id="why">why:</h3>
<p>0213645879 和 0123456789，这两串数字哪个更容易被人记住。<br>
当然是按照顺序排列的数字串比杂乱无序排列的要更容易被记住。<br>
因为人类更容易记住结构化的信息。</p>
<h3 id="how">how：</h3>
<p><img src="https://zhangyaoo.github.io/post-images/1627012568883.png" alt="" loading="lazy"><br>
塔尖就是我们的中心思想或主题。塔身就是构成中心思考或者主题的各个分论点。而塔基则是支撑各个分论点的要素或论据</p>
<p>1、综上而下的结构化思维<br>
纵向是自上而下的层次的关系，下一层是上一层的解释和构成，上一层是下一层的总结和概括<br>
比如，先给结论后给原因，先目的后方法，先抽象后具体，先整体后部分<br>
2、从左往右的顺序思维，在同一个组内必须是同一个逻辑范畴，按照顺序来组织</p>
<h4 id="具体的步骤">具体的步骤：</h4>
<p>1、确定问题产生背景<br>
2、确定核心目标<br>
3、拆解核心目标<br>
4、继续分解，直到能够把问题解释清楚，形成方法论</p>
<h3 id="example">example</h3>
<h4 id="1-采购清单">1、采购清单</h4>
<figure data-type="image" tabindex="1"><img src="https://zhangyaoo.github.io/post-images/1627012578248.png" alt="" loading="lazy"></figure>
<h4 id="2-带团队">2、带团队</h4>
<figure data-type="image" tabindex="2"><img src="https://zhangyaoo.github.io/post-images/1627012581164.png" alt="" loading="lazy"></figure>
<h4 id="3-事情划分方法">3、事情划分方法</h4>
<figure data-type="image" tabindex="3"><img src="https://zhangyaoo.github.io/post-images/1627012584884.png" alt="" loading="lazy"></figure>

            </div>
            
            
              <div class="post-footer">
  <ul class="post-copyright">
    <li class="post-copyright-author">
      <strong class="language" data-lan="author">本文作者：</strong>
      will
    </li>
    <li class="post-copyright-link">
      <strong class="language" data-lan="link">本文链接：</strong>
      <a href="https://zhangyaoo.github.io/post/jie-gou-hua-si-wei/" title="浅谈结构化思维">https://zhangyaoo.github.io/post/jie-gou-hua-si-wei/</a>
    </li>
    <li class="post-copyright-license">
      <strong class="language" data-lan="copyright">版权声明： </strong>
      本博客所有文章除特别声明外，均采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i> BY-NC-SA</a> 许可协议。转载请注明出处！
    </li>
  </ul>
  <div class="tags">
    
      <a href="https://zhangyaoo.github.io/tag/8hWOBgAHN/"># 方法论</a>
    
  </div>
  <div class="nav">
    <div class="nav-prev">
      
        <i class="fa fa-chevron-left"></i>
        <a class="nav-pc-next" title="基于Netty即时通讯系统设计与实现" href="https://zhangyaoo.github.io/post/ji-yu-netty-ji-shi-tong-xun-xi-tong-she-ji-yu-shi-xian/">基于Netty即时通讯系统设计与实现</a class="nav-pc-next">
        <a class="nav-mobile-prev" title="基于Netty即时通讯系统设计与实现" href="https://zhangyaoo.github.io/post/ji-yu-netty-ji-shi-tong-xun-xi-tong-she-ji-yu-shi-xian/">上一篇</a>
      
    </div>
    <div class="nav-next">
      
        <a class="nav-pc-next" title="HikariDataSource核心源码分析" href="https://zhangyaoo.github.io/post/hikaridatasource-he-xin-yuan-ma-fen-xi/">HikariDataSource核心源码分析</a>
        <a class="nav-mobile-next" title="HikariDataSource核心源码分析" href="https://zhangyaoo.github.io/post/hikaridatasource-he-xin-yuan-ma-fen-xi/">下一篇</a>
        <i class="fa fa-chevron-right"></i>
      
    </div>
  </div>
</div>
            
            
  

          </div>
        </div>
      </div>
    </div>
    <div class="footer-box">
  <footer class="footer">
    <div class="copyright">
      Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a> | © 2019-2020 Theme By <a
        href="https://github.com/hsxyhao/gridea-theme-next" target="_blank">HsxyHao</a>
    </div>
    <div class="poweredby">
      <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
            <span id="busuanzi_container_site_pv">本站总访问量<span id="busuanzi_value_site_pv"></span>次</span>
    </div>
  </footer>
  
  
  <div class="pisces back-to-top" id="back_to_top">
    <i class="fa fa-arrow-up"></i>
    
    <span class="scrollpercent">
      <span id="back_to_top_text">0</span>%
    </span>
    
  </div>
  
  
  
</div>
<script>

  let sideBarOpen = 'sidebar-open';
  let body = document.body;
  let back2Top = document.querySelector('#back_to_top'),
    back2TopText = document.querySelector('#back_to_top_text'),
    drawerBox = document.querySelector('#drawer_box'),
    rightSideBar = document.querySelector('.sidebar'),
    viewport = document.querySelector('body');

  function scrollAnimation(currentY, targetY) {

    let needScrollTop = targetY - currentY
    let _currentY = currentY
    setTimeout(() => {
      const dist = Math.ceil(needScrollTop / 10)
      _currentY += dist
      window.scrollTo(_currentY, currentY)
      if (needScrollTop > 10 || needScrollTop < -10) {
        scrollAnimation(_currentY, targetY)
      } else {
        window.scrollTo(_currentY, targetY)
      }
    }, 1)
  }

  back2Top.addEventListener("click", function (e) {
    scrollAnimation(document.scrollingElement.scrollTop, 0);
    e.stopPropagation();
    return false;
  });

  window.addEventListener('scroll', function (e) {
    let percent = document.scrollingElement.scrollTop / (document.scrollingElement.scrollHeight - document.scrollingElement.clientHeight) * 100;
    if (percent > 1 && !back2Top.classList.contains('back-top-active')) {
      back2Top.classList.add('back-top-active');
    }
    if (percent == 0) {
      back2Top.classList.remove('back-top-active');
    }
    if (back2TopText) {
      back2TopText.textContent = Math.floor(percent);
    }
  });


  let hasCacu = false;
  window.onresize = function () {
    calcuHeight();
  }

  function calcuHeight() {
    // 动态调整站点概览高度
    if (!hasCacu && back2Top.classList.contains('pisces') || back2Top.classList.contains('gemini')) {
      let sideBar = document.querySelector('.sidebar');
      let navUl = document.querySelector('#site_nav');
      sideBar.style = 'margin-top:' + (navUl.offsetHeight + navUl.offsetTop + 15) + 'px;';
      hasCacu = true;
    }
  }
  calcuHeight();

  let open = false, MOTION_TIME = 300, RIGHT_MOVE_DIS = '320px';

  if (drawerBox) {
    let rightMotions = document.querySelectorAll('.right-motion');
    let right = drawerBox.classList.contains('right');

    let transitionDir = right ? "transition.slideRightIn" : "transition.slideLeftIn";

    let openProp, closeProp;
    if (right) {
      openProp = {
        paddingRight: RIGHT_MOVE_DIS
      };
      closeProp = {
        paddingRight: '0px'
      };
    } else {
      openProp = {
        paddingLeft: RIGHT_MOVE_DIS
      };
      closeProp = {
        paddingLeft: '0px'
      };
    }

    drawerBox.onclick = function () {
      open = !open;
      window.Velocity(rightSideBar, 'stop');
      window.Velocity(viewport, 'stop');
      window.Velocity(rightMotions, 'stop');
      if (open) {
        window.Velocity(rightSideBar, {
          width: RIGHT_MOVE_DIS
        }, {
          duration: MOTION_TIME,
          begin: function () {
            window.Velocity(rightMotions, transitionDir, {});
          }
        })
        window.Velocity(viewport, openProp, {
          duration: MOTION_TIME
        });
      } else {
        window.Velocity(rightSideBar, {
          width: '0px'
        }, {
          duration: MOTION_TIME,
          begin: function () {
            window.Velocity(rightMotions, {
              opacity: 0
            });
          }
        })
        window.Velocity(viewport, closeProp, {
          duration: MOTION_TIME
        });
      }
      for (let i = 0; i < drawerBox.children.length; i++) {
        drawerBox.children[i].classList.toggle('muse-line');
      }
      drawerBox.classList.toggle(sideBarOpen);
    }
  }

  // 链接跳转
  let newWindow = 'true'
  if (newWindow === 'true') {
    let links = document.querySelectorAll('.post-body a')
    links.forEach(item => {
      if (!item.classList.contains('btn')) {
        item.setAttribute("target", "_blank");
      }
    })
  }

  let faSearch = document.querySelector('#fa_search');
  faSearch.addEventListener('click', function () {
    document.querySelector('#search_mask').style = ''
  })

  // 代码高亮
  hljs.initHighlightingOnLoad();
  
  // 离开当前页title变化
  var leaveTitle = '';
  if (leaveTitle) {
    document.addEventListener('visibilitychange', function () {
      if (document.visibilityState == 'hidden') {
        normal_title = document.title;
        document.title = leaveTitle;
      } else {
        document.title = normal_title;
      }
    });
  }

</script>
    <div class="light-box" id="light_box"></div>
<script>
  let imgs = document.querySelectorAll('.post-body img');
  let lightBox = document.querySelector('#light_box');
  lightBox.addEventListener('mousedown', (e) => {
    e.preventDefault()
  })
  lightBox.addEventListener('mousewheel', (e) => {
    e.preventDefault()
  })
  let width = window.innerWidth * 0.8;
  lightBox.onclick = () => {
    let img = lightBox.querySelector('img');
    lightBox.style = '';
    img && img.remove();
  }
  imgs.forEach(item => {
    item.onclick = function (e) {
      let lightImg = document.createElement('img');
      lightImg.src = this.src;
      lightBox.style = `height: 100%; opacity: 1; background-color: rgba(0, 0, 0, 0.5);cursor: zoom-out;`;
      lightImg.style = `width: ${width}px; border: 1px solid #fff; border-radius: 2px;`;
      lightImg.onclick = function () {
        lightBox.style = '';
        this.remove();
      }
      lightBox.append(lightImg);
    }
  })
</script>
    <div class="reward-mask" style="display: none;">
  <div class="reward-relative">
    <span class="close" aria-hidden="true">x</span>
    <div class="reward-body">
      <h2>感谢您的支持，我会继续努力的!</h2>
      <div class="reward-img-box">
        <div style="position: relative; width: 140px; height: 140px;">
          
          
          
        </div>
      </div>
      <p class="reward-word">扫码打赏，你说多少就多少</p>
      <p class="reward-tip">打开微信扫一扫，即可进行扫码打赏哦</p>
    </div>
    <div class="bottom">
      
      
    </div>
  </div>
</div>
<style>
  .reward-mask {
    position: fixed;
    z-index: 99999;
    top: 0;
    bottom: 0;
    left: 0;
    right: 0;
    background-color: #00000054;
  }

  .reward-relative {
    position: relative;
    width: 480px;
    text-align: center;
    margin: 0 auto;
    border-radius: 5px;
    background-color: #fff;
    top: 50%;
    margin-top: -205px;
  }

  .reward-relative .close {
    position: absolute;
    right: 10px;
    font-weight: normal;
    font-size: 16px;
    color: #929292;
  }

  .reward-body {
    padding: 40px 20px 20px;
  }

  .bottom {
    display: flex;
  }

  .reward-btn {
    text-align: center;
  }

  .reward-btn-text {
    display: inline-block;
    cursor: pointer;
    width: 60px;
    height: 60px;
    line-height: 60px;
    border-radius: 50%;
    background-color: #ff9734;
    color: #FFF;
    margin-top: 20px;
  }

  .pay-text {
    margin-top: 10px;
    padding: 10px;
    flex: 1;
    transition: all .2s linear;
  }

  .pay-text:hover {
    background-color: #a5a5a536;
  }

  .reward-body h2 {
    padding-top: 10px;
    text-align: center;
    color: #a3a3a3;
    font-size: 16px;
    font-weight: normal;
    margin: 0 0 20px;
  }

  .reward-body h2:after,
  .reward-body h2:before {
    font-family: Arial, Helvetica, sans-serif;
    background: 0 0;
    width: 0;
    height: 0;
    font-style: normal;
    color: #eee;
    font-size: 80px;
    position: absolute;
    top: 20px;
  }

  .reward-body h2:before {
    content: '\201c';
    left: 50px;
  }

  .reward-body h2:after {
    content: '\201d';
    right: 80px;
  }

  .reward-img-box {
    display: inline-block;
    padding: 10px;
    border: 6px solid #ea5f00;
    margin: 0 auto;
    border-radius: 3px;
    position: relative;
  }

  .reward-img {
    position: absolute;
    left: 0px;
    top: 0px;
    width: 100%;
    height: 100%;
  }

  @media (max-width: 767px) {
    .reward-relative {
      height: 100%;
      top: 0px;
      margin-top: 0;
      width: auto;
    }

    .reward-relative .bottom {
      flex-direction: column;
    }

    .reward-relative .pay-text {
      width: 80%;
      margin: 5px auto;
      border: 1px solid silver;
      padding: 6px;
      border-radius: 4px;
    }

    .reward-body h2:after {
      right: 40px;
    }

    .reward-body h2:after,
    .reward-body h2:before {
      font-size: 60px;
    }

    .reward-body h2:before {
      left: 20px;
    }
  }
</style>
<script>
  !function () {
    var mask = document.querySelector('.reward-mask');
    let close = document.querySelector('.reward-relative .close');
    let rewardBtn = document.querySelector('.reward-btn');

    let zfb = document.querySelector('#zfb'),
      wx = document.querySelector('#wx'),
      zfbBtn = document.querySelector('#zfbBtn'),
      wxBtn = document.querySelector('#wxBtn');

    if (zfbBtn && wxBtn) {
      zfbBtn.addEventListener('click', () => {
        window.Velocity(zfb, 'transition.slideLeftIn', {
          duration: 400
        });
        window.Velocity(wx, 'transition.slideRightOut', {
          display: 'none',
          duration: 400
        });
      });

      wxBtn.addEventListener('click', () => {
        window.Velocity(wx, 'transition.slideRightIn', {
          duration: 400
        });
        window.Velocity(zfb, 'transition.slideLeftOut', {
          display: 'none',
          duration: 400
        });
      });
    }

    rewardBtn.addEventListener('click', (e) => {
      window.Velocity(mask, 'transition.slideDownIn', {
        duration: 400
      })
    });

    close.addEventListener('click', (e) => {
      e.preventDefault();
      window.Velocity(mask, 'transition.slideUpOut', {
        duration: 400
      })
    })
  }()
</script>

  </div>
</body>

  <div class="search-mask" id="search_mask" style="display: none;">
  <div class="search-box">
    <div class="search-title">
      <i class="fa fa-search"></i>
      <div class="input-box">
        <input id="search" type="text" class="language" data-lan="search" placeholder="搜索">
      </div>
      <i id="close" class="fa fa-times-circle"></i>
    </div>
    <div class="stat-box">
      <span id="stat_count">0</span><span class="language" data-lan="stat">条相关条目，使用了</span><span id="stat_times">0</span><span class="language" data-lan="stat-time">毫秒</span>
      <hr>
    </div>
    <div class="result" id="result">
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://zhangyaoo.github.io/post/ji-yu-netty-ji-shi-tong-xun-xi-tong-she-ji-yu-shi-xian/"" data-c="
          &lt;h2 id=&#34;fastim&#34;&gt;FastIM&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;🚀基于Netty高可用分布式即时通讯系统，支持长连接网关管理、单聊、群聊、登录登出、聊天记录查询、离线消息存储、消息推送、心跳、分布式唯一ID、红包、消息同步和漫游等功能，支持集群部署的分布式架构。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;一-功能&#34;&gt;一、功能&lt;/h2&gt;
&lt;h3 id=&#34;1-设计&#34;&gt;1. 设计&lt;/h3&gt;
&lt;ul class=&#34;contains-task-list&#34;&gt;
&lt;li class=&#34;task-list-item&#34;&gt;&lt;input class=&#34;task-list-item-checkbox&#34; checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34; id=&#34;task-item-3516157&#34;&gt; &lt;a href=&#34;#%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1&#34;&gt;IM架构设计&lt;label class=&#34;task-list-item-label&#34; for=&#34;task-item-3516157&#34;&gt; [IM架构设计](#架构设计)&lt;/label&gt;&lt;/li&gt;
&lt;li class=&#34;task-list-item&#34;&gt;&lt;input class=&#34;task-list-item-checkbox&#34; checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34; id=&#34;task-item-5020453&#34;&gt; &lt;a href=&#34;#%E6%B6%88%E6%81%AFID%E7%94%9F%E6%88%90%E6%9C%BA%E5%88%B6&#34;&gt;分布式ID设计&lt;label class=&#34;task-list-item-label&#34; for=&#34;task-item-5020453&#34;&gt; [分布式ID设计](#消息ID生成机制)&lt;/label&gt;&lt;/li&gt;
&lt;li class=&#34;task-list-item&#34;&gt;&lt;input class=&#34;task-list-item-checkbox&#34; checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34; id=&#34;task-item-7669253&#34;&gt; &lt;a href=&#34;#%E6%A0%B8%E5%BF%83%E8%A1%A8%E7%BB%93%E6%9E%84%E8%AE%BE%E8%AE%A1&#34;&gt;IM表结构设计&lt;label class=&#34;task-list-item-label&#34; for=&#34;task-item-7669253&#34;&gt; [IM表结构设计](#核心表结构设计)&lt;/label&gt;&lt;/li&gt;
&lt;li class=&#34;task-list-item&#34;&gt;&lt;input class=&#34;task-list-item-checkbox&#34; disabled=&#34;&#34; type=&#34;checkbox&#34; id=&#34;task-item-9247461&#34;&gt;&lt;label class=&#34;task-list-item-label&#34; for=&#34;task-item-9247461&#34;&gt; TCP网关设计&lt;/label&gt;&lt;/li&gt;
&lt;li class=&#34;task-list-item&#34;&gt;&lt;input class=&#34;task-list-item-checkbox&#34; disabled=&#34;&#34; type=&#34;checkbox&#34; id=&#34;task-item-1971622&#34;&gt;&lt;label class=&#34;task-list-item-label&#34; for=&#34;task-item-1971622&#34;&gt; HTTP网关设计&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2-功能&#34;&gt;2. 功能&lt;/h3&gt;
&lt;ul class=&#34;contains-task-list&#34;&gt;
&lt;li class=&#34;task-list-item&#34;&gt;&lt;input class=&#34;task-list-item-checkbox&#34; disabled=&#34;&#34; type=&#34;checkbox&#34; id=&#34;task-item-298044&#34;&gt;&lt;label class=&#34;task-list-item-label&#34; for=&#34;task-item-298044&#34;&gt; 单聊&lt;/label&gt;&lt;/li&gt;
&lt;li class=&#34;task-list-item&#34;&gt;&lt;input class=&#34;task-list-item-checkbox&#34; disabled=&#34;&#34; type=&#34;checkbox&#34; id=&#34;task-item-4293091&#34;&gt;&lt;label class=&#34;task-list-item-label&#34; for=&#34;task-item-4293091&#34;&gt; 群聊&lt;/label&gt;&lt;/li&gt;
&lt;li class=&#34;task-list-item&#34;&gt;&lt;input class=&#34;task-list-item-checkbox&#34; disabled=&#34;&#34; type=&#34;checkbox&#34; id=&#34;task-item-8417817&#34;&gt;&lt;label class=&#34;task-list-item-label&#34; for=&#34;task-item-8417817&#34;&gt; 心跳保活，断线自动重连&lt;/label&gt;&lt;/li&gt;
&lt;li class=&#34;task-list-item&#34;&gt;&lt;input class=&#34;task-list-item-checkbox&#34; checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34; id=&#34;task-item-215823&#34;&gt; &lt;a href=&#34;#%E8%87%AA%E5%AE%9A%E4%B9%89%E9%80%9A%E8%AE%AF%E5%8D%8F%E8%AE%AE+Protobuf%E5%BA%8F%E5%88%97%E5%8C%96&#34;&gt;自定义通讯协议 + Protobuf序列化&lt;label class=&#34;task-list-item-label&#34; for=&#34;task-item-215823&#34;&gt; [自定义通讯协议 + Protobuf序列化](#自定义通讯协议+Protobuf序列化)&lt;/label&gt;&lt;/li&gt;
&lt;li class=&#34;task-list-item&#34;&gt;&lt;input class=&#34;task-list-item-checkbox&#34; checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34; id=&#34;task-item-4200907&#34;&gt; &lt;a href=&#34;#%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%9C%AAack%E6%B6%88%E6%81%AF%E9%87%8D%E8%AF%95&#34;&gt;客户端未ack消息重试&lt;label class=&#34;task-list-item-label&#34; for=&#34;task-item-4200907&#34;&gt; [客户端未ack消息重试](#客户端未ack消息重试)&lt;/label&gt;&lt;/li&gt;
&lt;li class=&#34;task-list-item&#34;&gt;&lt;input class=&#34;task-list-item-checkbox&#34; disabled=&#34;&#34; type=&#34;checkbox&#34; id=&#34;task-item-7522919&#34;&gt;&lt;label class=&#34;task-list-item-label&#34; for=&#34;task-item-7522919&#34;&gt; 消息未读计数&lt;/label&gt;&lt;/li&gt;
&lt;li class=&#34;task-list-item&#34;&gt;&lt;input class=&#34;task-list-item-checkbox&#34; disabled=&#34;&#34; type=&#34;checkbox&#34; id=&#34;task-item-4811149&#34;&gt;&lt;label class=&#34;task-list-item-label&#34; for=&#34;task-item-4811149&#34;&gt; 聊天记录存储和查询&lt;/label&gt;&lt;/li&gt;
&lt;li class=&#34;task-list-item&#34;&gt;&lt;input class=&#34;task-list-item-checkbox&#34; disabled=&#34;&#34; type=&#34;checkbox&#34; id=&#34;task-item-9561088&#34;&gt;&lt;label class=&#34;task-list-item-label&#34; for=&#34;task-item-9561088&#34;&gt; 登录、登出&lt;/label&gt;&lt;/li&gt;
&lt;li class=&#34;task-list-item&#34;&gt;&lt;input class=&#34;task-list-item-checkbox&#34; disabled=&#34;&#34; type=&#34;checkbox&#34; id=&#34;task-item-4205703&#34;&gt;&lt;label class=&#34;task-list-item-label&#34; for=&#34;task-item-4205703&#34;&gt; 通讯协议支持HTTP/2&lt;/label&gt;&lt;/li&gt;
&lt;li class=&#34;task-list-item&#34;&gt;&lt;input class=&#34;task-list-item-checkbox&#34; checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34; id=&#34;task-item-2138903&#34;&gt; &lt;a href=&#34;#%E5%AE%A2%E6%88%B7%E7%AB%AFSDK&#34;&gt;客户端SDK&lt;label class=&#34;task-list-item-label&#34; for=&#34;task-item-2138903&#34;&gt; [客户端SDK](#客户端SDK)&lt;/label&gt;&lt;/li&gt;
&lt;li class=&#34;task-list-item&#34;&gt;&lt;input class=&#34;task-list-item-checkbox&#34; disabled=&#34;&#34; type=&#34;checkbox&#34; id=&#34;task-item-2968781&#34;&gt;&lt;label class=&#34;task-list-item-label&#34; for=&#34;task-item-2968781&#34;&gt; 多端消息同步和消息漫游&lt;/label&gt;&lt;/li&gt;
&lt;li class=&#34;task-list-item&#34;&gt;&lt;input class=&#34;task-list-item-checkbox&#34; disabled=&#34;&#34; type=&#34;checkbox&#34; id=&#34;task-item-736732&#34;&gt;&lt;label class=&#34;task-list-item-label&#34; for=&#34;task-item-736732&#34;&gt; 唯一设备踢出&lt;/label&gt;&lt;/li&gt;
&lt;li class=&#34;task-list-item&#34;&gt;&lt;input class=&#34;task-list-item-checkbox&#34; disabled=&#34;&#34; type=&#34;checkbox&#34; id=&#34;task-item-7458345&#34;&gt;&lt;label class=&#34;task-list-item-label&#34; for=&#34;task-item-7458345&#34;&gt; 文件图片发送&lt;/label&gt;&lt;/li&gt;
&lt;li class=&#34;task-list-item&#34;&gt;&lt;input class=&#34;task-list-item-checkbox&#34; disabled=&#34;&#34; type=&#34;checkbox&#34; id=&#34;task-item-443778&#34;&gt;&lt;label class=&#34;task-list-item-label&#34; for=&#34;task-item-443778&#34;&gt; 消息加密&lt;/label&gt;&lt;/li&gt;
&lt;li class=&#34;task-list-item&#34;&gt;&lt;input class=&#34;task-list-item-checkbox&#34; disabled=&#34;&#34; type=&#34;checkbox&#34; id=&#34;task-item-1756299&#34;&gt;&lt;label class=&#34;task-list-item-label&#34; for=&#34;task-item-1756299&#34;&gt; 群红包&lt;/label&gt;&lt;/li&gt;
&lt;li class=&#34;task-list-item&#34;&gt;&lt;input class=&#34;task-list-item-checkbox&#34; disabled=&#34;&#34; type=&#34;checkbox&#34; id=&#34;task-item-4153938&#34;&gt;&lt;label class=&#34;task-list-item-label&#34; for=&#34;task-item-4153938&#34;&gt; 消息撤回&lt;/label&gt;&lt;/li&gt;
&lt;li class=&#34;task-list-item&#34;&gt;&lt;input class=&#34;task-list-item-checkbox&#34; disabled=&#34;&#34; type=&#34;checkbox&#34; id=&#34;task-item-7257877&#34;&gt;&lt;label class=&#34;task-list-item-label&#34; for=&#34;task-item-7257877&#34;&gt; 消息已读&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;二-系统设计&#34;&gt;二、系统设计&lt;/h2&gt;
&lt;h3 id=&#34;1-im架构图&#34;&gt;1. IM架构图&lt;/h3&gt;
&lt;p&gt;基于可扩展性高可用原则，把网关层、路由层、逻辑层、数据层分离，并且支持分布式部署&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/architecture.png&#34; alt=&#34;IM架构图&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;2-架构设计&#34;&gt;2. 架构设计&lt;/h3&gt;
&lt;h4 id=&#34;20-client设计&#34;&gt;2.0 CLIENT设计：&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;client每个设备会在本地存每一个会话，保留有最新一条消息的顺序 ID&lt;/li&gt;
&lt;li&gt;为了避免client宕机，也就是退出应用，保存在内存的消息ID丢失，会存到本地的文件中&lt;/li&gt;
&lt;li&gt;client需要在本地维护一个等待ack队列，并配合timer超时机制，来记录哪些消息没有收到ack：N，以定时重发。&lt;/li&gt;
&lt;li&gt;客户端本地生成一个递增序列号发送给服务器，用作保证发送顺序性。该序列号还用作ack队列收消息时候的移除。&lt;/li&gt;
&lt;/ol&gt;
&lt;h5 id=&#34;21-客户端序列号设计&#34;&gt;2.1 客户端序列号设计&lt;/h5&gt;
&lt;h5 id=&#34;方案一&#34;&gt;方案一&lt;/h5&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://zhangyaoo.github.io/post-images/sequenceId.png&#34; alt=&#34;客户端序列号&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;设计：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;数据传输中的大小尽量小用int，不用bigint，节省传输大小&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;只保证递增即可,在用户重新登录或者重连后可以进行日期重置，只保证单次&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;客户端发号器不需要像类似服务器端发号器那样集群部署，不需要考虑集群同步问题&lt;br&gt;
说明：上述生成器可以用18年[(2^29-1)/3600/24/365]左右，一秒内最多产生4个消息&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;优点：可以在断线重连和重装APP的情况下，18年之内是有序的&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;缺点：每秒只能发4个消息，限制太大，对于群发场景不合适&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;改进：使用long进行传输，年限扩展很久并且有序&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;方案二&#34;&gt;方案二&lt;/h5&gt;
&lt;p&gt;设计：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;每次重新建立链接后进行重置，将sequence_id（int表示）从0开始进行严格递增&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;客户端发送消息会带上唯一的递增sequence_id，同一条消息重复投递的sequence_id是一样的&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;后端存储每个用户的sequence_id，当sequence_id归0，用户的epoch年代加1存储入库，单聊场景下转发给接收者时候，接收者按照sequence_id和epoch来进行排序&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;优点：可以在断线重连和重装APP的情况下，接收者可以按照发送者发送时序来显示，并且对发送消息的速率没限制&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;21-lsb设计与优化&#34;&gt;2.1 LSB设计与优化：&lt;/h4&gt;
&lt;h5 id=&#34;210-lsb设计&#34;&gt;2.1.0 LSB设计&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;接入层的高可用、负载均衡、扩展性全部在这里面做&lt;/li&gt;
&lt;li&gt;客户端通过LSB，来获取gate IP地址，通过IP直连，目的是
&lt;ul&gt;
&lt;li&gt;灵活的负载均衡策略 可根据最少连接数来分配IP&lt;/li&gt;
&lt;li&gt;做灰度策略来分配IP&lt;/li&gt;
&lt;li&gt;AppId业务隔离策略 不同业务连接不同的gate，防止相互影响&lt;/li&gt;
&lt;li&gt;单聊和群聊的im接入层通道分开&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h5 id=&#34;211-lsb优化&#34;&gt;2.1.1 LSB优化&lt;/h5&gt;
&lt;p&gt;问题背景：当某个实例重启后，该实例的连接断开后，客户端会发起重连，重连就大概率转移其他实例上，导致最近启动的实例连接数较少，最早启动的实例连接数较多&lt;br&gt;
解决方法：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;客户端会发起重连，跟服务器申请重连的新的服务器IP，系统提供合适的算法来平摊gate层的压力，防止雪崩效应。&lt;/li&gt;
&lt;li&gt;gate层定时上报本机的元数据信息以及连接数信息，提供给LSB中心，LSB根据最少连接数负载均衡实现，来计算一个节点供连接。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;22-gate设计&#34;&gt;2.2 GATE设计：&lt;/h4&gt;
&lt;p&gt;GATE层网关有以下特性：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;任何一个gate网关断掉，用户端检测到以后重新连接LSB服务获取另一个gate网关IP，拿到IP重新进行长连接通信。对整体服务可靠性基本没有影响。&lt;/li&gt;
&lt;li&gt;gate可以无状态的横向部署，来扩展接入层的接入能力&lt;/li&gt;
&lt;li&gt;根据协议分类将入口请求打到不同的网关上去，HTTP网关接收HTTP请求，TCP网关接收tcp长连接请求&lt;/li&gt;
&lt;li&gt;长连接网关，提供各种监控功能，比如网关执行线程数、队列任务数、ByteBuf使用堆内存数、堆外内存数、消息上行和下行的数量以及时间&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;23-router设计&#34;&gt;2.3 ROUTER设计：&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;把用户状态信息存储在Redis集群里。因此也是无状态的，任何一个router服务挂掉，不影响整体服务能力。&lt;/li&gt;
&lt;li&gt;转发消息，将消息投递给固定gate上的会话，处理路由逻辑&lt;/li&gt;
&lt;li&gt;router层需要存储的关系
&lt;ul&gt;
&lt;li&gt;uid和gate层机器ID关系&lt;/li&gt;
&lt;li&gt;用户全局在线信息&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;用户路由状态一致性保证
&lt;ul&gt;
&lt;li&gt;如果路由状态和channel通道不一致，比如有路由状态，没有channel通道（已关闭）那么，就会走离线消息流出，并且清除路由信息&lt;/li&gt;
&lt;li&gt;动态重启gate，会及时清理路由信息&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;24-logic设计&#34;&gt;2.4 LOGIC设计：&lt;/h4&gt;
&lt;p&gt;logic按照分布式微服务的拆分思想进行拆分，拆分为多个模块&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;单聊服务&lt;/li&gt;
&lt;li&gt;群聊服务&lt;/li&gt;
&lt;li&gt;登录 登出 注册服务&lt;/li&gt;
&lt;li&gt;红包服务&lt;/li&gt;
&lt;li&gt;分布式ID服务&lt;/li&gt;
&lt;li&gt;离线服务&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;25-das-data-access-service设计&#34;&gt;2.5 DAS (data access service)设计：&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;定时将冷数据迁移到Cold存储系统&lt;/li&gt;
&lt;li&gt;多个存储系统的实现，统一cache层&lt;/li&gt;
&lt;li&gt;向上游屏蔽存储引擎，提供友好的接口&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;3-协议设计&#34;&gt;3. 协议设计&lt;/h3&gt;
&lt;h4 id=&#34;30-目标&#34;&gt;3.0 目标&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;高性能：协议设计紧凑，保证数据包小，并且序列化性能好&lt;/li&gt;
&lt;li&gt;可扩展性：针对后续业务发展，可以自由的自定义协议，无需较大改动协议结构&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;31-设计&#34;&gt;3.1 设计&lt;/h4&gt;
&lt;p&gt;IM协议采用二进制定长包头和变长包体来实现客户端和服务端的通信，并且采用谷歌protobuf序列化协议，设计如下：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://zhangyaoo.github.io/post-images/IM-protocol.png&#34; alt=&#34;IM协议设计图&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;各个字段如下解释：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;headData：头部标识，协议头标识，用作粘包半包处理。4个字节&lt;/li&gt;
&lt;li&gt;version：客户端版本。4个字节&lt;/li&gt;
&lt;li&gt;cmd：业务命令，比如心跳、推送、单聊、群聊。1个字节&lt;/li&gt;
&lt;li&gt;msgType：消息通知类型 request response notify。1个字节&lt;/li&gt;
&lt;li&gt;logId：调试性日志，追溯一个请求的全路径。4个字节&lt;/li&gt;
&lt;li&gt;sequenceId：序列号，可以用作异步处理。4个字节&lt;/li&gt;
&lt;li&gt;dataLength：数据体的长度。4个字节&lt;/li&gt;
&lt;li&gt;data：数据&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;32-实践&#34;&gt;3.2 实践&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;针对数据data，&lt;strong&gt;网关gate层不做反序列化，反序列化步骤在service做&lt;/strong&gt;，避免重复序列化和反序列化导致的性能损失&lt;/li&gt;
&lt;li&gt;网关层不做业务逻辑处理，只做消息转发和推送，减少网关层的复杂度&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;4-安全管理&#34;&gt;4. 安全管理&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;为防止消息传输过程中不被截获、篡改、伪造，采用TLS传输层加密协议&lt;/li&gt;
&lt;li&gt;私有化协议天然具备一定的防窃取和防篡改的能力，相对于使用JSON、XML、HTML等明文传输系统，被第三方截获后在内容破解上相对成本更高，因此安全性上会更好一些&lt;/li&gt;
&lt;li&gt;消息存储安全性:针对账号密码的存储安全可以通过“高强度单向散列算法”和“加盐”机制来提升加密密码可逆性；IM消息采用“端到端加密”方式来提供更加安全的消息传输保护。&lt;/li&gt;
&lt;li&gt;安全层协议设计。基于动态密钥，借鉴类似SSL，不需要用证书来管理。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;5-消息流转设计&#34;&gt;5. 消息流转设计&lt;/h3&gt;
&lt;p&gt;一个正常的消息流转需要如图所示的流程：&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/IM-pic1.png&#34; alt=&#34;IM核心流程图&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;客户端A发送请求包R&lt;/li&gt;
&lt;li&gt;server将消息存储到DB&lt;/li&gt;
&lt;li&gt;存储成功后返回确认ack&lt;/li&gt;
&lt;li&gt;server push消息给客户端B&lt;/li&gt;
&lt;li&gt;客户端B收到消息后返回确认ack&lt;/li&gt;
&lt;li&gt;server收到ack后更新消息的状态或者删除消息&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;需要考虑的是，一个健壮的系统需要考虑各种异常情况，如丢消息，重复消息，消息时序问题&lt;/p&gt;
&lt;h4 id=&#34;50-消息可靠性如何保证-不丢消息&#34;&gt;5.0 消息可靠性如何保证 不丢消息&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;应用层ACK&lt;/li&gt;
&lt;li&gt;客户端需要超时与重传&lt;/li&gt;
&lt;li&gt;服务端需要超时与重传，具体做法就是增加ack队列和定时器Timer&lt;/li&gt;
&lt;li&gt;业务侧兜底保证，客户端拉消息通过一个本地的旧的序列号来拉取服务器的最新消息&lt;/li&gt;
&lt;li&gt;为了保证消息必达，在线客户端还增加一个定时器，定时向服务端拉取消息，避免服务端向客户端发送拉取通知的包丢失导致客户端未及时拉取数据。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;51-消息重复性如何保证-不重复&#34;&gt;5.1 消息重复性如何保证 不重复&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;超时与重传机制将导致接收的client收到重复的消息，具体做法就是一份消息使用同一个消息ID进行去重处理。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;52-消息顺序性如何保证-不乱序&#34;&gt;5.2 消息顺序性如何保证 不乱序&lt;/h4&gt;
&lt;h5 id=&#34;520-消息乱序影响的因素&#34;&gt;5.2.0 消息乱序影响的因素&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;时钟不一致，分布式环境下每个机器的时间可能是不一致的&lt;/li&gt;
&lt;li&gt;多发送方和多接收方，这种情况下，无法保先发的消息被先收到&lt;/li&gt;
&lt;li&gt;网络传输和多线程，网络传输不稳定的话可能导致包在数据传输过程中有的慢有的快。多线程也可能是会导致时序不一致影响的因素&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;以上，如果保持绝对的实现，那么只能是一个发送方，一个接收方，一个线程阻塞式通讯来实现。那么性能会降低。&lt;/p&gt;
&lt;h5 id=&#34;521-如何保证时序&#34;&gt;5.2.1 如何保证时序&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;单聊：通过发送方的绝对时序seq，来作为接收方的展现时序seq。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;实现方式：可以通过时间戳或者本地序列号方式来实现&lt;/li&gt;
&lt;li&gt;缺点：本地时间戳不准确或者本地序列号在意外情况下可能会清0，都会导致发送方的绝对时序不准确&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;群聊：因为发送方多点发送时序不一致，所以通过服务器的单点做序列化，也就是通过ID递增发号器服务来生成seq，接收方通过seq来进行展现时序。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;实现方式：通过服务端统一生成唯一趋势递增消息ID来实现或者通过redis的递增incr来实现&lt;/li&gt;
&lt;li&gt;缺点：redis的递增incr来实现，redis取号都是从主取的，会有性能瓶颈。ID递增发号器服务是集群部署，可能不同发号服务上的集群时间戳不同，可能会导致后到的消息seq还小。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;群聊时序的优化：按照上面的群聊处理，业务上按照道理只需要保证单个群的时序，不需要保证所有群的绝对时序，所以解决思路就是&lt;strong&gt;同一个群的消息落到同一个发号service&lt;/strong&gt;上面，消息seq通过service本地生成即可。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h5 id=&#34;522-客户端如何保证顺序&#34;&gt;5.2.2 客户端如何保证顺序&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;为什么要保证顺序？&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;消息即使按照顺序到达服务器端，也会可能出现：不同消息到达接收端后，可能会出现“先产生的消息后到”“后产生的消息先到”等问题。所以客户端需要进行兜底的流量整形机制&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如何保证顺序？&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;接收方收到消息后进行判定，如果当前消息序号大于前一条消息的序号就将当前消息追加在会话里&lt;/li&gt;
&lt;li&gt;否则继续往前查找倒数第二条、第三条等消息，一直查找到恰好小于当前推送消息的那条消息，然后插入在其后展示。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;6-消息通知设计&#34;&gt;6 消息通知设计&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;整体消息推送和拉取的时序图如下：&lt;/strong&gt;&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/msg-pull-push-model.png&#34; alt=&#34;IM消息推拉模型&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;60-消息拉取方式的选择&#34;&gt;6.0 消息拉取方式的选择&lt;/h4&gt;
&lt;p&gt;本项目是进行推拉结合来进行服务器端消息的推送和客户端的拉取，我们知道单pull和单push有以下缺点：&lt;/p&gt;
&lt;p&gt;单pull：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;pull要考虑到消息的实时性，不知道消息何时送达&lt;/li&gt;
&lt;li&gt;pull要考虑到哪些好友和群收到了消息，要循环每个群和好友拿到消息列表，读扩散&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;单push：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;push实时性高，只要将消息推送给接收者就ok，但是会集中消耗服务器资源。并且再群聊非常多，聊天频率非常高的情况下，会增加客户端和服务端的网络交互次数&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;推拉结合：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;推拉结合的方式能够分摊服务端的压力,能保证时效性，又能保证性能&lt;/li&gt;
&lt;li&gt;具体做法就是有新消息时候，推送哪个好友或者哪个群有新消息，以及新消息的数量或者最新消息ID，客户端按需根据自身数据进行拉取&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;61-推拉隔离设计&#34;&gt;6.1 推拉隔离设计&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;为什么做隔离
&lt;ul&gt;
&lt;li&gt;如果客户端一边正在拉取数据，一边有新的增量消息push过来&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;如何做隔离
&lt;ul&gt;
&lt;li&gt;本地设置一个全局的状态，当客户端拉取完离线消息后设置状态为1（表示离线消息拉取完毕）。当客户端收到拉取实时消息，会启用一个轮询监听这个状态，状态为1后，再去向服务器拉取消息。&lt;/li&gt;
&lt;li&gt;如果是push消息过来（不是主动拉取），那么会先将消息存储到本地的消息队列中，等待客户端上一次拉取数据完毕，然后将数据进行合并即可&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;7-消息id生成设计&#34;&gt;7 消息ID生成设计&lt;/h3&gt;
&lt;h5 id=&#34;70-设计&#34;&gt;7.0 设计&lt;/h5&gt;
&lt;p&gt;实际业务的情况【只做参考，实际可以根据公司业务线来调整】&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;单机高峰并发量小于1W，预计未来5年单机高峰并发量小于10W&lt;/li&gt;
&lt;li&gt;有2个机房，预计未来5年机房数量小于4个 每个机房机器数小于150台&lt;/li&gt;
&lt;li&gt;目前只有单聊和群聊两个业务线，后续可以扩展为系统消息、聊天室、客服等业务线，最多8个业务线&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;根据以上业务情况，来设计分布式ID：&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/server-id.jpg&#34; alt=&#34;IM服务端分布式ID设计&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;h5 id=&#34;71-优点&#34;&gt;7.1 优点&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;不同机房不同机器不同业务线内生成的ID互不相同&lt;/li&gt;
&lt;li&gt;每个机器的每毫秒内生成的ID不同&lt;/li&gt;
&lt;li&gt;预留两位留作扩展位&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;72-缺点&#34;&gt;7.2 缺点：&lt;/h5&gt;
&lt;p&gt;当并发度不高的时候，时间跨毫秒的消息，区分不出来消息的先后顺序。因为时间跨毫秒的消息生成的ID后面的最后一位都是0，后续如果按照消息ID维度进行分库分表，会导致数据倾斜&lt;/p&gt;
&lt;h5 id=&#34;73-两种解决方案&#34;&gt;7.3 两种解决方案：&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;方案一：去掉snowflake最后8位，然后对剩余的位进行取模&lt;/li&gt;
&lt;li&gt;方案二：不同毫秒的计数，每次不是归0，而是归为随机数，相比方案一，比较简单实用&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;8-消息未读数设计&#34;&gt;8 消息未读数设计&lt;/h3&gt;
&lt;h4 id=&#34;80-实现&#34;&gt;8.0 实现&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;每发一个消息，消息接收者的会话未读数+1，并且接收者所有未读数+1&lt;/li&gt;
&lt;li&gt;消息接收者返回消息接收确认ack后，消息未读数会-1&lt;/li&gt;
&lt;li&gt;消息接收者的未读数+1，服务端就会推算有多少条未读数的通知&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;81-分布式锁保证总未读数和会话未读数一致&#34;&gt;8.1 分布式锁保证总未读数和会话未读数一致&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;不一致原因：当总未读数增加，这个时候客户端来了请求将未知数置0，然后再增加会话未读数，那么会导致不一致&lt;/li&gt;
&lt;li&gt;保证：为了保证总未读数和会话未读数原子性，需要用分布式锁来保证&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;82-群聊消息未读数难点和优化&#34;&gt;8.2 群聊消息未读数难点和优化&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;难点&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一个群聊每秒几百的并发聊天，比如消息未读数，相当于每秒W级别的写入redis，即便redis做了集群数据分片+主从，但是写入还是单节点，会有写入瓶颈&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;优化&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;群ID分组或者用户ID分组，批量写入，写入的两种方式
&lt;ul&gt;
&lt;li&gt;定时flush&lt;/li&gt;
&lt;li&gt;满多少消息进行flush&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;9-网关设计&#34;&gt;9. 网关设计&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;接入层网关和应用层网关不同地方
&lt;ul&gt;
&lt;li&gt;接入层网关需要有接收通知包或者下行接收数据的端口，并且需要另外开启线程池。应用层网关不需要开端口，并且不需要开启线程池。&lt;/li&gt;
&lt;li&gt;接入层网关需要保持长连接，接入层网关需要本地缓存channel映射关系。应用层网关无状态不需要保存。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;91-接入层网关设计&#34;&gt;9.1 接入层网关设计&lt;/h4&gt;
&lt;h5 id=&#34;910-目标&#34;&gt;9.1.0 目标：&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;网关的线程池实现1+8+4+1，减少线程切换&lt;/li&gt;
&lt;li&gt;集中实现长连接管理和推送能力&lt;/li&gt;
&lt;li&gt;与业务服务器解耦，集群部署缩容扩容以及重启升级不相互影响&lt;/li&gt;
&lt;li&gt;长连接的监控与报警能力&lt;/li&gt;
&lt;li&gt;客户端重连指令一键实现&lt;/li&gt;
&lt;/ol&gt;
&lt;h5 id=&#34;911-技术点&#34;&gt;9.1.1 技术点：&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;自定义协议以及序列化&lt;/li&gt;
&lt;li&gt;通道连接自定义保活以及心跳检测&lt;/li&gt;
&lt;li&gt;本地缓存channel&lt;/li&gt;
&lt;li&gt;责任链&lt;/li&gt;
&lt;li&gt;服务调用完全异步&lt;/li&gt;
&lt;li&gt;泛化调用&lt;/li&gt;
&lt;li&gt;转发通知包或者Push包&lt;/li&gt;
&lt;li&gt;容错网关down机处理&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;912-设计方案&#34;&gt;9.1.2 设计方案：&lt;/h5&gt;
&lt;p&gt;参考&lt;a href=&#34;https://github.com/zhangyaoo/fastim/blob/master/fastim-gate/fastim-gate-tcp/README.md&#34;&gt;基于Netty的长连接网关设计与实现&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;一个Notify包的数据经网关的线程模型图：&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/TCP-Gate-ThreadModel.png&#34; alt=&#34;TCP网关线程模型&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;92-应用层api网关设计&#34;&gt;9.2 应用层API网关设计&lt;/h4&gt;
&lt;h5 id=&#34;920-目标&#34;&gt;9.2.0 目标：&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;基于版本的自动发现以及灰度/扩容 ，不需要关注IP&lt;/li&gt;
&lt;li&gt;网关的线程池实现1+8+1，减少线程切换&lt;/li&gt;
&lt;li&gt;支持协议转换实现多个协议转换，基于SPI来实现&lt;/li&gt;
&lt;li&gt;与业务服务器解耦，集群部署缩容扩容以及重启升级不相互影响&lt;/li&gt;
&lt;li&gt;接口错误信息统计和RT时间的监控和报警能力&lt;/li&gt;
&lt;li&gt;UI界面实现路由算法，服务接口版本管理，灰度策略管理以及接口和服务信息展示能力&lt;/li&gt;
&lt;li&gt;基于OpenAPI提供接口级别的自动生成文档的功能&lt;/li&gt;
&lt;/ol&gt;
&lt;h5 id=&#34;921-技术点&#34;&gt;9.2.1 技术点：&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Http2.0&lt;/li&gt;
&lt;li&gt;channel连接池复用&lt;/li&gt;
&lt;li&gt;Netty http 服务端编解码&lt;/li&gt;
&lt;li&gt;责任链&lt;/li&gt;
&lt;li&gt;服务调用完全异步&lt;/li&gt;
&lt;li&gt;全链路超时机制&lt;/li&gt;
&lt;li&gt;泛化调用&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;922-设计方案&#34;&gt;9.2.2 设计方案：&lt;/h5&gt;
&lt;p&gt;参考&lt;a href=&#34;https://github.com/zhangyaoo/fastim/blob/master/fastim-gate/fastim-gate-http/README.md&#34;&gt;基于Netty的API网关设计与实现&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;一个请求包的数据经网关的架构图：&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/HTTP-gate.png&#34; alt=&#34;网关的架构图&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;10-高并发-高可用设计&#34;&gt;10. 高并发、高可用设计&lt;/h3&gt;
&lt;h4 id=&#34;100-高并发设计&#34;&gt;10.0 高并发设计&lt;/h4&gt;
&lt;h5 id=&#34;1000-架构优化&#34;&gt;10.0.0 架构优化&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;水平扩展：各个模块无状态部署&lt;/li&gt;
&lt;li&gt;线程模型：每个服务底层线程模型遵从Netty主从reactor模型&lt;/li&gt;
&lt;li&gt;多层缓存：Gate层二级缓存，Redis一级缓存&lt;/li&gt;
&lt;li&gt;长连接：客户端长连接保持，避免频繁创建连接消耗&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;1001-万人群聊优化&#34;&gt;10.0.1 万人群聊优化&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;难点&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;消息扇出大，比如每秒群聊有50条消息，群聊2000人，那么光一个群对系统并发就有10W的消息扇出&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;优化&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;批量ACK：每条群消息都ACK，会给服务器造成巨大的冲击，为了减少ACK请求量，参考TCP的Delay ACK机制，在接收方层面进行批量ACK。&lt;/li&gt;
&lt;li&gt;群消息和成员批量加载以及懒加载：在真正进入一个群时才实时拉取群友的数据&lt;/li&gt;
&lt;li&gt;群离线消息过多：群消息分页拉取,第二次拉取请求作为第一次拉取请求的ack&lt;/li&gt;
&lt;li&gt;对于消息未读数场景，每个用户维护一个全局的未读数和每个会话的未读数，当群聊非常大时，未读资源变更的QPS非常大。这个时候应用层对未读数进行缓存，批量写+定时写来保证未读计数的写入性能&lt;/li&gt;
&lt;li&gt;路由信息存入redis会有写入和读取的性能瓶颈，每条消息在发出的时候会查路由信息来发送对应的gate接入层，比如有10个群，每个群1W，那么1s100条消息，那么1000W的查询会打满redis，即使redis做了集群。优化的思路就是将集中的路由信息分散到Router JVM本地内存中，然后做Route可用，避免单点故障。&lt;/li&gt;
&lt;li&gt;存储的优化，扩散写写入并发量巨大，另一方面也存在存储浪费，一般优化成扩散读的方式存储&lt;/li&gt;
&lt;li&gt;消息路由到相同接入层机器进行合并请求减少网络包传输&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;101-高可用设计&#34;&gt;10.1 高可用设计&lt;/h4&gt;
&lt;h3 id=&#34;1010-心跳设计&#34;&gt;10.1.0 心跳设计&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;服务端检测到某个客户端迟迟没有心跳过来可以主动关闭通道，让它下线，并且清除在线信息和路由信息；&lt;/li&gt;
&lt;li&gt;客户端检测到某个服务端迟迟没有响应心跳也能重连获取一个新的连接。&lt;/li&gt;
&lt;li&gt;智能心跳策略，比如正在发包的时候，不需要发送心跳。等待发包完毕后在开启心跳。并且自适应心跳策略调整。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;1011-异常场景设计&#34;&gt;10.1.1 异常场景设计&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;gate层重启升级或者意外down机有以下问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;客户端和gate意外丢失长连接，导致 客户端在发送消息的时候导致消息超时等待以及客户端重试等无意义操作&lt;/li&gt;
&lt;li&gt;发送给客户端的消息，从router层转发给gate的消息丢失，导致消息超时等待以及重试。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;解决方案如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;重启升级时候，向客户端发送重新连接指令，让客户端重新请求LSB获取IP直连。&lt;/li&gt;
&lt;li&gt;当gate层down机异常停止时候，增加hook钩子，向客户端发送重新连接指令。&lt;/li&gt;
&lt;li&gt;额外增加hook，向router层发送请求清空路由消息和在线状态&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;1012-系统稳定性设计&#34;&gt;10.1.2 系统稳定性设计&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;背景：高峰期系统压力大，偶发的网络波动或者机器过载，都有可能导致大量的系统失败。加上IM系统要求实时性，不能用异步处理实时发过来的消息。所以有了柔性保护机制防止雪崩&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;柔性保护机制开启判断指标，当每个指标不在平均范围内的时候就开启&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每条消息的ack时间 RT时间&lt;/li&gt;
&lt;li&gt;同时在线人数以及同时发消息的人数&lt;/li&gt;
&lt;li&gt;每台机器的负载CPU和内存和网络IO和磁盘IO以及GC参数&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;当开启了柔性保护机制，那么会返回失败，用户端体验不友好，如何优化&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;当开启了柔性保护机制，逻辑层hold住多余的请求，返回前端成功，不显示发送失败，后端异步重试，直至成功；&lt;/li&gt;
&lt;li&gt;为了避免重试加剧系统过载，指数时间延迟重试&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;11-核心表结构设计&#34;&gt;11. 核心表结构设计&lt;/h3&gt;
&lt;p&gt;核心设计点&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;群消息只存储一份，用户不需要为每个消息单独存一份。用户也无需去删除群消息。&lt;/li&gt;
&lt;li&gt;对于在线的用户，收到群消息后，修改这个last_ack_msg_id。&lt;/li&gt;
&lt;li&gt;对于离线用户，用户上线后，对比最新的消息ID和last_ack_msg_id，来进行拉取(参考Kafka的消费者模型)&lt;/li&gt;
&lt;li&gt;对应单聊，需要记录消息的送达状态，以便在异常情况下来做重试处理&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;用户表-t_user&#34;&gt;用户表 t_user&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;字段&lt;/th&gt;
&lt;th&gt;类型&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;id&lt;/td&gt;
&lt;td&gt;int&lt;/td&gt;
&lt;td&gt;自增ID&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;user_id&lt;/td&gt;
&lt;td&gt;bigint&lt;/td&gt;
&lt;td&gt;用户ID&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;群表-t_group&#34;&gt;群表 t_group&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;字段&lt;/th&gt;
&lt;th&gt;类型&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;id&lt;/td&gt;
&lt;td&gt;int&lt;/td&gt;
&lt;td&gt;自增ID&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;group_id&lt;/td&gt;
&lt;td&gt;int&lt;/td&gt;
&lt;td&gt;群ID&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;creator&lt;/td&gt;
&lt;td&gt;bigint&lt;/td&gt;
&lt;td&gt;创建人&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;群用户表-t_group_user&#34;&gt;群用户表 t_group_user&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;字段&lt;/th&gt;
&lt;th&gt;类型&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;id&lt;/td&gt;
&lt;td&gt;int&lt;/td&gt;
&lt;td&gt;自增ID&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;group_id&lt;/td&gt;
&lt;td&gt;int&lt;/td&gt;
&lt;td&gt;群ID&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;user_id&lt;/td&gt;
&lt;td&gt;bigint&lt;/td&gt;
&lt;td&gt;用户ID&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;join_time&lt;/td&gt;
&lt;td&gt;datetime&lt;/td&gt;
&lt;td&gt;加群时间&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;active_time&lt;/td&gt;
&lt;td&gt;datetime&lt;/td&gt;
&lt;td&gt;活跃时间&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;群用户消息表-t_group_user_msg&#34;&gt;群用户消息表 t_group_user_msg&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;字段&lt;/th&gt;
&lt;th&gt;类型&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;id&lt;/td&gt;
&lt;td&gt;int&lt;/td&gt;
&lt;td&gt;自增ID&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;group_id&lt;/td&gt;
&lt;td&gt;int&lt;/td&gt;
&lt;td&gt;群ID&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;user_id&lt;/td&gt;
&lt;td&gt;bigint&lt;/td&gt;
&lt;td&gt;用户ID&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;last_ack_msg_id&lt;/td&gt;
&lt;td&gt;bigint&lt;/td&gt;
&lt;td&gt;最后一次ack的消息ID&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;user_device_type&lt;/td&gt;
&lt;td&gt;tinyint&lt;/td&gt;
&lt;td&gt;用户设备类型&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;is_deleted&lt;/td&gt;
&lt;td&gt;tinyint&lt;/td&gt;
&lt;td&gt;是否删除,根据这个字段后续可以做冷备归档&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;create_time&lt;/td&gt;
&lt;td&gt;datetime&lt;/td&gt;
&lt;td&gt;创建时间&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;update_time&lt;/td&gt;
&lt;td&gt;datetime&lt;/td&gt;
&lt;td&gt;更新时间&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;群消息表-t_group_msg&#34;&gt;群消息表 t_group_msg&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;字段&lt;/th&gt;
&lt;th&gt;类型&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;id&lt;/td&gt;
&lt;td&gt;int&lt;/td&gt;
&lt;td&gt;自增ID&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;msg_id&lt;/td&gt;
&lt;td&gt;bigint&lt;/td&gt;
&lt;td&gt;消息ID&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;group_id&lt;/td&gt;
&lt;td&gt;int&lt;/td&gt;
&lt;td&gt;群ID&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;sender_id&lt;/td&gt;
&lt;td&gt;bigint&lt;/td&gt;
&lt;td&gt;发送方ID&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;msg_type&lt;/td&gt;
&lt;td&gt;int&lt;/td&gt;
&lt;td&gt;消息类型&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;msg_content&lt;/td&gt;
&lt;td&gt;varchar&lt;/td&gt;
&lt;td&gt;消息内容&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;is_deleted&lt;/td&gt;
&lt;td&gt;tinyint&lt;/td&gt;
&lt;td&gt;是否删除&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;create_time&lt;/td&gt;
&lt;td&gt;datetime&lt;/td&gt;
&lt;td&gt;创建时间&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;update_time&lt;/td&gt;
&lt;td&gt;datetime&lt;/td&gt;
&lt;td&gt;更新时间&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;个人消息表-t_user_msg&#34;&gt;个人消息表 t_user_msg&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;字段&lt;/th&gt;
&lt;th&gt;类型&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;id&lt;/td&gt;
&lt;td&gt;int&lt;/td&gt;
&lt;td&gt;自增ID&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;msg_id&lt;/td&gt;
&lt;td&gt;bigint&lt;/td&gt;
&lt;td&gt;消息ID&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;sender_id&lt;/td&gt;
&lt;td&gt;bigint&lt;/td&gt;
&lt;td&gt;发送方ID&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;receiver_id&lt;/td&gt;
&lt;td&gt;bigint&lt;/td&gt;
&lt;td&gt;接收方ID&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;receiver_device_type&lt;/td&gt;
&lt;td&gt;tinyint&lt;/td&gt;
&lt;td&gt;接收方设备类型&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;msg_type&lt;/td&gt;
&lt;td&gt;int&lt;/td&gt;
&lt;td&gt;消息类型&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;msg_content&lt;/td&gt;
&lt;td&gt;varchar&lt;/td&gt;
&lt;td&gt;消息内容&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;msg_status&lt;/td&gt;
&lt;td&gt;tinyint&lt;/td&gt;
&lt;td&gt;消息状态，已送达和未送达&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;is_deleted&lt;/td&gt;
&lt;td&gt;tinyint&lt;/td&gt;
&lt;td&gt;是否删除&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;create_time&lt;/td&gt;
&lt;td&gt;datetime&lt;/td&gt;
&lt;td&gt;创建时间&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;update_time&lt;/td&gt;
&lt;td&gt;datetime&lt;/td&gt;
&lt;td&gt;更新时间&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;个人会话表-t_conversation&#34;&gt;个人会话表 t_conversation&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;字段&lt;/th&gt;
&lt;th&gt;类型&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;id&lt;/td&gt;
&lt;td&gt;int&lt;/td&gt;
&lt;td&gt;自增ID&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;conversation_id&lt;/td&gt;
&lt;td&gt;int&lt;/td&gt;
&lt;td&gt;会话ID&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;user_id&lt;/td&gt;
&lt;td&gt;bigint&lt;/td&gt;
&lt;td&gt;用户ID&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;conversation_type&lt;/td&gt;
&lt;td&gt;tinyint&lt;/td&gt;
&lt;td&gt;会话类型 1=单聊 2=群聊&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;receiver_id&lt;/td&gt;
&lt;td&gt;bigint&lt;/td&gt;
&lt;td&gt;接收方ID 单聊为个人用户ID 群聊为群ID&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;last_sequence_id&lt;/td&gt;
&lt;td&gt;int&lt;/td&gt;
&lt;td&gt;客户端最新一条消息序号&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;last_msg_id&lt;/td&gt;
&lt;td&gt;bigint&lt;/td&gt;
&lt;td&gt;客户端最新一条消息对应的ID&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;last_msg_receive_time&lt;/td&gt;
&lt;td&gt;datetime&lt;/td&gt;
&lt;td&gt;客户端最新一条消息接收时间&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;is_deleted&lt;/td&gt;
&lt;td&gt;tinyint&lt;/td&gt;
&lt;td&gt;会话是否删除&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;create_time&lt;/td&gt;
&lt;td&gt;datetime&lt;/td&gt;
&lt;td&gt;会话创建时间&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;update_time&lt;/td&gt;
&lt;td&gt;datetime&lt;/td&gt;
&lt;td&gt;更新时间&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;12-核心业务流程&#34;&gt;12 核心业务流程&lt;/h3&gt;
&lt;h4 id=&#34;120-用户a发消息给用户b-单聊&#34;&gt;12.0 用户A发消息给用户B 【单聊】&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;A通过账号密码登录获取token，以及接入层IP和port信息&lt;/li&gt;
&lt;li&gt;接入层IP和port信息进行远程TCP连接，接入层维护登录状态&lt;/li&gt;
&lt;li&gt;服务层校验token，token校验通过&lt;/li&gt;
&lt;li&gt;A打包数据发送给服务端， 服务端检测A用户是否风险用户&lt;/li&gt;
&lt;li&gt;服务端对消息进行敏感词检查，以及发送频率的限制检查&lt;/li&gt;
&lt;li&gt;服务端接收消息后，根据接收消息的sequence_id来进行客户端发送消息的去重，并且生成递增的消息ID，将发送的信息和ID打包一块入库，入库成功后返回ACK，ACK包带上服务端生成的消息ID&lt;/li&gt;
&lt;li&gt;服务端检测接收用户B是否在线，在线直接推送给用户B&lt;/li&gt;
&lt;li&gt;如果没有本地消息ID则存入，并且返回接入层ACK信息；如果有则拿本地sequence_id和推送过来的sequence_id大小对比，并且去重，进行展现时序进行排序展示，并且记录最新一条消息ID。最后返回接入层ack&lt;/li&gt;
&lt;li&gt;服务端接收ACK后，将消息标为已送达&lt;/li&gt;
&lt;li&gt;如果用户B不在线,首先将消息存入库中，然后直接通过手机通知来告知客户新消息到来&lt;/li&gt;
&lt;li&gt;用户B上线后，拿本地最新的消息ID，去服务端拉取所有好友发送给B的消息，考虑到一次拉取所有消息数据量大，通过channel通道来进行分页拉取，将上一次拉取消息的最大的ID，作为请求参数，来请求最新一页的比ID大的数据。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;121-用户a发消息给群g-群聊&#34;&gt;12.1 用户A发消息给群G 【群聊】&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;登录，TCP连接，token校验，名词检查，sequence_id去重，生成递增的消息ID，群消息入库成功返回发送方ACK&lt;/li&gt;
&lt;li&gt;查询群G所有的成员，然后去redis中央存储中找在线状态。离线和在线成员分不同的方式处理&lt;/li&gt;
&lt;li&gt;在线成员：并行发送拉取通知，等待在线成员过来拉取，发送拉取通知包如丢失会有兜底机制&lt;/li&gt;
&lt;li&gt;在线成员过来拉取，会带上这个群标识和上一次拉取群的最小消息ID，服务端会找比这个消息ID大的所有的数据返回给客户端，等待客户端ACK。一段时间没ack继续推送。如果重试几次后没有回ack，那么关闭连接和清除ack等待队列消息&lt;/li&gt;
&lt;li&gt;客户端会更新本地的最新的消息ID，然后进行ack回包。服务端收到ack后会更新群成员的最新的消息ID&lt;/li&gt;
&lt;li&gt;离线成员：发送手机通知栏通知。离线成员上线后，拿本地最新的消息ID，去服务端拉取群G发送给A的消息，通过channel通道来进行分页拉取，每一次请求，会将上一次拉取消息的最大的ID，作为请求参数来拉取消息，这里相当于第二次拉取请求包是作为第一次拉取的ack包。&lt;/li&gt;
&lt;li&gt;分页的情况下，客户端在收到上一页请求的的数据后更新本地的最新的消息ID后，再请求下一页并且带上消息ID。上一页请求的的数据可以当作为ack来返回服务端，避免网络多次交互。服务端收到ack后会更新群成员的最新的消息ID&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;13-红包设计&#34;&gt;13 红包设计&lt;/h3&gt;
&lt;h4 id=&#34;131-抢红包的大致核心逻辑&#34;&gt;13.1 抢红包的大致核心逻辑&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;银行快捷支付，保证账户余额和发送红包逻辑的一致性&lt;/li&gt;
&lt;li&gt;发送红包后，首先计算好红包的个数，个数确定好后，确定好每个红包的金额，存入存储层【这里可以是redis的List或者是队列】方便后续每个人来取&lt;/li&gt;
&lt;li&gt;生成一个24小时的延迟任务，检测红包是否还有钱方便退回&lt;/li&gt;
&lt;li&gt;每个红包的金额需要保证每个红包的的抢金额概率是一致的，算法需要考量&lt;/li&gt;
&lt;li&gt;存入数据库表中后，服务器通过长连接，给群里notify红包消息,供群成员抢红包&lt;/li&gt;
&lt;li&gt;群成员并发抢红包，在第二步中会将每个红包的金额放入一个队列或者其他存储中，群成员实际是来竞争去队列中的红包金额。兜底机制：如果redis挂了，可以重新生成红包信息到数据库中&lt;/li&gt;
&lt;li&gt;取成功后，需要保证红包剩余金额、新插入的红包流水数据、队列中的红包数据以及群成员的余额账户金额一致性。&lt;/li&gt;
&lt;li&gt;这里还需要保证一个用户只能领取一次，并且保持幂等&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;132-红包相关表结构设计&#34;&gt;13.2 红包相关表结构设计&lt;/h4&gt;
&lt;h5 id=&#34;红包表-t_red_package-原则上红包信息和订单支付信息分两个表&#34;&gt;红包表 t_red_package (原则上红包信息和订单支付信息分两个表)&lt;/h5&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;字段&lt;/th&gt;
&lt;th&gt;类型&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;id&lt;/td&gt;
&lt;td&gt;int&lt;/td&gt;
&lt;td&gt;自增ID&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;package_id&lt;/td&gt;
&lt;td&gt;int&lt;/td&gt;
&lt;td&gt;红包ID&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;sender_id&lt;/td&gt;
&lt;td&gt;bigint&lt;/td&gt;
&lt;td&gt;发送用户ID&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;received_id&lt;/td&gt;
&lt;td&gt;bigint&lt;/td&gt;
&lt;td&gt;接收者ID或者群ID&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;type&lt;/td&gt;
&lt;td&gt;tinyint&lt;/td&gt;
&lt;td&gt;1=单聊红包 2=群聊红包&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;package_amount&lt;/td&gt;
&lt;td&gt;bigint&lt;/td&gt;
&lt;td&gt;红包金额, 填充0到分后两位&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;package_lock_amount&lt;/td&gt;
&lt;td&gt;bigint&lt;/td&gt;
&lt;td&gt;红包预占金额&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;package_remaining_amount_&lt;/td&gt;
&lt;td&gt;bigint&lt;/td&gt;
&lt;td&gt;红包剩余金额&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;status&lt;/td&gt;
&lt;td&gt;tinyint&lt;/td&gt;
&lt;td&gt;红包状态，是否支付成功&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;pay_time&lt;/td&gt;
&lt;td&gt;datetime&lt;/td&gt;
&lt;td&gt;支付时间&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;pay_order_no&lt;/td&gt;
&lt;td&gt;datetime&lt;/td&gt;
&lt;td&gt;支付订单号&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;is_deleted&lt;/td&gt;
&lt;td&gt;tinyint&lt;/td&gt;
&lt;td&gt;是否删除&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;create_time&lt;/td&gt;
&lt;td&gt;datetime&lt;/td&gt;
&lt;td&gt;创建时间&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;update_time&lt;/td&gt;
&lt;td&gt;datetime&lt;/td&gt;
&lt;td&gt;更新时间&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h5 id=&#34;抢红包记录表-t_red_package_record&#34;&gt;抢红包记录表 t_red_package_record&lt;/h5&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;字段&lt;/th&gt;
&lt;th&gt;类型&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;id&lt;/td&gt;
&lt;td&gt;int&lt;/td&gt;
&lt;td&gt;自增ID&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;user_id&lt;/td&gt;
&lt;td&gt;int&lt;/td&gt;
&lt;td&gt;用户ID&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;package_id&lt;/td&gt;
&lt;td&gt;int&lt;/td&gt;
&lt;td&gt;红包ID&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;package_rob_amount&lt;/td&gt;
&lt;td&gt;bigint&lt;/td&gt;
&lt;td&gt;抢红包金额&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;status&lt;/td&gt;
&lt;td&gt;tinyint&lt;/td&gt;
&lt;td&gt;红包状态，是否存入零钱账户&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;payment_time&lt;/td&gt;
&lt;td&gt;datetime&lt;/td&gt;
&lt;td&gt;收款时间&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;receive_order_no&lt;/td&gt;
&lt;td&gt;datetime&lt;/td&gt;
&lt;td&gt;收款订单号&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;is_deleted&lt;/td&gt;
&lt;td&gt;tinyint&lt;/td&gt;
&lt;td&gt;是否删除&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;create_time&lt;/td&gt;
&lt;td&gt;datetime&lt;/td&gt;
&lt;td&gt;创建时间&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;update_time&lt;/td&gt;
&lt;td&gt;datetime&lt;/td&gt;
&lt;td&gt;更新时间&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;三-项目结构&#34;&gt;三、项目结构&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;fastim-logic：逻辑服务，比如单聊、群聊、红包、离线等业务逻辑&lt;/li&gt;
&lt;li&gt;fastim-client：客户端逻辑实现，实现发送消息、断线重连、SDK包等功能&lt;/li&gt;
&lt;li&gt;fastim-gate-tcp：HTTP API网关实现，实现限流降级、版本路由、openAPI管理、协议转换、泛化调用等功能&lt;/li&gt;
&lt;li&gt;fastim-gate-http：长连接TCP网关实现，实现自定义协议、channel管理、心跳检测、泛化调用等功能&lt;/li&gt;
&lt;li&gt;fastim-leaf：分布式ID实现，基于zookeeper的实现或基于redis实现或完全基于内存的实现&lt;/li&gt;
&lt;li&gt;fastim-router：路由逻辑服务，主要负责消息的路由转发，以及客户端在线状态的维护&lt;/li&gt;
&lt;li&gt;fastim-common：共用类，主要是实体类和工具类的存放&lt;/li&gt;
&lt;li&gt;fastim-lsb：LSB service，提供接入层IP和port来进行负载均衡的连接&lt;/li&gt;
&lt;li&gt;fastim-das：数据访问层实现，封装一层，提供数据的增删改查入口&lt;/li&gt;
&lt;li&gt;fastim-sample：客户端client使用案例&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;四-性能测试&#34;&gt;四、性能测试&lt;/h2&gt;
&lt;h2 id=&#34;五-qa&#34;&gt;五、Q&amp;amp;A&lt;/h2&gt;
&lt;h3 id=&#34;1-架构&#34;&gt;1 架构&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Q：对于单聊和群聊的实时性消息，是否需要MQ来作为通信的中间件来代替rpc？&lt;/p&gt;
&lt;p&gt;A：MQ作为解耦可以有以下好处：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;易扩展，gate层到logic层无需路由，logic层多个有新的业务时候，只需要监听新的topic即可&lt;/li&gt;
&lt;li&gt;解耦，gate层到logic层解耦，不会有依赖关系&lt;/li&gt;
&lt;li&gt;节省端口资源，gate层无需再开启新的端口接收logic的请求，而且直接监听MQ消息即可&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;但是缺点也有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;网络通信多一次网络通信，增加RT的时间，消息实时性对于IM即使通信的场景是非常注重的一个点&lt;/li&gt;
&lt;li&gt;MQ的稳定性，不管任何系统只要引入中间件都会有稳定性问题，需要考虑MQ不可用或者丢失数据的情况&lt;/li&gt;
&lt;li&gt;需要考虑到运维的成本&lt;/li&gt;
&lt;li&gt;当用消息中间代替路由层的时候，gate层需要广播消费消息，这个时候gate层会接收大部分的无效消息，因为这个消息的接收者channel不在本机维护的session中&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;综上，是否考虑使用MQ需要架构师去考量，比如考虑业务是否允许、或者系统的流量等等影响因素。&lt;br&gt;
本项目基于使用成本、耦合成本和运维成本考虑，采用RPC的方案来实现。并且根据泛化调用，也能同样实现层级解耦。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Q：架构设计为什么要增加router层？上行消息gate层为什么直接访问service，而下行消息service则需要经过router和Kafka来跟gate通信？&lt;/p&gt;
&lt;p&gt;A：增加router层的目的是根据路由全局信息将通知包或者推送包路由到具体的某一台接入层的机器上，然后router层通过rpc或者MQ发送到gate层，gate发送数据到客户端来进行通信。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Q：为什么接入层用LSB返回的IP来做接入呢？&lt;/p&gt;
&lt;p&gt;A：可以有以下好处：1、灵活的负载均衡策略 可根据最少连接数来分配IP；2、做灰度策略来分配IP；3、AppId业务隔离策略 不同业务连接不同的gate，防止相互影响&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Q：为什么应用层心跳对连接进行健康检查？&lt;/p&gt;
&lt;p&gt;A：因为TCP Keepalive状态无法反应应用层状态问题，如进程阻塞、死锁、TCP缓冲区满等情况；并且要注意心跳的频率，频率小则可能及时感知不到应用情况，频率大可能有一定的性能开销。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Q：MQ的使用场景？&lt;/p&gt;
&lt;p&gt;A：IM消息是非常庞大的，比如说群聊相关业务、推送，对于一些业务上可以忍受的场景，尽量使用MQ来解耦和通信，来降低同步通讯的服务器压力。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Q：群消息存一份还是多份，读扩散还是写扩散？&lt;/p&gt;
&lt;p&gt;A：存1份，读扩散。存多份下同一条消息存储了很多次，对磁盘和带宽造成了很大的浪费。可以在架构上和业务上进行优化，来实现读扩散。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Q：消息ID为什么是趋势递增就可以，严格递增的不行吗？&lt;/p&gt;
&lt;p&gt;A：严格递增会有单点性能瓶颈，比如MySQL auto increments；redis性能好但是没有业务语义，比如缺少时间因素，还可能会有数据丢失的风险，并且集群环境下写入ID也属于单点，属于集中式生成服务。小型IM可以根据业务场景需求直接使用redis的incr命令来实现IM消息唯一ID。本项目采用snowflake算法实现唯一趋势递增ID，即可实现IM消息中，时序性，重复性以及查找功能。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Q：为什么gate层泛化调用logic层，router层泛化调用gate层？&lt;/p&gt;
&lt;p&gt;A：gate层直接调用logic层，不需要调用router层，减少网络传输和RT时间，增加一个服务,就多了一条链路, 就可能会导致服务链路过长,稳定性下降。泛化调用的目的是解耦网关和服务，使其不相互影响。router层泛化调用gate层，目的也是解耦gate层和router层，防止各自层级机器扩容缩容重启升级等场景下互相影响，并且router需要具体调用某一台gate层机器，泛化刚好能实现。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Q：gate层为什么需要开两个端口？&lt;/p&gt;
&lt;p&gt;A：gate会接收客户端的连接请求（被动），需要外网监听端口；entry会主动给logic发请求（主动）；entry会接收router给它的通知请求（被动），需要内网监听端口。一个端口对内，一个端口对外。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Q：用户的在线状态，是维护在中央存储的redis中，还是维护在每个gate层内存中？&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;A：如果维护在每个gate层内存的话，router层无法知晓目标的用户会话在哪个gate层，只能通过MQ或者广播到gate层，然后gate层做过滤处理。这种处理方式的缺点就是会多消耗网络资源，好处也明显，不需要中央维护资源，高并发查询下会增加性能。如果维护在中央存储的话，相比各自存储不需要消耗太多的网络资源，但缺点就是需要维护中央存储的redis&lt;/p&gt;
&lt;h3 id=&#34;2-技术细节&#34;&gt;2 技术细节&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Q：本地写数据成功，一定代表对端应用侧接收读取消息了吗？&lt;/p&gt;
&lt;p&gt;A：本地TCP写操作成功，但数据可能还在本地写缓冲区中、网络链路设备中、对端读缓冲区中，并不代表对端应用读取到了数据。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Q：为什么用netty做来做http网关, 而不用tomcat？&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;netty对象池，内存池，高性能线程模型&lt;/li&gt;
&lt;li&gt;netty堆外内存管理，减少GC压力，jvm管理的只是一个很小的DirectByteBuffer对象引用&lt;/li&gt;
&lt;li&gt;tomcat读取数据和写入数据都需要从内核态缓冲copy到用户态的JVM中，多1次或者2次的拷贝会有性能影响&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Q：为什么消息入库后，对于在线状态的用户，单聊直接推送，群聊通知客户端来拉取，而不是直接推送消息给客户端（推拉结合）？&lt;/p&gt;
&lt;p&gt;A：在保证消息实时性的前提下，对于单聊，直接推送。对于群聊，由于群聊人数多，推送的话一份群消息会对群内所有的用户都产生一份推送的消息，推送量巨大。解决办法是按需拉取，当群消息有新消息时候发送时候，服务端主动推送新的消息数量，然后客户端分页按需拉取数据。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Q：为什么除了单聊 群聊 推送 离线拉取等实时性业务，其他的业务都走http协议？&lt;/p&gt;
&lt;p&gt;A：IM协议简单最好，如果让其他的业务请求混进IM协议中，会让其IM变的更复杂，比如查找离线消息记录拉取走http通道避免tcp 通道压力过大，影响即时消息下发效率。在比如上传图片和大文件，可以利用HTTP的断点上传和分段上传特性&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;六-contact&#34;&gt;六、Contact&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;网站：zhangyaoo.github.io&lt;/li&gt;
&lt;li&gt;微信：will_zhangyao&lt;/li&gt;
&lt;/ul&gt;
">基于Netty即时通讯系统设计与实现</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://zhangyaoo.github.io/post/netty-wei-he-xing-neng-zhe-me-gao/"" data-c="
          &lt;h2 id=&#34;线程模型&#34;&gt;线程模型&lt;/h2&gt;
&lt;p&gt;内存模型：&lt;br&gt;
锁模型：&lt;br&gt;
网络IO模型：&lt;br&gt;
零拷贝：&lt;br&gt;
内存池：&lt;br&gt;
堆外内存：不受堆内存的大小的影响，JVM内存持有堆外内存的引用，好处是不受GC停顿带来的影响。堆外内存基于引用计数来进行回收&lt;br&gt;
其他：自建FastThreadLocal，基本类型代替引用类型，海量对象场景类FieldUpdater对象代替原子类，IntObjectMap代替HashMap，wrappedBuf避免内存复制，内建多种序列化方式，多种粘包和半包处理和自定义处理&lt;/p&gt;
">Netty为何性能这么高</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://zhangyaoo.github.io/post/jie-gou-hua-si-wei/"" data-c="
          &lt;h3 id=&#34;what&#34;&gt;what：&lt;/h3&gt;
&lt;p&gt;是一种以无序到有序的整理信息和构建结构化的思维方式，目的是减少认知复杂度，是的更加被容易理解和记忆，表达清晰&lt;/p&gt;
&lt;h3 id=&#34;why&#34;&gt;why:&lt;/h3&gt;
&lt;p&gt;0213645879 和 0123456789，这两串数字哪个更容易被人记住。&lt;br&gt;
当然是按照顺序排列的数字串比杂乱无序排列的要更容易被记住。&lt;br&gt;
因为人类更容易记住结构化的信息。&lt;/p&gt;
&lt;h3 id=&#34;how&#34;&gt;how：&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1627012568883.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
塔尖就是我们的中心思想或主题。塔身就是构成中心思考或者主题的各个分论点。而塔基则是支撑各个分论点的要素或论据&lt;/p&gt;
&lt;p&gt;1、综上而下的结构化思维&lt;br&gt;
纵向是自上而下的层次的关系，下一层是上一层的解释和构成，上一层是下一层的总结和概括&lt;br&gt;
比如，先给结论后给原因，先目的后方法，先抽象后具体，先整体后部分&lt;br&gt;
2、从左往右的顺序思维，在同一个组内必须是同一个逻辑范畴，按照顺序来组织&lt;/p&gt;
&lt;h4 id=&#34;具体的步骤&#34;&gt;具体的步骤：&lt;/h4&gt;
&lt;p&gt;1、确定问题产生背景&lt;br&gt;
2、确定核心目标&lt;br&gt;
3、拆解核心目标&lt;br&gt;
4、继续分解，直到能够把问题解释清楚，形成方法论&lt;/p&gt;
&lt;h3 id=&#34;example&#34;&gt;example&lt;/h3&gt;
&lt;h4 id=&#34;1-采购清单&#34;&gt;1、采购清单&lt;/h4&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1627012578248.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h4 id=&#34;2-带团队&#34;&gt;2、带团队&lt;/h4&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1627012581164.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h4 id=&#34;3-事情划分方法&#34;&gt;3、事情划分方法&lt;/h4&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;3&#34;&gt;&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1627012584884.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
">浅谈结构化思维</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://zhangyaoo.github.io/post/hikaridatasource-he-xin-yuan-ma-fen-xi/"" data-c="
          &lt;h2 id=&#34;一-前言&#34;&gt;一、前言&lt;/h2&gt;
&lt;p&gt;上一篇文章讲了不合理的连接池代码导致的内存泄露事件，详见这篇文章&lt;a href=&#34;https://zhangyaoo.github.io/post/ji-yi-ci-duo-shu-ju-yuan-lu-you-zao-cheng-de-shu-ju-ku-lian-jie-nei-cun-xie-lu/&#34;&gt;记一次多数据源路由造成的数据库连接泄露排查过程&lt;/a&gt;。其中粗略的分析了HikariDataSource连接池的代码，并没有仔细分析。本篇文章带读者们一起去分析一波源码，看完本篇文章后，你可以&lt;br&gt;
1、对锁和高并发有一定理解以及其在连接池中的运用&lt;br&gt;
2、了解HikariDataSource业界性能最高连接池的原因&lt;br&gt;
3、可以对连接池的原理有大致的了解，可以尝试自己实现一个连接池&lt;/p&gt;
&lt;h2 id=&#34;二-源码分析&#34;&gt;二、源码分析&lt;/h2&gt;
&lt;h3 id=&#34;20-关键代码类介绍&#34;&gt;2.0 关键代码类介绍&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;HikariDataSource对象：Hikari中的核心类为HikariDataSource，实现了DataSource的getConnetion接口&lt;/li&gt;
&lt;li&gt;HikariPool对象：HikariDataSource中有两个HikariPool对象,一个是fastPathPool是在HikariPool有参构造函数中创建, 如果没有创建fastPathPool,那么就会在getConnection方法时创建pool对象。&lt;/li&gt;
&lt;li&gt;ConcurrentBag对象：连接池的真正实现，实现了&lt;strong&gt;高性能高并发的无锁设计&lt;/strong&gt;，主要的方法有borrow 借,requite 归还,add 新增,remove 去除。&lt;/li&gt;
&lt;li&gt;PoolEntry对象：对数据库connection对象进行包装，增加额外的属性，包括最后一次访问时间，是否丢弃，当前状态等等。HikariDataSource源码底层里面都是操作这个对象。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;21-初始化以下所有代码只列出关键实现&#34;&gt;2.1 初始化（以下所有代码只列出关键实现）&lt;/h3&gt;
&lt;p&gt;初始化工作包括HikariDataSource初始化，HikariPool初始化，connectionBag初始化，一些线程池的初始化，最小连接数的初始化，以下逐一分析&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public HikariDataSource(HikariConfig configuration)
{
  // 一个datasource有两个HikariPool成员变量，fastPathPool无参构造为null，用final修饰，pool有参构造，用volatile修饰
  // 因为volatile修饰的对象，需要从主内存读取，而且需要写入主内存等操作，所以最好在使用上用有参构造来构造HikariDataSource
  pool = fastPathPool = new HikariPool(this);
  // 连接池配置锁定无法修改
  this.seal();
}
// HikariPool初始化成员变量EntryCreator，创建PoolEntry的任务
private final PoolEntryCreator postFillPoolEntryCreator = new PoolEntryCreator(&amp;quot;After adding &amp;quot;);

public HikariPool(final HikariConfig config)
{
  // 初始化配置，根据配置生成datasource变量
  super(config);
  // 生成真正的连接池，后续的获取连接释放连接都是从这里面弄的
  this.connectionBag = new ConcurrentBag&amp;lt;&amp;gt;(this);
  // 测试数据库的连通性
  checkFailFast();
  // 增加连接的线程池
  this.addConnectionExecutor = createThreadPoolExecutor(addConnectionQueue, poolName + &amp;quot; connection adder&amp;quot;, threadFactory, new ThreadPoolExecutor.DiscardOldestPolicy());
  // 关闭连接的线程池
  this.closeConnectionExecutor = createThreadPoolExecutor(maxPoolSize, poolName + &amp;quot; connection closer&amp;quot;, threadFactory, new ThreadPoolExecutor.CallerRunsPolicy());
  // 初始化维持最小连接数任务
  this.houseKeeperTask = houseKeepingExecutorService.scheduleWithFixedDelay(new HouseKeeper(), 100L, housekeepingPeriodMs, MILLISECONDS);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;重点是维持最小连接数任务，如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;private final class HouseKeeper implements Runnable{
  public void run(){
     // Detect retrograde time, allowing +128ms as per NTP spec.
    if (plusMillis(now, 128) &amp;lt; plusMillis(previous, housekeepingPeriodMs)) {
       previous = now;
       // 标为丢弃的连接关闭
       softEvictConnections();
       return;
    }
    if (idleTimeout &amp;gt; 0L &amp;amp;&amp;amp; config.getMinimumIdle() &amp;lt; config.getMaximumPoolSize()) {
       // 获取当前连接池中已经不是使用中的连接集合
       final List&amp;lt;PoolEntry&amp;gt; notInUse = connectionBag.values(STATE_NOT_IN_USE);
       int toRemove = notInUse.size() - config.getMinimumIdle();
       for (PoolEntry entry : notInUse) {
          // 如果PoolEntry的最后一次访问的时间超过了idleTimeout并且将这个PoolEntry的状态变为不可借状态STATE_RESERVED
          // STATE_RESERVED状态底层变更是CAS变更，用到的类是AtomicIntegerFieldUpdater，可以对指定类的指定 volatile int 字段进行原子更新
          if (toRemove &amp;gt; 0 &amp;amp;&amp;amp; elapsedMillis(entry.lastAccessed, now) &amp;gt; idleTimeout &amp;amp;&amp;amp; connectionBag.reserve(entry)) {
             // 关闭连接
             closeConnection(entry, &amp;quot;(connection has passed idleTimeout)&amp;quot;);
             toRemove--;
          }
       }
    }
    // 填充最小连接到minimum。 在初始化时候就填充连接，异步填充
    fillPool();
  }
}
// 填充连接
// 当没有达到最大连接数之前 或者 空闲连接数小于最小连接数时候 就异步提交创建poolEntryCreator任务
private synchronized void fillPool(){
  final int connectionsToAdd = Math.min(config.getMaximumPoolSize() - getTotalConnections(), config.getMinimumIdle() - getIdleConnections())
                               - addConnectionQueueReadOnlyView.size();
  for (int i = 0; i &amp;lt; connectionsToAdd; i++) {
     addConnectionExecutor.submit((i &amp;lt; connectionsToAdd - 1) ? poolEntryCreator : postFillPoolEntryCreator);
  }
}

// 关闭连接
void closeConnection(final PoolEntry poolEntry, final String closureReason){
    // 如果remove成功，将状态设置为STATE_REMOVED
	if (connectionBag.remove(poolEntry)) {
     final Connection connection = poolEntry.close();
     // 异步关闭
     closeConnectionExecutor.execute(() -&amp;gt; {
        quietlyCloseConnection(connection, closureReason);
        if (poolState == POOL_NORMAL) {
           fillPool();
        }
     });
  }
}

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;以上大致逻辑就是，将被标为丢弃的连接关闭，将空闲超时的连接进行关闭，然后进行进连接填充连接，填充连接的逻辑就是增加poolEntryCreator任务,poolEntryCreator逻辑在后面分析。&lt;/p&gt;
&lt;h3 id=&#34;22-获取连接&#34;&gt;2.2 获取连接&lt;/h3&gt;
&lt;p&gt;获取连接是主要的实现逻辑，首先看HikariDataSource对象getConnnection方法&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;// 双重锁实现
public Connection getConnection(){
	HikariPool result = pool;
	if (result == null) {
	 synchronized (this) {
	    result = pool;
	    if (result == null) {
	       pool = result = new HikariPool(this);
	       // 锁定配置，不能热更新配置
	       this.seal();
	    }
	 }
	}
	return result.getConnection();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;result.getConnection()就是HikariPool getConnection方法，这里面大致核心逻辑就是加锁在超时时间内获取poolEntry的connectionBag.borrow方法，重点着重borrow方法实现。&lt;/p&gt;
&lt;p&gt;在讲之前，先介绍以下connectionBag的几个重要的成员变量&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;final CopyOnWriteArrayList&lt;T&gt; sharedList：当前所有缓存的poolEntry连接，都在这个list内，CopyOnWriteArrayList写时复制，在读多写少的场景下性能更高，一般情况下连接池中的poolEntry连接不会增加或者关闭，读场景多。&lt;/li&gt;
&lt;li&gt;final ThreadLocal&amp;lt;List&lt;Object&gt;&amp;gt; threadList ：当前线程缓存的本地poolEntry的list。朝生夕灭的线程，是无法有效利用本地线程缓存的，只有在线程池场景或者当前线程多次使用getConnetion获取connection方法进行增删改时候，才会有效的使用ThreadLocal。&lt;/li&gt;
&lt;li&gt;final boolean weakThreadLocals：是否是弱引用，ThreadLocal可能会存在内存泄露的风险，当值为true时包装的poolEntry对象是弱引用，在内存不足时GC的时候会被回收，避免了出现内存泄露的问题。&lt;/li&gt;
&lt;li&gt;final IBagStateListener listener：监听器，监听创建poolEntry的任务&lt;/li&gt;
&lt;li&gt;final AtomicInteger waiters：当前正在等待获取连接的数量&lt;/li&gt;
&lt;li&gt;final SynchronousQueue&lt;T&gt; handoffQueue：无存储元素的单个提供者和消费者通信队列，并且是公平模式。比如，是谁先来take操作，谁就会优先take成功，类似FIFO。&lt;/li&gt;
&lt;li&gt;this.threadList = ThreadLocal.withInitial(() -&amp;gt; new FastList&amp;lt;&amp;gt;(IConcurrentBagEntry.class, 16))：默认情况下会ThreadLocal value默认使用fastList来存储poolEntry，fastList是Hikari自己写一个不需要范围检查的一个List，而且它的remove方法是从后往前遍历删除的（和arrayList相反），刚好符合下面倒叙遍历获取poolEntry的逻辑&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public T borrow(long timeout, final TimeUnit timeUnit) throws InterruptedException
   {
      // Try the thread-local list first
      // 1、优先从本地线程缓存中获取poolEntry
      final List&amp;lt;Object&amp;gt; list = threadList.get();
      // 倒叙遍历，优先获取最近使用的poolEntry
      for (int i = list.size() - 1; i &amp;gt;= 0; i--) {
         final Object entry = list.remove(i);
         // 开启弱引用就对value进行弱引用包装
         final T bagEntry = weakThreadLocals ? ((WeakReference&amp;lt;T&amp;gt;) entry).get() : (T) entry;
         // CAS成功就返回poolEntry
         if (bagEntry != null &amp;amp;&amp;amp; bagEntry.compareAndSet(STATE_NOT_IN_USE, STATE_IN_USE)) {
            return bagEntry;
         }
      }

      // Otherwise, scan the shared list ... then poll the handoff queue
      // 2、本地缓存没有，那么从所有缓存的poolEntry连接列表中获取
      final int waiting = waiters.incrementAndGet();
      try {
         for (T bagEntry : sharedList) {
            if (bagEntry.compareAndSet(STATE_NOT_IN_USE, STATE_IN_USE)) {
               // If we may have stolen another waiter&#39;s connection, request another bag add.
               // 如果等待的任务大于1，添加一个监听任务
               if (waiting &amp;gt; 1) {
                  listener.addBagItem(waiting - 1);
               }
               return bagEntry;
            }
         }

         // 如果sharedList都在使用状态中，添加一个监听任务
         listener.addBagItem(waiting);

		 // 3、所有的连接正在被使用，超时等待其他poolEntry被归还通知handoffQueue
         timeout = timeUnit.toNanos(timeout);
         do {
            final long start = currentTime();
            // 从阻塞队列中获取bagEntry
            final T bagEntry = handoffQueue.poll(timeout, NANOSECONDS);
            if (bagEntry == null || bagEntry.compareAndSet(STATE_NOT_IN_USE, STATE_IN_USE)) {
               return bagEntry;
            }

            timeout -= elapsedNanos(start);
         } while (timeout &amp;gt; 10_000);
         return null;
      }finally {
         waiters.decrementAndGet();
      }
   }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;以上具体实现步骤&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;优先从本地线程缓存中获取poolEntry&lt;/li&gt;
&lt;li&gt;本地缓存没有，那么从所有缓存的poolEntry连接列表中获取&lt;/li&gt;
&lt;li&gt;所有的连接正在被使用，增加一个监听任务，这个任务就是异步创建poolEntry，以便给此次阻塞的线程提供poolEntry&lt;/li&gt;
&lt;li&gt;超时等待其他poolEntry被归还或者新建后 通知handoffQueue，以便获取poolEntry&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;可以总结出，Hikari连接池最大限度上减少多线程锁竞争，提升连接池的性能。&lt;/p&gt;
&lt;p&gt;然后看一下异步创建poolEntry poolEntryCreator的实现：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;private final class PoolEntryCreator implements Callable&amp;lt;Boolean&amp;gt; {
  @Override
  public Boolean call()
  {
     // 只有特定条件下才创建PoolEntry
     while (poolState == POOL_NORMAL &amp;amp;&amp;amp; shouldCreateAnotherConnection()) {
        // 创建PoolEntry
        final PoolEntry poolEntry = createPoolEntry();
        if (poolEntry != null) {
           // 在连接池中增加PoolEntry
           connectionBag.add(poolEntry);
           return Boolean.TRUE;
        }
     }

     // Pool is suspended or shutdown or at max size
     return Boolean.FALSE;
  }

  // 1、总的连接数小于最大连接数 
  // 2、当前连接池中的等待获取连接的线程大于0  或者 连接池中的空闲连接小于最小连接池数
  // 满足所有上述条件后才创建poolEntry
  private synchronized boolean shouldCreateAnotherConnection() {
     return getTotalConnections() &amp;lt; config.getMaximumPoolSize() &amp;amp;&amp;amp;
        (connectionBag.getWaitingThreadCount() &amp;gt; 0 || getIdleConnections() &amp;lt; config.getMinimumIdle());
  }
}

// 真正创建poolEntry的实现
private PoolEntry createPoolEntry(){
  try {
      // 创建poolEntry
     final PoolEntry poolEntry = newPoolEntry();

     final long maxLifetime = config.getMaxLifetime();
     if (maxLifetime &amp;gt; 0) {
        // variance up to 2.5% of the maxlifetime
        final long variance = maxLifetime &amp;gt; 10_000 ? ThreadLocalRandom.current().nextLong( maxLifetime / 40 ) : 0;
        final long lifetime = maxLifetime - variance;
        // 如果配置了maxlifetime，那么会给这一个连接增加一个延迟任务
        // 延迟任务主要就是将这个连接标记为Evict不可用
        poolEntry.setFutureEol(houseKeepingExecutorService.schedule(
           () -&amp;gt; {
              if (softEvictConnection(poolEntry, &amp;quot;(connection has passed maxLifetime)&amp;quot;, false /* not owner */)) {
                 addBagItem(connectionBag.getWaitingThreadCount());
              }
           },
           lifetime, MILLISECONDS));
     }
     return poolEntry;
  }
  return null;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;由上面createPoolEntry可以知道，HikariCP在使用时不会关闭连接。如果使用中的连接到达maxLifetime时它将被标记为驱逐，并且在下一次线程尝试借用它时将被驱逐，这也是Hikari连接池设计的一个核心精髓。&lt;/p&gt;
&lt;p&gt;再来看一下connectionBag的add方法&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public void add(final T bagEntry){
      // 在sharedList增加bagEntry
      sharedList.add(bagEntry);
      // spin until a thread takes it or none are waiting
      // 满足一下条件后，让出当前线程CPU时间片，让其他线程去工作
      // 1、当等待获取连接的线程大于0  2、当前的PoolEntry状态是没占用  3、没有其他线程去从队列中取任务
      while (waiters.get() &amp;gt; 0 &amp;amp;&amp;amp; bagEntry.getState() == STATE_NOT_IN_USE &amp;amp;&amp;amp; !handoffQueue.offer(bagEntry)) {
         Thread.yield();
      }
   }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;可以看到，新增的poolEntry会加入到sharedList所有的缓存连接中，并且要满足上述三个条件的时候会一直循环让出CPU时间片，让其他线程从无界队列中去取连接&lt;/p&gt;
&lt;h3 id=&#34;23-释放连接&#34;&gt;2.3 释放连接&lt;/h3&gt;
&lt;p&gt;Hikari实现了关闭连接Connection的方法，不是真正的关闭连接，而是归还到连接池当中，实现逻辑在ProxyConnection的close方法中，然后会调用poolEntry的recycle方法，最终会调用ConcurrentBag的requite方法，我们着重分析这个方法：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;// 此方法会将借来的对象返回到ConcurrentBag中。如果不归还会导致内存泄露
public void requite(final T bagEntry){
  // 设置为未使用状态以便其他线程获取连接
  bagEntry.setState(STATE_NOT_IN_USE);
  for (int i = 0; waiters.get() &amp;gt; 0; i++) {
     // 传递信号给队列，优先告诉其他阻塞等待获取的线程获取poolEntry
     if (bagEntry.getState() != STATE_NOT_IN_USE || handoffQueue.offer(bagEntry)) {
        return;
     }
     // 循环多次后，等待阻塞10纳秒
     else if ((i &amp;amp; 0xff) == 0xff) {
        parkNanos(MICROSECONDS.toNanos(10));
     }
     else {
        // 让出时间片
        Thread.yield();
     }
  }

  // 更新最新poolEntry的本地线程的缓存中，以便当前线程下次获取连接
  final List&amp;lt;Object&amp;gt; threadLocalList = threadList.get();
  if (threadLocalList.size() &amp;lt; 50) {
     // 对应上文中的fastList, 每次新增都是放到数组最后面
     threadLocalList.add(weakThreadLocals ? new WeakReference&amp;lt;&amp;gt;(bagEntry) : bagEntry);
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;最后我们分析以下remove方法，很简单&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public boolean remove(final T bagEntry)
   {
      if (!bagEntry.compareAndSet(STATE_IN_USE, STATE_REMOVED) &amp;amp;&amp;amp; !bagEntry.compareAndSet(STATE_RESERVED, STATE_REMOVED) &amp;amp;&amp;amp; !closed) {
         LOGGER.warn(&amp;quot;Attempt to remove an object from the bag that was not borrowed or reserved: {}&amp;quot;, bagEntry);
         return false;
      }
      // 从所有缓存的list去除
      final boolean removed = sharedList.remove(bagEntry);
      // 从当前本地线程缓存中去除
      threadList.get().remove(bagEntry);
      return removed;
   }

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;什么时候会调用remove，笔者总结了以下：&lt;br&gt;
1、当调用datasource shutdown方法时候&lt;br&gt;
2、当前connetion没有用的时候（可能是MySQL服务器down机）&lt;br&gt;
3、当前conntion被标记为丢弃时候，超过了maxLifetime被标记为丢弃&lt;br&gt;
4、当前connetion的最后一次使用时间和当前时间的差值大于idleTimeout时候&lt;/p&gt;
&lt;p&gt;以上可以理解了从初始化到getConnection获取连接，到closeConnectiond的核心逻辑，实现了核心逻辑的小闭环。&lt;/p&gt;
&lt;h2 id=&#34;三-自己写个连接池需要考虑哪些方面&#34;&gt;三、自己写个连接池需要考虑哪些方面&lt;/h2&gt;
&lt;p&gt;根据上面分析的源码，可以看到，如果自己实现一个连接池的话，需要考虑：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;初始化的步骤，初始化最初的最小空闲数连接&lt;/li&gt;
&lt;li&gt;取连接，从连接池中取，并且要上锁&lt;/li&gt;
&lt;li&gt;归还连接，需要放回到连接池中，要上锁&lt;/li&gt;
&lt;li&gt;如果连接池全被占用，是返回失败，还是让上游等待&lt;/li&gt;
&lt;li&gt;拿到的连接，需要检测这个连接是否可用，是否还是活的，因为不知道服务端是否挂掉，抑或是连接超过maxlife被标记为evit正在关闭&lt;/li&gt;
&lt;li&gt;连接池用什么数据结构存储，数组还是链表，还要考虑并发安全&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;四-总结&#34;&gt;四、总结&lt;/h2&gt;
&lt;p&gt;本篇文章从源码角度分析了一波，明白了为什么HikariDataSource是业界性能最高连接池的原因。我们可以更深入理解连接池背后的工作原理，以便后面出了线上问题可以轻松应对。最后读者可以试试自己实现一个连接池加深理解。&lt;br&gt;
以上文章有任何表达上或者技术问题欢迎指正。&lt;/p&gt;
&lt;h2 id=&#34;四-参考&#34;&gt;四、参考&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;数据库连接池之Hikari源码解析——https://www.cnblogs.com/jackion5/p/14193025.html&lt;/li&gt;
&lt;/ol&gt;
">HikariDataSource核心源码分析</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://zhangyaoo.github.io/post/ji-yi-ci-duo-shu-ju-yuan-lu-you-zao-cheng-de-shu-ju-ku-lian-jie-nei-cun-xie-lu/"" data-c="
          &lt;h3 id=&#34;前言&#34;&gt;前言&lt;/h3&gt;
&lt;p&gt;之前一篇文章讲了自己写了一个多数据源路由组件给公司内部使用，进行快速迭代。文章URL是 &lt;a href=&#34;https://zhangyaoo.github.io/post/saas-xi-tong-duo-shu-ju-yuan-lu-you-you-ya-jie-jue-fang-an&#34;&gt;SaaS系统多数据源路由优雅解决方案&lt;/a&gt;&lt;br&gt;
随着时间推移，某一天运维找上门说数据库连接打满，就刚好这一台机器上装了Java服务导致的。&lt;br&gt;
下面文章就是讲的这次连接泄露导致的数据库hang住问题以及后面的解决过程。&lt;/p&gt;
&lt;h3 id=&#34;一-案发当时的情况&#34;&gt;一、案发当时的情况：&lt;/h3&gt;
&lt;p&gt;线上MySQL session 逐渐增加，不活跃的的数量逐渐增加，导致的后果：占用链接，导致链接满了无法分配新的连接&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1612261925869.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;二-紧急处理方式&#34;&gt;二、紧急处理方式：&lt;/h3&gt;
&lt;p&gt;用自研的应用层网关将流量切换为旧的版本中，并且不停机切换，然后将当前的版本的服务停调，然后观察阿里云的数据库连接数量变回正常。&lt;/p&gt;
&lt;p&gt;目前线上存在多个版本存在docker，然后用K8s部署，实现快速不停机切换上线。&lt;br&gt;
自研网关这篇文章有介绍： &lt;a href=&#34;https://zhangyaoo.github.io/post/ying-yong-ceng-wang-guan-she-ji-yu-shi-xian&#34;&gt;应用层网关设计和实现&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;三-第一次查找问题并且解决的过程&#34;&gt;三、第一次查找问题并且解决的过程：&lt;/h3&gt;
&lt;p&gt;1、开启本地服务，让它飞一会，或者多线程并且切租户查询数据库，dump内存快照进行分析&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1612253583270.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;p&gt;2、然后查看本地服务相关数据库连接的对象&lt;br&gt;
1）分析sqlsession 对象，发现sqlsession对象为0，而且日志中有打印及时关闭sqlsession。结论：sqlsession正常，说明正常关闭了sqlsession&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1612237357285.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
2）分析datasource 对象，发现datasource对象和数据库连接配置中的max-pool-size一致。结论：datasource正常，说明正常关闭了datasource&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1612237380060.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
3）分析connection对象，发现HikariProxyConnection对象和数据库配置一致。结论：HikariProxyConnection正常&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1612237411657.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;p&gt;3、在分析本地内存快照，发现一个类随着时间的推移，逐渐增多，并且没有被回收，正是connectionImpl对象，这个对象是MySQL底层连接的实现，来自com.mysql.cj.jdbc&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1612237433473.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
（图片中指的类有100多个对象）&lt;/p&gt;
&lt;p&gt;4、跟踪了一波源码，发现HikariProxyConnection对象，实质上底层就是new了一个并管理connectionImpl对象，猜测某个因为参数原因导致HikariProxyConnection及时释放，而connectionImpl没有释放，积累没有及时清除导致的。&lt;/p&gt;
&lt;p&gt;5、经过Google查找问题，怀疑是max_lifetime导致的问题。max_lifetime官网解释：一个连接的生命时长（毫秒），超时而且没被使用则被释放（retired）。建议比数据库的wait_timeout小几分钟。默认30分钟&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1612237640791.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;p&gt;6、查看线上配置和测试环境配置，果然是只配置了1分钟。&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1612262047685.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
随后将其改成30分钟，然后继续多线程并发跑测试用例。测试环境验证，dump内存，观察connectionImpl对象并没有随着时间的推移增加。发现connectionImpl对象并没有随着时间的推移增加。验证了个人的猜想。&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1612237699007.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;p&gt;7、最终将配置更新后上线，过了没2个小时，连接数又飙升。初步观察还是connectionImpl对象增多，连接没有释放。所以认为，不是max_lifetime配置的问题。还是得从源码中入手和线上的dump入手看。&lt;/p&gt;
&lt;p&gt;第一次查找问题并&lt;strong&gt;没有解决根本问题&lt;/strong&gt;，对此总结了一下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;自己的猜想缺少实际的数据支持和多方位的有力证明&lt;/li&gt;
&lt;li&gt;对源码研究不够深入，只是停留在表明&lt;/li&gt;
&lt;li&gt;对官网的配置参数理解不够透彻&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;四-第二次查找问题并且解决的过程&#34;&gt;四、第二次查找问题并且解决的过程：&lt;/h3&gt;
&lt;p&gt;本地环境观察没有问题，正式环境观察就有问题。像这种问题算是比较难解决的，为了快速解决问题，避免把线上数据copy到本地进行测试，直接down线上的dump文件下来进行仔细分析。&lt;/p&gt;
&lt;p&gt;1、查找线上的内存，dump数量，刚好100个，并且随着时间偏移，这个类对象越来越多，个人猜想就是这个对象没有被回收导致连接数未释放。有强引用引用这个对象。&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1612420897419.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;p&gt;2、查找这个对象GC root对象，右键选择Merge Shortest Paths to GC roots -&amp;gt; exclude all phantom/weak/soft etc.reference(排除所有虚弱软引用)，发现这100个对象大部分被一个名字叫做housekeeper线程所强引用，如下图。个人验证猜想是线程没有及时回收关闭或者是没有关闭线程池。&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1612423498302.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;p&gt;3、这个时候dump文件里面就没法发现更多有用的信息了，然后就去看源码看这个housekeeper线程为什么一直强引用。查找源码发现在获取datasource 的 getConnetcion方法，会初始化HikariPool连接池。&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1612423896839.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;p&gt;初始化连接池里面会初始化housekeeper连接池，刚好对应了上面在根引用的对象。&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1612423966034.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1612425624943.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;p&gt;看了下这个housekeeper对象的作用，目的是为了维持最少的空闲的连接，说白了就是根据配置参数idleTimeout和minIdle来维持最小的空闲连接数。&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1612425545450.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;p&gt;4、至此，可以初步得出结论，是由于应用程序不停的new HikariPool，然后没有及时close导致的问题。然后顺着这个结论去查看应用程序的BUG&lt;/p&gt;
&lt;p&gt;5、在程序发现下面逻辑，下面这一段逻辑就是根据租户来获取缓存中租户对应的datasource对象&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;   /**
     * 获取已缓存的数据源
     */
    private Optional&amp;lt;DataSource&amp;gt; getDataSourceIfCache(SelectRdsConfigDto rdsConfigDto) {
        String key = getUniqueMysqlKey(rdsConfigDto.getHost(), rdsConfigDto.getPort());
        if (Objects.nonNull(dataSourceCachePool.get(key))) {
            DataSourceCache dataSourceCache = dataSourceCachePool.get(key);
            //cache中已经缓存了租户的连接并且没有修改rds config信息
            if (dataSourceCache.verifyRdsConfig(rdsConfigDto)) {
                return Optional.ofNullable(dataSourceCachePool.get(key).getDataSource());
            }
            //cache中已经缓存了租户的连接，但是校验不通过
            else {
                dataSourceCachePool.remove(key);
                return Optional.empty();
            }
        }
        return Optional.empty();
    }

   // 校验
   private boolean verifyRdsConfig(SelectRdsConfigDto rdsConfigDto) {
        return rdsConfigDto.getAccount().equals(this.account) &amp;amp;&amp;amp;
                rdsConfigDto.getHost().equals(this.host) &amp;amp;&amp;amp;
                rdsConfigDto.getPort().equals(this.port) &amp;amp;&amp;amp;    rdsConfigDto.getPwd().equals(this.pwd) &amp;amp;&amp;amp;；

    //  dataSourceCachePool的key组成，一个MySQL连接对应的key
    private String getUniqueMysqlKey(String host, Integer port){
        return host + &amp;quot;:&amp;quot; + port;
    }

 }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这里逻辑有一段是校验不通过，会remove对应的datasource对象，问题就出现在这里，这里没有及时close。校验不通过的原因就是，一个host port作为一个dataSourceCachePool的key，因为线上有一个MySQL实例多个账号，导致校验总是不通过误以为成是修改了用户名或者密码，随后就是一直new datasource对象。&lt;/p&gt;
&lt;h3 id=&#34;五-根本原因&#34;&gt;五、根本原因&lt;/h3&gt;
&lt;p&gt;所以综上，最终得出结论是，因为程序问题导致HikariDataSource对象增多，而且因为HikariDataSource对象内部有一个线程池，如果外部丢失了对这个HikariDataSource对象的引用，也不会被垃圾回收，导致HikariDataSource对象不释放，然后结果就是数据库连接未释放。&lt;/p&gt;
&lt;h3 id=&#34;六-最终处理方式&#34;&gt;六、最终处理方式：&lt;/h3&gt;
&lt;p&gt;1、修改代码：&lt;br&gt;
1） dataSourceCachePool的key组成由host port 改成 host port account pwd 四个维度作为一个key。&lt;/p&gt;
&lt;p&gt;Q：为什么要这四个维度作为一个key ？&lt;br&gt;
A：因为避免一个rds有多个账户密码，导致dataSourceCachePool无限put相同host port，避免一直new datasource 和close datasource，浪费资源。&lt;/p&gt;
&lt;p&gt;2）关闭datasource对象，remove那段代码的逻辑修改成下面这个样子&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;//cache中已经缓存了租户的连接,但是修改了rds config信息
        DataSource dataSource = dataSourceCachePool.remove(key).getDataSource();
        log.info(&amp;quot;remove datasource:{}, {}&amp;quot;, key, rdsConfigDto.toString());
        new Thread(() -&amp;gt; {
            while (true) {
                try {
                    TimeUnit.SECONDS.sleep(10);
                } catch (InterruptedException e) {
                    log.error(&amp;quot;e:&amp;quot;, e);
                }
                if (dataSource instanceof HikariDataSource) {
                    if (((HikariDataSource) dataSource).getHikariPoolMXBean().getActiveConnections() &amp;gt; 0){
                        log.info(&amp;quot;ActiveConnections &amp;gt; 0, continue&amp;quot;);
                        continue;
                    }
                    log.info(&amp;quot;HikariDataSource close...&amp;quot;);
                    ((HikariDataSource) dataSource).close();
                } else if (dataSource instanceof DruidDataSource) {
                    if (((DruidDataSource) dataSource).getActiveCount() &amp;gt; 0) {
                        log.info(&amp;quot;ActiveConnections &amp;gt; 0, continue&amp;quot;);
                        continue;
                    }
                    log.info(&amp;quot;DruidDataSource close...&amp;quot;);
                    ((DruidDataSource) dataSource).close();
                } else {
                    log.error(&amp;quot;close datasource|datasource is wrong&amp;quot;);
                    throw new RuntimeException(&amp;quot;close datasource|datasource is wrong&amp;quot;);
                }
                break;
            }
        }).start();
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Q：为什么要判断活跃的连接 ActiveCount &amp;gt; 0 ？&lt;br&gt;
A：因为close的时候要判断是否有正在使用的connection对象，如果强制关闭，那么会出现一个线程查询的时候，connetion突然不可用，导致错误。&lt;/p&gt;
&lt;p&gt;Q：为什么不用线程池，而是直接new Thread ？&lt;br&gt;
A：这个场景笔者也有考虑，但是这种场景很少，一般不会有，除非手动修改数据库配置。很少使用的场景，如果开个线程池一直放着，也耗系统资源。&lt;/p&gt;
&lt;p&gt;2、改配置，改成和官方默认的配置&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1612426469625.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;p&gt;最后，重新上线后，观测对象内存数据，正常。观察3306端口连接数，正常。&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1613802463906.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;七-总结&#34;&gt;七、总结&lt;/h3&gt;
&lt;p&gt;底层的数据库组件的代码编写，要注意使用数据库连接资源的时候，一定要检查代码中是否释放，不然会造成严重的事故。而且平常还要熟悉官方配置，并且多研究源码。以免出现这种情况时束手无策。&lt;br&gt;
可以的话还可以叫身边的资深大牛给review代码，做到双重保障。&lt;/p&gt;
&lt;p&gt;最后非常感谢组内小伙伴的技术支持，才能一步一步的排除出问题，找出问题所在&lt;/p&gt;
">记一次多数据源路由造成的数据库连接泄露排查过程</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://zhangyaoo.github.io/post/2020-nian-zong-jie/"" data-c="
          &lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1609517863900.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;开头&#34;&gt;开头&lt;/h3&gt;
&lt;p&gt;今天是1月1号，新年第一天，抓住2020年的小尾巴，随便絮絮叨叨一下，做个小总结。回想一下今年一整年，开心，困难，心酸，大部分都经历过，没有什么值得说的经历，倒是小事挺多。&lt;/p&gt;
&lt;p&gt;值得提的事情就是疫情了，今年疫情在家呆了2个月，那时候因为年前被裁，已经是失业的状态，没有收入来源，开始坐立不安，烦躁 。后面意识到了在家也有在家值得做的事情，不必因为疫情打乱自己的内心，充实陪家人过每一天。&lt;/p&gt;
&lt;p&gt;作为成年人，现在认为时常开心快乐倒是一件很难的事情，想起一句话，小时候快乐是一件简单的事情，长大后，简单是一件快乐的事情。不过后面还是要时常开心为主，然后就是今年以后要沉静下来，理性思考，不管对人还是对事。还要多看些关于生活上的书，不只是盯着技术书死啃，提醒一下自己要停下来多思考，低头做事，抬头看路。&lt;/p&gt;
&lt;p&gt;今年总结方面有些少，因为我自己认为这些方面值得去总结，至于其他的，可能我没有意识到或者是今年经历事情的太少。&lt;/p&gt;
&lt;h3 id=&#34;学习&#34;&gt;学习&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1609517630829.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
关于学习这件事，还是要放在第一来说。学无止境，活到老学到老。人不能总是停留在原地，还是要多看书多学习，增长知识。中国人大部分劳动人民以前（80年代）是基本靠努力，靠勤奋，获得属于自己的劳动果实，现在信息时代，除了靠努力勤奋以外，还要有效利用专业知识去解决生活工作中的问题，享受现在信息时代给与的成果。&lt;br&gt;
就像文臣武将，谋士当出谋划策，武士当战场厮杀。每个人当去发挥自己的专业本领。不管最终目的是啥，精忠报国还是养家糊口，小有小义，大有大义。&lt;/p&gt;
&lt;p&gt;扯远了，今年准备还是以技术学习为主，然后以公众号和GitHub为辅助进行学习。&lt;br&gt;
今年准备看完这些学习资料，其中有书籍以及网络课程&lt;br&gt;
1、MySQL是如何运行的&lt;br&gt;
2、redis设计和实现&lt;br&gt;
3、架构师视频课&lt;br&gt;
4、极客时间MySQL&lt;br&gt;
5、Netty网络编程学习+技术书籍+Netty实战&lt;/p&gt;
&lt;p&gt;不多，列多了就看不完了[dog]。&lt;/p&gt;
&lt;p&gt;其他则按时及时总结工作上遇到的问题，提升自己的技术深度。毕竟工作中遇到的最容易加深理解的和提升能力的。&lt;br&gt;
顺便看一些优秀的博客及时总结，输出自己的理解。然后维护到自己的个人网站上面去。&lt;/p&gt;
&lt;p&gt;然后其他时间，准备看一些其他类型的书籍，比如人文历史，以及其他优秀的国内外著作，现在已经想好看些什么，就不一一列举了，今年今后会抽空余时间去看这些，提升自己对人和生活的一些思考。&lt;/p&gt;
&lt;p&gt;最后的话要提醒自己少看动漫二次元多学习，早睡早起~~&lt;/p&gt;
&lt;h3 id=&#34;运动&#34;&gt;运动&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1609517659211.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
运动这件事情，算是我个人每年立的flag中，自己最满意的了。一周最少一次跑步+篮球。基本上也不算全部，每周都做了。&lt;br&gt;
我身边的朋友或者亲人，我会经常提醒他们，要适当的锻炼。虽然总是被当作耳边风，但是每次过年祝别人身体健康只是噱头，只有真正关心你的人会在乎你的健康。我个人不管是生日还是新年愿望，大部分都是希望身边的人过的平平安安开开心心就行了，其他都是扯淡。&lt;br&gt;
而我自己运动的动力来源是，如果我自己身体不行，那就没有能力照护身边人。我自己能够成长为大树，让别人安心倚靠。&lt;/p&gt;
&lt;p&gt;现在虽然毕业了3年，6块腹肌已经变成了4快，身体没有毕业那会好，但是我自己还是会坚持的，朝着更man的目标奋斗。想当年我可是拥有8块腹肌的男人。。。。&lt;/p&gt;
&lt;h3 id=&#34;爱情&#34;&gt;爱情&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1609517842818.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
今年最开心的就是和女朋友度过第一年的恋爱期（不要脸的我，自认为网恋了一年的热恋期），这一年有开心和难过，不过难过时刻很少，大部分都是开心时刻，我觉得已经可以了，能够和对方每天都很开心，已经很不错了。毕竟和喜欢的人在一起不就是开心撒，这个是最难能可贵的。。&lt;/p&gt;
&lt;p&gt;我自认为我是个不好i相处的人，个人的小脾气很多，而且有时候会常有不自信。谢谢我女朋友的理解和鼓励。今年往后，还希望一起开心度过每一天，哈哈哈哈。&lt;/p&gt;
&lt;p&gt;新的一年，希望咱俩都身体健康，开开心心~&lt;/p&gt;
&lt;h3 id=&#34;2021flag&#34;&gt;2021flag&lt;/h3&gt;
&lt;p&gt;国际惯例，最后说一些打脸的flag&lt;br&gt;
1、完成上面的资料的学习&lt;br&gt;
2、每个月一次文章总结，工作总结，4次个人网站文章的发表和维护&lt;br&gt;
3、一周一次运动+篮球&lt;br&gt;
4、身体体重不超130&lt;br&gt;
5、经营好个人博客&lt;br&gt;
6、 早睡早起，11点半之前睡&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2021年，干就完事&lt;/strong&gt;。&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1609517948326.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
">2020年总结</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://zhangyaoo.github.io/post/ying-yong-ceng-wang-guan-she-ji-yu-shi-xian/"" data-c="
          &lt;h3 id=&#34;前言&#34;&gt;前言&lt;/h3&gt;
&lt;h3 id=&#34;api网关调研&#34;&gt;API网关调研&lt;/h3&gt;
&lt;h4 id=&#34;kong&#34;&gt;kong&lt;/h4&gt;
&lt;h4 id=&#34;zuul&#34;&gt;zuul&lt;/h4&gt;
&lt;h4 id=&#34;spring-cloud-gateway&#34;&gt;spring cloud gateway&lt;/h4&gt;
&lt;p&gt;自研原因：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;服务自动注册发现，不用人工更改配置接口服务&lt;/li&gt;
&lt;li&gt;相比用nginx+lua，不用多维护一套注册中心&lt;/li&gt;
&lt;li&gt;Java生态接入好，减少学习成本&lt;/li&gt;
&lt;li&gt;网关自动为API接口生成OpenApi文档&lt;/li&gt;
&lt;li&gt;基于版本的灰度发布设计实现&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;原理&#34;&gt;原理&lt;/h3&gt;
&lt;h3 id=&#34;设计&#34;&gt;设计&lt;/h3&gt;
&lt;h3 id=&#34;关键实现&#34;&gt;关键实现&lt;/h3&gt;
&lt;h3 id=&#34;总结&#34;&gt;总结&lt;/h3&gt;
&lt;h3 id=&#34;参考&#34;&gt;参考&lt;/h3&gt;
">应用层网关设计与实现</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://zhangyaoo.github.io/post/shou-lu-yi-ge-hong-bao-suan-fa/"" data-c="
          &lt;h3 id=&#34;1-要求&#34;&gt;1、要求&lt;/h3&gt;
&lt;p&gt;红包算法 function：拼手气红包&lt;br&gt;
1、每个红包获得的数学概率要一样&lt;br&gt;
2、红包最小值：1分钱&lt;/p&gt;
&lt;h3 id=&#34;2-思路&#34;&gt;2、思路：&lt;/h3&gt;
&lt;p&gt;利用切片的思想，比如有5个红包，20分，就从0-20的范围内获取四个随机数，就被分成5份，然后顺序抽取。这样保证每个红包的的概率一样&lt;br&gt;
这种方案需要考虑到几个注意点：&lt;br&gt;
1）重复的随机切片如何处理；&lt;br&gt;
2）需要考虑1分钱如何处理；&lt;/p&gt;
&lt;h3 id=&#34;3-实现&#34;&gt;3、实现：&lt;/h3&gt;
&lt;p&gt;遇到随机切片重复:重新生成切片直至不重复&lt;br&gt;
1分钱处理：判断相邻间隔的大小&lt;/p&gt;
&lt;p&gt;###4、 代码实现：&lt;br&gt;
利用treeMap的顺序有序性&lt;/p&gt;
&lt;p&gt;直接上代码（笔者已经调试过没有问题，可以运行）&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class RedPackage {
   /**
    * 红包最小金额
    */
   private long minAmount = 1L;

   /**
    * 最大的红包是平均值的N倍
    */
   private static final long N = 2;

   /**
    * 红包最大金额
    */
   private long maxAmount;

   /**
    * 红包金额 分
    */
   private long packageAmount;

   /**
    * 红包个数
    */
   private long packageSize;

   /**
    * 是否抢完
    */
   private boolean finish;

   /**
    * 存储红包的金额顺序
    */
   private final TreeMap&amp;lt;Long, Long&amp;gt; treeMap = Maps.newTreeMap((o1, o2) -&amp;gt; o1 &amp;gt; o2 ? 1 : o1.equals(o2) ? 0 : -1);

   /**
    * 构造函数不写业务逻辑
    */
   public RedPackage(long packageAmount, int packageSize){
       this.packageAmount = packageAmount;
       this.packageSize = packageSize;
       maxAmount = (packageAmount * N)/ packageSize;
   }

   public RedPackage(long packageAmount, int packageSize, long minAmount){
       this.packageAmount = packageAmount;
       this.packageSize = packageSize;
       this.minAmount = minAmount;
   }

   /**
    * 获取金额
    */
   public synchronized long nextAmount(){
       // 前置校验，初始化
       if(!finish &amp;amp;&amp;amp; treeMap.size() == 0){
           treeMap.put(packageAmount, 0L);
           for (int i = 0; i &amp;lt; packageSize - 1; i++) {
               // 随机抽取切片
               long splitNum = RandomUtils.nextLong(minAmount, packageAmount);
               Long higher = treeMap.higherKey(splitNum);
               higher = higher == null ? packageAmount : higher;
               Long lower = treeMap.lowerKey(splitNum);
               lower = lower == null ? 0 : lower;
               // 相同切片重新生成,和上一个或者下一个切片间隔小于minAmount的重新生成
               while (higher - splitNum &amp;lt;= minAmount
                       || splitNum - lower &amp;lt;= minAmount
                       || treeMap.containsKey(splitNum)){
                   splitNum = RandomUtils.nextLong(minAmount, packageAmount);
               }
               // value放入上一个entry的key,组成链条，防止再次循环
               treeMap.put(splitNum, lower);
               treeMap.put(higher, splitNum);
           }
           System.out.println(&amp;quot;init finish&amp;quot;);
       }
       Map.Entry&amp;lt;Long, Long&amp;gt; entry = treeMap.pollFirstEntry();
       if(treeMap.size() == 0){
           // 用完红包
           this.finish = true;
           if(entry == null){
               return 0L;
           }
       }
       return entry.getKey() - entry.getValue();
   }

   public static void main(String[] args) {
       RedPackage redPackage = new RedPackage(1500L, 10, 10L);
       long result = 0;
       for (int i = 0; i &amp;lt; 15; i++) {
           long amount = redPackage.nextAmount()；
           System.out.println(amount);
           result = result + amount;
       }
       System.out.println(result);
   }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;5-todo-设置单个红包最大限额值&#34;&gt;5、TODO 设置单个红包最大限额值&lt;/h3&gt;
&lt;p&gt;目前还没有实现思路&lt;/p&gt;
">概率相等的拼手气红包算法实现</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://zhangyaoo.github.io/post/di-pin-lu-da-shu-ju-liang-qiang-yi-zhi-xing-chang-jing-xia-jie-jue-si-lu/"" data-c="
          &lt;h1 id=&#34;&#34;&gt;&lt;/h1&gt;
">低频率大数据量强一致性场景下解决思路</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://zhangyaoo.github.io/post/hua-dong-chuang-kou-shi-xian-xian-liu-suan-fa-huan-xing-dui-lie-shi-xian/"" data-c="
          &lt;h3 id=&#34;&#34;&gt;&lt;/h3&gt;
">滑动窗口限流算法——环形队列实现</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://zhangyaoo.github.io/post/xue-xi-bi-ji-mysql/"" data-c="
          &lt;h2 id=&#34;幻读原理&#34;&gt;幻读原理&lt;/h2&gt;
&lt;h3 id=&#34;1-定义&#34;&gt;1、定义：&lt;/h3&gt;
&lt;p&gt;幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行&lt;br&gt;
幻读：提交隔离级别下看到的，严格来说不算。因为这个就是读提交隔离级别下“设计内”的问题&lt;br&gt;
对于读提交隔离级别，这个算“feature”,对于可重复读，这个是”bug”, 所以要解决，称呼这个bug为幻读&lt;/p&gt;
&lt;h3 id=&#34;2-注意&#34;&gt;2、注意：&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;在可重复读隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的。因此，幻读在“当前读”下才会出现。&lt;/li&gt;
&lt;li&gt;幻读只针对新增的行，即使把所有的记录都加上锁，还是阻止不了新插入的记录&lt;/li&gt;
&lt;li&gt;间隙锁是在可重复读隔离级别下才会生效的。如果把隔离级别设置为读提交的话，就没有间隙锁了。&lt;/li&gt;
&lt;li&gt;隔离级别为读提交的话，就会出现幻读【严格来说RC级别下不是幻读】情况。并且需要将binlog的模式设置为row模式（binlog三种模式https://www.cnblogs.com/xingyunfashi/p/8431780.html），不能使用statement格式，statement会导致数据一致性问题（没有间隙锁）&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;为什么要设置为row？&lt;br&gt;
间隙锁是在可重复读隔离级别下才会生效的。所以，你如果把隔离级别设置为读提交的话，就没有间隙锁了。但同时，你要解决可能出现的数据和日志不一致问题，需要把 binlog 格式设置为 row。&lt;/p&gt;
&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;主键之间也会也有间隙锁，如下图，执行select * from t where id=N for update; 如果没有这行会锁住间隙(5,10)(有一条5和一条10的记录)。如下图，多线程执行语句会导致死锁&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1614246510870.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;3-解决&#34;&gt;3、解决：&lt;/h3&gt;
&lt;p&gt;间隙锁和行锁，合成为next-key lock，next-key lock是前开后闭区间，单独间隙锁是前开后开区间&lt;/p&gt;
&lt;h3 id=&#34;4-后果&#34;&gt;4、后果：&lt;/h3&gt;
&lt;p&gt;间隙锁的引入，可能会导致同样的语句锁住更大的范围，影响并发度&lt;/p&gt;
&lt;h3 id=&#34;5-案例&#34;&gt;5、案例&lt;/h3&gt;
&lt;p&gt;案例1、select * from t where d=5 for update，d没有索引&lt;br&gt;
这个时候会扫描全表，会给表记录所有的行加上行锁，还会加上间隙锁。比如表t有6条记录，会上6条行锁，以及7个间隙锁。&lt;br&gt;
结论：对于非索引字段进行update或select .. for update操作，代价极高。所有记录上锁，以及所有间隔的锁。对于索引字段进行上述操作，代价一般。只有索引字段本身和附近的间隔会被加锁。&lt;/p&gt;
&lt;h2 id=&#34;online-ddl-原理&#34;&gt;online DDL 原理&lt;/h2&gt;
&lt;h3 id=&#34;1-mdl锁表元数据锁在online-ddl的体现&#34;&gt;1、MDL锁（表元数据锁）在online DDL的体现？&lt;/h3&gt;
&lt;p&gt;作用：维护表元数据的数据一致性，保证DDL操作与DML操作之间的一致性。如果在SQL查询期间修改了表结构就会有问题。&lt;br&gt;
总结：MDL作用是防止DDL和DML并发的冲突&lt;/p&gt;
&lt;h3 id=&#34;2-过程&#34;&gt;2、过程&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;当对一个表做增删改查操作的时候，加 MDL 读锁；当要对表做结构变更操作的时候，加 MDL 写锁。&lt;br&gt;
结论：加读锁则所有线程可正常读元数据，不影响增删改查操作，只是不能修改表结构；加写锁则只有拥有锁的线程可以读写元数据，也就是修改表结构，其它线程不能执行任何操作，包括修改表结构与增删改查。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;事务中的 MDL 锁，在语句执行开始时申请，但是语句结束后并不会马上释放，而会等到整个事务提交后再释放。&lt;br&gt;
注：一般增删改查语句默认加上MDL读锁&lt;br&gt;
结论：当有未提交的事务时候，或者是长事务时候，如果这个时候进行增删改查，是一个危险的操作，可能阻塞其它增删改查请求，或导致线程爆满。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;3-online-ddl工作原理&#34;&gt;3、online DDL工作原理&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;拿MDL写锁&lt;/li&gt;
&lt;li&gt;DDL执行准备&lt;/li&gt;
&lt;li&gt;降级成MDL读锁&lt;/li&gt;
&lt;li&gt;DDL核心执行（耗时最多的）&lt;/li&gt;
&lt;li&gt;升级成MDL写锁&lt;/li&gt;
&lt;li&gt;DDL最终提交&lt;/li&gt;
&lt;li&gt;释放MDL锁&lt;br&gt;
注：除了第四步，其他都是获取锁，如果没有冲突，获取锁的时间较小。其中第四步是读锁，所以是可以正常读写数据所以被称为Online DDL。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;oderby-工作原理&#34;&gt;oderby 工作原理&lt;/h2&gt;
&lt;h3 id=&#34;1-引出&#34;&gt;1、引出&lt;/h3&gt;
&lt;p&gt;explain 的extra信息里面出现了filesort，MySQL 会给每个线程分配一块内存用于排序，称为 sort_buffer。&lt;/p&gt;
&lt;p&gt;sort_buffer_size，就是 MySQL 为排序开辟的内存（sort_buffer）的大小。如果要排序的数据量小于 sort_buffer_size，排序就在内存中完成。但如果排序数据量太大，内存放不下，则不得不利用磁盘临时文件辅助排序。&lt;br&gt;
外部排序一般使用归并排序算法。&lt;/p&gt;
&lt;h3 id=&#34;2-排序类型&#34;&gt;2、排序类型&lt;/h3&gt;
&lt;p&gt;全字段排序和rowID排序&lt;br&gt;
全字段排序：会找出主键索引的所有字段数据放入sort_buffer中排序&lt;br&gt;
缺点：返回的字段很多的话，那么 sort_buffer 里面要放的字段数太多，这样内存里能够同时放下的行数很少，要分成很多个临时文件，排序的性能会很差&lt;/p&gt;
&lt;p&gt;rowID排序：要排序的列只有排序字段和ID&lt;br&gt;
缺点:rowid 排序多访问了一次表 t 的主键索引，多了磁盘读&lt;/p&gt;
&lt;p&gt;MySQL设计思想：如果内存够，就要多利用内存，尽量减少磁盘访问。&lt;/p&gt;
&lt;h3 id=&#34;3-增加覆盖索引和联合索引优化排序&#34;&gt;3、增加覆盖索引和联合索引优化排序&lt;/h3&gt;
&lt;p&gt;索引默认数据是有序的，这样可以避免使用sort_buffer（全字段排序和rowID排序）来进行排序&lt;/p&gt;
&lt;h3 id=&#34;4-额外案例&#34;&gt;4、额外案例&lt;/h3&gt;
&lt;p&gt;1）无条件查询如果只有order by create_time（create_time是索引），那么不会走索引&lt;br&gt;
原因：优化器认为走二级索引再去回表成本比全表扫描排序更高，所以选择走全表扫描，然后利用全字段排序和rowID排序其中一种排序。&lt;/p&gt;
&lt;h2 id=&#34;select-count工作原理&#34;&gt;select count工作原理&lt;/h2&gt;
&lt;h3 id=&#34;1-count-实现方式&#34;&gt;1、count(*) 实现方式&lt;/h3&gt;
&lt;p&gt;在不同的 MySQL 引擎中，count(&lt;em&gt;) 有不同的实现方式。&lt;br&gt;
MyISAM 引擎把一个表的总行数存在了磁盘上，因此执行 count(&lt;/em&gt;) 的时候会直接返回这个数，效率很高；&lt;br&gt;
而 InnoDB 引擎就麻烦了，它执行 count(*) 的时候，需要把数据一行一行地从引擎里面读出来，然后累积计数。&lt;/p&gt;
&lt;h3 id=&#34;2-为什么innodb-不跟-myisam-一样也把数字存起来呢&#34;&gt;2、为什么InnoDB 不跟 MyISAM 一样，也把数字存起来呢&lt;/h3&gt;
&lt;p&gt;因为InnoDB 有MVCC，不同时刻不同事务之间有可能的结果不一样&lt;/p&gt;
&lt;h3 id=&#34;3-小结一下&#34;&gt;3、小结一下&lt;/h3&gt;
&lt;p&gt;MyISAM 表虽然 count(&lt;em&gt;) 很快，但是不支持事务；，加了where条件也很慢&lt;br&gt;
show table status 命令虽然返回很快，但是不准确；&lt;br&gt;
InnoDB 表直接 count(&lt;/em&gt;) 会遍历全表，虽然结果准确，但会导致性能问题&lt;/p&gt;
&lt;h3 id=&#34;4-count-count主键-id-count字段-和-count1-等不同用法的性能有哪些差别&#34;&gt;4、count(*)、count(主键 id)、count(字段) 和 count(1) 等不同用法的性能，有哪些差别？&lt;/h3&gt;
&lt;p&gt;count语义：count() 是一个聚合函数，对于返回的结果集，一行行地判断，如果 count 函数的参数不是 NULL，累计值就加 1，否则不加。最后返回累计值&lt;br&gt;
得出结论：count(*)、count(主键 id) 和 count(1) 都表示返回满足条件的结果集的总行数；而 count(字段），则表示返回满足条件的数据行里面，参数“字段”不为 NULL 的总个数&lt;/p&gt;
&lt;h3 id=&#34;5-性能对比&#34;&gt;5、性能对比：&lt;/h3&gt;
&lt;p&gt;count(主键ID)：InnoDB 引擎遍历整张表，但不取值。server 层拿到 id 后，判断是不可能为空的，就按行累加&lt;br&gt;
count(1)：InnoDB 引擎遍历整张表，把每一行的ID取出来。server 层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加&lt;br&gt;
count(字段)：一行行地从记录里面读出这个字段，判断不能为 null，按行累加&lt;br&gt;
count(&lt;em&gt;)：count(&lt;/em&gt;)是个例外，目前MySQL只针对了这个做了优化，并不会把全部字段取出来，而是专门做了优化，不取值。count(*) 肯定不是 null，按行累加。&lt;/p&gt;
&lt;h3 id=&#34;6-结论&#34;&gt;6、结论&lt;/h3&gt;
&lt;p&gt;count(字段) &amp;lt; count(主键ID)&amp;lt; count(1)=count(&lt;em&gt;)&lt;br&gt;
1、因为count(&lt;/em&gt;) 和 count(1) 不取字段值，引擎层减少往 server层的数据返回，所以比其他count(字段)要返回值的【性能】较好；&lt;br&gt;
2、为什么count(字段)&amp;lt; count(主键ID)，因为如果选择count(ID)，那么MySQL会自动选择最小的索引树来遍历，如果是count(字段)，而且字段没有索引，那么会使用主键索引。主键索引很大。&lt;/p&gt;
&lt;h2 id=&#34;普通索引和唯一索引选择&#34;&gt;普通索引和唯一索引选择&lt;/h2&gt;
&lt;h3 id=&#34;1-普通索引和唯一索引选择&#34;&gt;1、普通索引和唯一索引选择&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;查询性能都一样&lt;/li&gt;
&lt;li&gt;更新分两种情况&lt;/li&gt;
&lt;/ol&gt;
&lt;ol&gt;
&lt;li&gt;这个记录要更新的目标页在内存中：&lt;br&gt;
对于唯一索引来说，找到 3 和 5 之间的位置，判断到没有冲突，插入这个值，语句执行结束；&lt;br&gt;
对于普通索引来说，找到 3 和 5 之间的位置，插入这个值，语句执行结束。&lt;br&gt;
总结：目标记录在内存buffer pool中的话，普通索引和唯一索引更新性能是一致的。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;2)这个记录要更新的目标页不在内存中：&lt;br&gt;
对于唯一索引来说，需要将数据页读入内存，判断到没有冲突，插入这个值，语句执行结束；&lt;br&gt;
对于普通索引来说，则是将更新记录在 change buffer，语句执行就结束了。&lt;br&gt;
总结：唯一索引将数据页读入内存涉及随机访问IO，操作成本极高。change buffer避免更新磁盘，减少了随机磁盘访问，提供性能。&lt;/p&gt;
&lt;p&gt;案例：某个业务的库内存命中率突然从 99% 降低到了 75%，整个系统处于阻塞状态，更新语句全部堵住&lt;br&gt;
原因：业务有大量插入数据的操作，开发人员把其中的某个普通索引改成了唯一索引。&lt;/p&gt;
&lt;h3 id=&#34;2-changebuffer的使用场景&#34;&gt;2、changebuffer的使用场景&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;唯一索引的更新就不能使用 change buffer，实际上也只有普通索引可以使用。&lt;/li&gt;
&lt;li&gt;对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时 change buffer 的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。&lt;/li&gt;
&lt;li&gt;如果是写完立马读的场景，建议关闭change buffer ，因为立马查询会访问数据页，会进行merge操作&lt;br&gt;
merge：将 change buffer 中的操作应用到原数据页，得到最新结果的过程称为 merge。除了访问这个数据页会触发 merge 外，系统有后台线程会定期 merge。在数据库正常关闭（shutdown）的过程中，也会执行 merge 操作。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;3-change-buffer-和-redo-log两个分别是如何提高性能的&#34;&gt;3、change buffer 和 redo log两个分别是如何提高性能的&lt;/h3&gt;
&lt;p&gt;redo log 主要节省的是随机写磁盘的 IO 消耗（转成顺序写），&lt;br&gt;
对于普通索引的修改，则会记录到change buffer，而 change buffer 主要节省的则是随机读磁盘的 IO 消耗。&lt;/p&gt;
&lt;h3 id=&#34;4-举个简单的例子来说明-mergechangebufferredolog的关系&#34;&gt;4、举个简单的例子来说明 merge，changebuffer，redolog的关系&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;插入(id1,k1) (id2,k2)两条记录，k1 所在的数据页在内存 (InnoDB buffer pool) 中，k2 所在的数据页不在内存中&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1614246819842.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
以上操作是：&lt;br&gt;
1）Page 1 在内存中，直接更新内存；&lt;br&gt;
2）Page 2 没有在内存中，就在内存的 change buffer 区域，记录下“我要往 Page 2 插入一行”这个信3）将上述两个动作记入 redo log 中（图中 3 和 4）。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;执行查询操作select * from t where k in (k1, k2)&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1614246855416.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
以上操作是：&lt;br&gt;
1）如果k1对应的数据页在buffer pool内存中，那么直接从内存中查出并且返回。这里不用直接从redolog中读盘&lt;br&gt;
2）如果k2对应的数据页不在内存中，那么会读盘，读数据到数据页page2中，然后应用 change buffer 里面的操作日志，做merge操作，并且返回正确的数据&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;注：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;此时数据页是脏页，需要刷盘flush&lt;/li&gt;
&lt;li&gt;change buffer虽然是在内存中的，如何避免停电导致的丢失呢？&lt;br&gt;
1）.change buffer有一部分在内存有一部分在ibdata.做purge操作,应该就会把change buffer里相应的数据持久化到ibdata&lt;br&gt;
2.）redo log里记录了数据页的修改以及change buffer新写入的信息&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;mysql抖动可能原因&#34;&gt;MySQL抖动可能原因&lt;/h2&gt;
&lt;h3 id=&#34;1-概念&#34;&gt;1、概念&lt;/h3&gt;
&lt;p&gt;当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。内存里的数据写入磁盘的过程，术语就是 flush&lt;/p&gt;
&lt;p&gt;更新操作：其实就是在写内存和日志&lt;br&gt;
MySQL 偶尔“抖”一下的那个瞬间：可能就是在刷脏页&lt;/p&gt;
&lt;h3 id=&#34;2-触发刷flush时机&#34;&gt;2、触发刷flush时机&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;redo log写满&lt;br&gt;
redo log是一个环形的数据结构，当数组redo log写满了，会停止所有的更新操作。checkpoint 往前推进，redo log 留出空间可以继续写。&lt;br&gt;
checkpoint 如果要往前移动，就需要将两个点之间的日志（浅绿色部分），对应的所有脏页都 flush 到磁盘上。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这种对数据库影响是很严重的，会停止所有的更新操作&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1614246959529.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;
&lt;p&gt;BufferPool内存池无可用内存，需要淘汰脏页，淘汰脏页需要flush&lt;br&gt;
当需要新的内存页，而内存不够用的时候，就要淘汰一些数据页，空出内存给别的数据页使用。这时候只能把最久不使用的数据页从内存中淘汰掉：。如果淘汰的是“脏页”，就要先将脏页写到磁盘。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;MySQL空闲会主动flush&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;MySQL 正常关闭的情况。&lt;br&gt;
这时候，MySQL 会把内存的脏页都 flush 到磁盘上，下次 MySQL 启动的时候，就可以直接从磁盘上读数据，启动速度会很快。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;3-innodb刷脏页的策略&#34;&gt;3、Innodb刷脏页的策略&lt;/h3&gt;
&lt;p&gt;正确地告诉 InnoDB 所在主机的 IO 能力，通过innodb_io_capacity参数让InnoDB知道磁盘IO能力，以便其正确地刷脏页。&lt;br&gt;
建议：innodb_io_capacity设置为磁盘的 IOPS。 磁盘的 IOPS，也就是在一秒内，磁盘进行多少次 I/O 读写，是衡量磁盘性能的主要指标。&lt;/p&gt;
&lt;p&gt;刷脏页慢可能导致的情况：内存脏页太多，其次是 redo log 写满。&lt;br&gt;
总结: 无论是你的查询语句在需要内存的时候可能要求淘汰一个脏页，还是由于刷脏页的逻辑会占用 IO 资源并可能影响到了你的更新语句，都可能是造成你从业务端感知到 MySQL“抖”了一下的原因。&lt;/p&gt;
&lt;h3 id=&#34;4-具体业务场景&#34;&gt;4、具体业务场景&lt;/h3&gt;
&lt;p&gt;出现这样的场景：MySQL的TPS会很低，但是主机的IO压力不大&lt;br&gt;
如果是固态硬盘，那么它的IO读写能力会很大。这个时候如果innodb_io_capacity设置太低，MySQL认为磁盘io能力太差，导致全力刷脏页变慢、脏页累积下来，后续只要刷脏页，不管是内存不够还是日志满了导致的刷脏页，都会导致变慢。&lt;/p&gt;
&lt;h3 id=&#34;5-qa&#34;&gt;5 Q&amp;amp;A&lt;/h3&gt;
&lt;p&gt;1、“内存不够用了，要先将脏页写到磁盘“redo log对应的空间会释放嘛？“redo log 写满了，要 flush 脏页”对应的内存页会释放嘛？&lt;br&gt;
redolog 的空间是循环使用的，无所谓释放。 对应的内存页会变成干净页。但是等淘汰的时候才会逐出内存&lt;/p&gt;
&lt;p&gt;2、redo log是怎么记录对应脏页是否已经flush了？如果断电了重启导致内存丢失，前面几章说通过redo log进行数据恢复那redo log又怎么去释放空间？&lt;br&gt;
不用记，重启了就从checkpoint 的位置往后扫。 如果已经之前刷过盘的, 不会重复应用redo log&lt;/p&gt;
&lt;p&gt;3、redolog是记录的什么？&lt;br&gt;
redolog 记录的是动作，不是结果。Redo log记录的是页的偏移量。比如update语句更新+9，Redo log里是记的+9&lt;/p&gt;
&lt;p&gt;4：怎么让MySQL不抖？&lt;br&gt;
设置合理参数配配置，尤其是设置 好innodb_io_capacity 的值，并且平时要多关注脏页比例，不要让它经常接近 75%&lt;/p&gt;
&lt;p&gt;5：WAL怎么把随机写转化为顺序写的？&lt;br&gt;
写redolog是顺序写的，先写redolog等合适的时候再写磁盘，间接的将随机写变成了顺序写，性能确实会提高不少&lt;/p&gt;
">学习笔记：MySQL</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://zhangyaoo.github.io/post/ji-yi-ci-cai-yong-fen-bu-shi-id-jie-jue-fen-ku-fen-biao-cai-de-keng/"" data-c="
          &lt;h3 id=&#34;一-背景&#34;&gt;一、背景&lt;/h3&gt;
&lt;p&gt;随着业务模式的扩大，多个平台下用户数量不断扩大。并且因为业务需要，需要合并两个业务系统的用户中心，因为需要对接三方系统，所以要求用户的ID标识不能体现出系统的用户量。&lt;br&gt;
技术团队考虑到这种场景以及后续用户的扩大，需要一个方案去解决在&lt;strong&gt;分布式环境&lt;/strong&gt;下ID递增的问题，系统自己的ID递增算法也需要做改变。&lt;/p&gt;
&lt;h3 id=&#34;二-业界比较流行的分布式id解决方案&#34;&gt;二、业界比较流行的分布式ID解决方案&lt;/h3&gt;
&lt;p&gt;技术团队首先考察业界比较流行的做法，总结不同方案优缺点，然后根据自己的业务来选择更合适的方案。&lt;/p&gt;
&lt;h4 id=&#34;21-数据库分批id分发&#34;&gt;2.1 数据库分批ID分发&lt;/h4&gt;
&lt;p&gt;数据库分批ID原理主要是利用分批思想以及乐观锁来解决，目前淘宝中间件TDDL其中的主键分配就是用了这个方案。该方案具体是这样做的：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;数据库表维护一条数据，记录当前分配ID号以及偏移数量等数据&lt;/li&gt;
&lt;li&gt;编写服务，利用乐观锁去CAS更新数据，更新成功就说明拿到了一批ID号，失败的话进行重试，设置一定的重试次数&lt;/li&gt;
&lt;li&gt;放入本地缓存或者redis做扣减，如果用完就重复步骤2&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;具体的的表可以是类似这样的：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;字段&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;id&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;自增ID，没有业务意义&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;current_num&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;当前已经分配的ID最大值&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;limit&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;一次分配多少个ID&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;version&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;版本号，CAS更新用&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;create_time&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;记录创建时间&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;update_time&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;记录更新时间&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;比如，limit=1000，一次分配1000个ID，没分配之前current_num = 0，第一次current_num = 1000，第二次依次类推。&lt;/p&gt;
&lt;p&gt;当然，上述的方案也有缺点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;一条数据，如果有大量流程去更新，要竞争获取行锁，会有性能问题，（可以参考行锁的利弊，丁奇——秒杀场景下MySQL的低效）&lt;/li&gt;
&lt;li&gt;强依赖DB，如果当前数据库宕机，导致分布式ID分发服务就会出现问题&lt;/li&gt;
&lt;li&gt;如果在主从数据库场景下，需要考虑到主从的延迟性导致分配ID的不一致性&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;所以为了解决上面的问题，笔者参考concurrentHashMap分段锁的思想，将一条记录分段为多个，同时为了避免DB单点可用性，可以将不同的记录分布在不同的数据库上面。&lt;/p&gt;
&lt;p&gt;具体的表可以是类似这样的：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;字段&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;id&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;自增ID，没有业务意义&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;current_num&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;当前已经分配的ID最大值&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;limit&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;一次分配多少个ID&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;offset&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;前后分配的ID间隔数&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;initial_id&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;初始自增的ID&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;version&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;版本号，CAS更新用&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;create_time&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;记录创建时间&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;update_time&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;记录更新时间&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt; 新增offset偏移和initial_id字段，offset代表数据库表记录前后分配间隔数量，initial_id代表开始初始的值。&lt;br&gt;
 举个例子，现在将记录分为10条，分布在不同数据库上，那么offset就是10000，limit就是1000，第一条记录第一次开始配合获取0-1000，第二次分配获取10000-11000，依次类推。&lt;/p&gt;
&lt;p&gt; 这里需要考虑一个问题，就是如果请求ID分发的服务的流量&lt;strong&gt;怎么路由&lt;/strong&gt;到具体的记录呢？如果流量全部都请求到第一条记录上了，就会导致请求不均。&lt;br&gt;
 这个问题很简单，有一定开发经验的读者自然可以联想到用一致性hash去路由，具体路由的key可以根据业务去定，比如用户手机号。（具体一致性hash路由如何实现，可以参考利用treeMap实现）&lt;/p&gt;
&lt;p&gt; 以上方案算是解决性能问题，但是还有比较致命的问题，就是无法横向扩展。就比如说现在有10台机器不同数据库，每一个数据库一条记录。假如现在有新的机器10台机器想要加入分配的话，那么就要修改offset和initial_id，所以在不停机实现的话，可能无法实现（目前笔者没有想到方法解决，如果读者有idea可以欢迎和我讨论）。这里笔者提供一种方法去解决：&lt;br&gt;
 提前预先分配100条记录，每一条记录一批次获取100个ID，offset设置为10000，当前10台机器每一台有10条记录，后续有新机器的话直接将记录不停机转移到新机器就可以了。&lt;/p&gt;
&lt;h4 id=&#34;22-redis序列化分发&#34;&gt;2.2 Redis序列化分发&lt;/h4&gt;
&lt;p&gt;Redis来生成ID，这主要依赖于Redis是单线程的，所以也可以用生成全局唯一的ID。可以用Redis的原子操作 INCR和INCRBY来实现。目前单台redis的qps能够达到5W，所以一定程度上能够解决性能问题。具体实现笔者这里就不阐述了。&lt;/p&gt;
&lt;p&gt;当然用这个方案也有缺点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;依赖redis，如果业务中没有就要依赖这个中间件&lt;/li&gt;
&lt;li&gt;生成的ID是单调递增的，容易暴露系统的用户数&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;23-snowflake雪花算法&#34;&gt;2.3 SnowFlake雪花算法&lt;/h4&gt;
&lt;p&gt;以上2.1 2.2方案都能解决性能问题，但是产生的ID，是连续的，容易暴露自己系统中用户的数量。所以有些系统会要求要趋势递增，而且要保持信息安全。目前雪花算法就能解决这个问题。&lt;/p&gt;
&lt;p&gt;其中原理就是：给一个64位的二进制数字，其中&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;第1位置为0。&lt;/li&gt;
&lt;li&gt;第2-42位是相对时间戳，通过当前时间戳减去一个固定的历史时间戳生成。&lt;/li&gt;
&lt;li&gt;第43-52位是机器号workerID，每个Server的机器ID不同。&lt;/li&gt;
&lt;li&gt;第53-64位是自增ID。&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1604663039402.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这个方案也有缺点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;实现比较复杂，考验开发人员&lt;/li&gt;
&lt;li&gt;需要独立部署实现&lt;/li&gt;
&lt;li&gt;强依赖时钟，时钟回拨会有重复的ID&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;三-当前方案是如何做的&#34;&gt;三、当前方案是如何做的&lt;/h3&gt;
&lt;p&gt; 参考上述方案后，技术团队考虑到未来业务的增加，流量的增长以及后续的扩展，准备利用方案三去实现。其中具体实现可以参考笔者GitHub的实现：&lt;a href=&#34;https://github.com/zhangyaoo/fastim/blob/master/fastim-leaf/src/main/java/com/zyblue/fastim/leaf/manager/SnowFlakeManager.java&#34;&gt;分布式ID SnowFlake实现&lt;/a&gt;&lt;br&gt;
 当然使用方案三也会有缺陷，比如会发生时钟回拨问题，以及分布式ID分发服务强依赖zookeeper。&lt;/p&gt;
&lt;h4 id=&#34;31-时钟回拨&#34;&gt;3.1 时钟回拨&lt;/h4&gt;
&lt;p&gt; 发生时钟回拨的原因是，如果分发服务正在生成ID的过程中，系统时间因为不可抗拒的因素或者人为因素导致时间倒流了，会导致可能会有重复的ID生成，作为分布式ID分发这个是不准发生的。所以如果发生时钟回拨那么就抛出异常，实现如下&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;long timestamp = System.currentTimeMillis();
// 如果当前时间戳小于上次分发的时间戳
if (timestamp &amp;lt; lastTimestamp) {
    long offset = lastTimestamp - timestamp;
    if (offset &amp;lt;= 5) {
        // 如果时间戳间隔小于5，那么进行等待，等待窗口时间，然后再进行重试
        try {
            wait(offset &amp;lt;&amp;lt; 1);
            timestamp = System.currentTimeMillis();
            if (timestamp &amp;lt; lastTimestamp) {
                throw new RuntimeException(String.format(&amp;quot;lastTimestamp %s is after reference time %s&amp;quot;, lastTimestamp, timestamp));
            }
        } catch (InterruptedException e) {
            logger.error(&amp;quot;wait interrupted&amp;quot;);
            throw new RuntimeException(String.format(&amp;quot;lastTimestamp %s is after reference time %s&amp;quot;, lastTimestamp, timestamp));
        }
    } else {
        // 如果相差过大，直接抛出异常
        throw new RuntimeException(String.format(&amp;quot;lastTimestamp %s is after reference time %s&amp;quot;, lastTimestamp, timestamp));
    }
}
// 如果等于，表明同一时刻
if (lastTimestamp == timestamp) {
    // 如果小于计数器最大值就，增加
    if (this.counter &amp;lt; MAX_SEQUENCE) {
        this.counter++;
    } else {
        // 表明同一时刻，同一机器下，的所有计数器都用完了
        throw new RuntimeException(&amp;quot;Sequence exhausted at &amp;quot; + this.counter);
    }
} else {
    //如果是新的ms开始
    counter = 0L;
}
// 记录这一次时间戳，用作下一次比较
lastTimestamp = timestamp;
// 后续的生成ID逻辑
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;32-强依赖zookeeper&#34;&gt;3.2 强依赖zookeeper&lt;/h4&gt;
&lt;p&gt;以上能解决时钟回拨的问题，但是强依赖zookeeper来生成分布式环境下的当前机器的ID。笔者参考dubbo的设计思想，当ID分发服务通过ID+端口注册到zookeeper的递增持久节点后，返回的节点直接存储再本地文件中，实现高可用，如下&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;/**
 * 高可用，防止zookeeper挂了，本地本机生效
 * 写入本地文件的时机：当前机器获取zookeeper的持久节点后
 */
private void writeWorkerId2Local(int workerId){
    String path = WORKERID_PATH + File.separator + applicationName + File.separator + &amp;quot;workerId.properties&amp;quot;;
    File file = new File(path);
    if(file.exists() &amp;amp;&amp;amp; file.isFile()){
        try {
            FileUtils.writeStringToFile(file, &amp;quot;workerId=&amp;quot; + workerId, false);
        }catch (Exception e){
            logger.error(&amp;quot;e:&amp;quot;, e);
        }
    }else {
        boolean mkdirs = file.getParentFile().mkdirs();
        if(mkdirs){
            try {
                if (file.createNewFile()) {
                    FileUtils.writeStringToFile(file, &amp;quot;workerId=&amp;quot; + workerId, false);
                    logger.info(&amp;quot;local file cache workerID is {}&amp;quot;, workerId);
                }
            }catch (Exception e){
                logger.error(&amp;quot;e:&amp;quot;, e);
            }
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;四-采用分布式id上线后产生的bug&#34;&gt;四、采用分布式ID上线后产生的BUG&lt;/h3&gt;
&lt;h4 id=&#34;40-问题分析&#34;&gt;4.0 问题分析&lt;/h4&gt;
&lt;p&gt;当上线分布式ID分发服务后，观察日志，出现大量的报错，如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;io.lettuce.core.RedisCommandExecutionException: ERR bit offset is not an integer or out of range
at io.lettuce.core.ExceptionFactory.createExecutionException(ExceptionFactory.java:135) ~[lettuce-core-5.2.1.RELEASE.jar:5.2.1.RELEASE]
at io.lettuce.core.ExceptionFactory.createExecutionException(ExceptionFactory.java:108) ~[lettuce-core-5.2.1.RELEASE.jar:5.2.1.RELEASE]
at io.lettuce.core.protocol.AsyncCommand.completeResult(AsyncCommand.java:120) ~[lettuce-core-5.2.1.RELEASE.jar:5.2.1.RELEASE]
at io.lettuce.core.protocol.AsyncCommand.complete(AsyncCommand.java:111) ~[lettuce-core-5.2.1.RELEASE.jar:5.2.1.RELEASE]
at io.lettuce.core.protocol.CommandHandler.complete(CommandHandler.java:654) ~[lettuce-core-5.2.1.RELEASE.jar:5.2.1.RELEASE]
at io.lettuce.core.protocol.CommandHandler.decode(CommandHandler.java:614) ~[lettuce-core-5.2.1.RELEASE.jar:5.2.1.RELEASE]
…………
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;乍看是redis的抛出来的错误，和这次分布式ID改造没有什么关系，但是仔细静下来想一想，这次ID改造是从原来的数据库自增改造的，数据库自增数据主键很小是int类型，然后用了64位二进制数据当作ID后，导致redis中用户的数据存不下去，然后笔者就按照这个思路去发掘问题。&lt;/p&gt;
&lt;p&gt;笔者从业务抛出的堆栈中发现，这个错误是在判断用户是否是新用户服务方法中抛出的，而判断是新用户的逻辑就是，利用redis的bitmap来解决的：getbit new_user_key userId，其中 userId为用户ID，如果用户发生了交易信息，就会执行：setbit new_user_key userId 1 这个命令。 为什么要用bitmap解决呢，主要是因为如果从交易记录表查询某个用户是否交易信息来判断是新用户的话就会非常耗时，所以只要是发生了交易信息就设置bitmap就可以了。&lt;/p&gt;
&lt;p&gt;那为什么会抛出out of range这个错误呢，我们知道bitmap底层其实就是String类型，而String类型的最大长度为512M，官网截图：&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1605157810715.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
所以如果offset超过512M这个范围那么就会抛出异常，512M = 2^9 * 2^12 * 2^12 * 2^3 = 2^32 bit，也就是支持Integer类型的最大值，而我们这次分布式ID服务ID是64位的，支持2^64 bit，所以如果offset也就是userId大于2^32的话就会抛出out of range异常了。&lt;/p&gt;
&lt;h4 id=&#34;41-问题解决&#34;&gt;4.1 问题解决&lt;/h4&gt;
&lt;p&gt;找到了问题，也就好去做优化了，这里笔者提供几个方法作为参考&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在数据库用户表或者用户扩展表中增加一个字段，如果发生了交易，那么将字段标记为老用户&lt;/li&gt;
&lt;li&gt;把用户ID放入redis集合set中，利用SMISMEMBER命令判断当前用户是否在集合内，当然这个会有性能问题，其方法时间复杂度位O(N)，官方截图:&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1605162870590.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;五-总结&#34;&gt;五、总结&lt;/h3&gt;
&lt;p&gt; 笔者从分布式ID选型出发，介绍了几种业界几种比较常用的生成方法，并且介绍了其优缺点，然后结合实际业务出发，选择合适的方案。然后介绍了使用SnowFlake算法导致的业务问题，以及分析最后提供解方法。从这次踩坑的经历来说，我们要懂技术体系，并且还要非常熟悉业务，最大程度避免功能之间的相互的影响导致的bug。&lt;/p&gt;
&lt;h3 id=&#34;六-参考&#34;&gt;六、参考&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;美团分布式算法ID几种实现方式——https://tech.meituan.com/2017/04/21/mt-leaf.html&lt;/li&gt;
&lt;li&gt;SnowFlake算法——https://github.com/twitter-archive/snowflake&lt;/li&gt;
&lt;/ul&gt;
">记一次用户中心采用分布式ID踩的坑</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://zhangyaoo.github.io/post/saas-xi-tong-duo-shu-ju-yuan-lu-you-you-ya-jie-jue-fang-an/"" data-c="
          &lt;h2 id=&#34;背景&#34;&gt;背景&lt;/h2&gt;
&lt;p&gt;在目前的SaaS系统中，业务开发者需要重点关注的一个问题就是数据隔离问题，这个是做SaaS系统必须要考虑的点，多租户数据隔离是每个SaaS系统都要遇到并且要解决的问题，笔者就分享下解决这种问题的思路、具体的解决方案以及优雅的解决思路。&lt;/p&gt;
&lt;h2 id=&#34;一-解决方案介绍&#34;&gt;一、解决方案介绍&lt;/h2&gt;
&lt;h3 id=&#34;目前业界数据隔离方案&#34;&gt;目前业界数据隔离方案&lt;/h3&gt;
&lt;p&gt;1、独立数据库，通过动态切换数据源来实现多租户&lt;br&gt;
2、共享数据库，隔离数据架构&lt;br&gt;
3、共享数据库，共享数据表，使用字段来区分不同租户，此方案成本最低&lt;/p&gt;
&lt;p&gt;以上方案从上到下，安全性逐渐降低。由于考虑到安全问题，故采用第一种方案解决数据隔离&lt;br&gt;
优点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;非常安全&lt;/li&gt;
&lt;li&gt;数据互不影响，性能互不影响&lt;/li&gt;
&lt;li&gt;数据迁移，数据扩展方便&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;缺点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;需要维护大量的数据库&lt;/li&gt;
&lt;li&gt;需要自行切换数据库，开发量多且实现复杂&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;具体技术实现&#34;&gt;具体技术实现&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;简单的架构图&lt;/strong&gt;&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1603179800053.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
如图所示，SaaS项目大概架构图，关键点是应用层传参，以及路由层的实现。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;实现&lt;/strong&gt;&lt;br&gt;
1、应用层：项目中应用service层是dubbo服务，而且项目分多层，这里需要考虑到多层服务场景下，如何优雅传参问题，如下图所示&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1603181882775.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
我们考虑到租户ID是唯一标识，和业务参数绑定在一起不优雅，所以两种参数分开处理，业务参数直接参数透传，租户ID唯一标识通过隐式传参来处理（参考dubbo http://dubbo.apache.org/zh-cn/docs/user/demos/attachment.html），并且参数记录到服务本地的threadlocal中，以便后续其他业务需要。具体实现如下：&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1603183675071.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;p&gt;2、路由层：路由层实现主要是自行实现spring框架中DataSource接口，自定义dynamicDataSource类，然后implement DataSource接口，实现getConnection方法。然后重新定义SqlSessionFactory的bean，将自定义DataSource类属性注入。&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1603183148592.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1603183156251.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
然后我们只需要关注getConnection方法根据租户ID，选择相对应的租户连接池就可以了。&lt;br&gt;
如图中，我们只需要实现这个selectTenantCodeDataSource()这个方法就可以了，这个方法实现很简单，这里就不贴图了。selectTenantCodeDataSource()方法主要就是从threadlocal中拿租户ID，然后去缓存池map中拿出连接池信息。&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1603183509071.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
其中，dataSourceCachePool是在初始化配置时候，将所有的租户连接池直接创建，然后扔到dataSourceCachePool。key是租户的ID，value是连接池信息。&lt;/p&gt;
&lt;p&gt;具体的初始化配置：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;/**
 * 初始化数据源
 */
@Configuration
public class DataSourceInit {
    
    @PostConstruct
    public void InitDataSource()  {
        log.info(&amp;quot;=====初始化数据源=====&amp;quot;);
        TenantRoutingDataSource tenantRoutingDataSource = (TenantRoutingDataSource)ApplicationContextProvider.getBean(&amp;quot;tenantRoutingDataSource&amp;quot;);
        Map&amp;lt;String, DataSourceCache&amp;gt; dataSourceCachePool = new HashMap&amp;lt;&amp;gt;();

        List&amp;lt;TenantInfo&amp;gt; tenantList = tenantInfoService.InitTenantInfo();
        for (TenantInfo tenantInfo : tenantList) {
            log.info(tenantInfo.toString());
            HikariDataSource dataSource = new HikariDataSource();
            dataSource.setDriverClassName(tenantInfo.getDatasourceDriver());
            dataSource.setJdbcUrl(tenantInfo.getDatasourceUrl());
            dataSource.setUsername(tenantInfo.getDatasourceUsername());
            dataSource.setPassword(tenantInfo.getDatasourcePassword());
            dataSource.setDataSourceProperties(master.getDataSourceProperties());
            dataSourceCachePool.put(tenantInfo.getTenantId(), dataSource);
        }
        //设置数据源
        tenantRoutingDataSource.setDataSources(dataSourceCachePool);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;二-方案的隐藏缺点以及解决&#34;&gt;二、方案的隐藏缺点以及解决&lt;/h2&gt;
&lt;h3 id=&#34;隐藏的缺陷&#34;&gt;隐藏的缺陷&lt;/h3&gt;
&lt;p&gt;相信有一定开发经验的读者应该能想到，上述方案最大的缺点就是性能问题，对MySQL有非常大的影响。因为一开始初始化非常多的连接池，就会占用连接资源，比如租户从100个扩展到了1000个以及更多，那么连接池数量就线性增长，如果一个连接池保持15个活跃连接的话，那么连接数就是15*1000，此时如果MySQL的maxconntion的数量非常小，那么MySQL侧就会抛出”too many connctions“错误，在应用层方面就是MySQL不可用了。&lt;br&gt;
没优化之前的架构：&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1603190851131.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;解决&#34;&gt;解决&lt;/h3&gt;
&lt;p&gt;想保持数据库分离，又要考虑到MySQL性能问题，只能向连接池优化的方向去考虑，其实可以减少数量就可以了，这里实现方案就是一个数据库实例一个连接池，如下图所示：&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1603190889253.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
具体实现就是将上述方案中的dataSourceCachePool的key改为 “IP+端口”，作为key。然后再数据源路由层，多一层映射（租户ID——&amp;gt;数据库实例）就可以了。&lt;/p&gt;
&lt;h2 id=&#34;三-更优雅方案解决企业内部开发痛点&#34;&gt;三、更优雅方案解决企业内部开发痛点&lt;/h2&gt;
&lt;h3 id=&#34;现状&#34;&gt;现状&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;现状&lt;/strong&gt;：企业内部项目组开发数据源路由，各个人员开发水平不一，各种路由方案实现不同，自己组内的开发的方案只能自己组内使用，并且实现复杂，耗人力物力。&lt;br&gt;
&lt;strong&gt;目标&lt;/strong&gt;：项目组使用直接引入maven包，任何配置都不要配置（自定义的话需要自行在自己项目中配置属性），开箱即用。&lt;/p&gt;
&lt;h3 id=&#34;具体实现&#34;&gt;具体实现&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;原理&lt;/strong&gt;：直接采用springboot starter开发，将上述方案所有的逻辑和技术实现单独放入springboot starter工程中，采用外部配置的方式实现自定义配置。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;开发者实现&lt;/strong&gt;：网上有许多springboot starter开发的流程和开发案例，笔者这里就只贴出关键的代码&lt;br&gt;
1、自动装配类：spring.factories中写入这个类DataSourceAutoConfigure，实现bean的自动装入，类里面主要是实现SqlSessionFactory和PlatformTransactionManager，然后在TenantRoutingDataSource的getconnection方法中自定义实现路由逻辑。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@Configuration
public class DataSourceAutoConfigure {

    @Resource
    private TenantRoutingDataSource tenantRoutingDataSource;

    @Bean
    @ConditionalOnMissingBean(SqlSessionFactory.class)
    @ConditionalOnBean(TenantRoutingDataSource.class)
    public SqlSessionFactory sqlSessionFactory() throws Exception{
        SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean();
        sqlSessionFactoryBean.setDataSource(tenantRoutingDataSource);
        Objects.requireNonNull(sqlSessionFactoryBean.getObject()).getConfiguration().setMapUnderscoreToCamelCase(true);
        return sqlSessionFactoryBean.getObject();
    }

    @Bean
    @ConditionalOnMissingBean(PlatformTransactionManager.class)
    @ConditionalOnBean(TenantRoutingDataSource.class)
    public PlatformTransactionManager platformTransactionManager() {
        return new DataSourceTransactionManager(tenantRoutingDataSource);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;2、Java SPI机制：利用Javaspi 来获取用户自定义的mybatis plugin。这样做的好处是，不用每次增加一个plugin，就改动数据路由组件的代码。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public SqlSessionFactory sqlSessionFactory(@Qualifier(&amp;quot;tenantRoutingDataSource&amp;quot;) TenantRoutingDataSource tenantRoutingDataSource) throws Exception{
        SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean();
        sqlSessionFactoryBean.setDataSource(tenantRoutingDataSource);
        Interceptor[] plugins = loadMybatisPlugin();
        if(plugins.length &amp;gt; 0){
            sqlSessionFactoryBean.setPlugins(plugins);
        }
        Objects.requireNonNull(sqlSessionFactoryBean.getObject()).getConfiguration().setMapUnderscoreToCamelCase(true);
        return sqlSessionFactoryBean.getObject();
    }

    // SPI机制获取插件
    private Interceptor[] loadMybatisPlugin(){
        List&amp;lt;Interceptor&amp;gt; interceptors = new ArrayList&amp;lt;&amp;gt;();
        ServiceLoader&amp;lt;Interceptor&amp;gt; load = ServiceLoader.load(Interceptor.class);
        load.forEach(interceptors::add);
        return interceptors.toArray(new Interceptor[0]);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;3、dubbo filter扩展接口：获取租户ID，并且需要加@Activate注解，这样dubbo在初始化filter链的时候，自动将这个filter注册到filter链中，这样做的好处就是，用户在自己工程中不需要配置filter这个参数，无需增加任何的配置。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@Activate(group = {&amp;quot;provider&amp;quot;})
public class TenantCodeContextFilter implements Filter {
    @Override
    public Result invoke(Invoker&amp;lt;?&amp;gt; invoker, Invocation invocation) throws RpcException {
        String tenantCode = RpcContext.getContext().getAttachment(&amp;quot;tenantCode&amp;quot;);
        TenantCodeContextHolder.setTenantCode(tenantCode);
        return invoker.invoke(invocation);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;4、检查用户侧自定义配置是否正确：检查用户的配置是否合理，不合理的话再容器就绪阶段就会抛出异常&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@Component
public class CheckConfigListener implements ApplicationListener&amp;lt;ApplicationReadyEvent&amp;gt; {

    @Override
    public void onApplicationEvent(ApplicationReadyEvent applicationReadyEvent) {
        ConfigurableApplicationContext applicationContext = applicationReadyEvent.getApplicationContext();
        ConfigurableEnvironment environment = applicationContext.getEnvironment();
        // 检查用户自定义配置是否正确，自行实现
        checkDatasourceConfig(environment);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;5、利用缓存池保存多个dataSource对象，一个MySQL实例对应一个dataSource对象，一个dataSource对应多个租户，而不是一个dataSource对应一个租户，这样的好处就是，如果一个MySQL实例里面的租户数据库过多，不会导致一个MySQL实例连接数膨胀问题。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    /**
     * 数据源缓存池
     * Key 一个MySQL数据库连接信息key
     * Value 缓存时RDS连接信息与DataSource
     */
    private final Map&amp;lt;String, DataSourceCache&amp;gt; dataSourceCachePool = new ConcurrentHashMap&amp;lt;&amp;gt;();
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;用户使用&lt;/strong&gt;：直接引入相应的maven，方便快捷&lt;/p&gt;
&lt;h2 id=&#34;四-todo后续优化&#34;&gt;四、TODO后续优化&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;目前多租户数据源通用工程只支持Dubbo的调用，未来可扩展支持多种协议如HTTP、gRPC&lt;/li&gt;
&lt;li&gt;目前只支持Hikari数据源，后续支持多种数据源类型，比如Durid&lt;/li&gt;
&lt;li&gt;如果租户数据非常大，可以考虑空间换时间思想，使用缓存存放租户的数据源配置，提升查询效率。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;SaaS系统数据隔离方案——https://blog.arkency.com/comparison-of-approaches-to-multitenancy-in-rails-apps/&lt;/li&gt;
&lt;/ul&gt;
">SaaS系统多数据源路由优雅解决方案</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://zhangyaoo.github.io/post/mysql-lian-he-suo-yin-zai-bshu-de-cun-chu-he-cha-zhao/"" data-c="
          &lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;在对MySQL开发中，联合索引是很常见的一种MySQL优化方式，本文解释了联合索引的存储以及查找过程，可以了解一下底层的原理以及加深对MySQL联合索引的理解。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;innodb-b树&#34;&gt;Innodb B+树&lt;/h2&gt;
&lt;p&gt;先看一下Innodb B+树的主键索引和辅助索引。这里直接拿张洋大神的图：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;聚簇索引:&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1593425796639.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/li&gt;
&lt;li&gt;辅助非聚簇索引:&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1593425801180.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
&lt;strong&gt;结构&lt;/strong&gt;：当一个表T（id,name,age,sex,high）建一个普通索引  KEY(name)，name的索引结果就和上面辅助非聚簇索引结构一样。&lt;br&gt;
&lt;strong&gt;查询&lt;/strong&gt;：当有一个select id,name,age from T where name = &amp;quot;&amp;quot; 辅助索引会根据name在B+树上进行二叉树查找，找出叶子节点数据后发现没有age这个数据，就会进行&lt;strong&gt;回表&lt;/strong&gt;操作到主键聚簇索引去查找，拿到聚簇索引叶子节点的age数据。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;联合索引存储以及寻址&#34;&gt;联合索引存储以及寻址&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;索引结构&lt;/strong&gt;：我们知道上述回表过程也会消耗性能，相当于多查一次，所以系统可以根据业务情况加上一个组合索引，当然并不是一直加组合索引就可以了，因为要考虑到索引存储空间的问题。例如给上述加上一个组合索引  KEY（name,age,sex）【 KEY（col1,col2,col3）】。那么这个组合索引的B+树非叶子节点数据结构和上述辅助非聚簇索引图一样，但是叶子节点是这样的：&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1593425790647.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
叶子节点存储col1,col2,col3这三列数据以及加上ID这一列数据。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;寻址过程：&lt;/strong&gt;&lt;br&gt;
例如语句：select * from T where name = &amp;quot;张三&amp;quot; and age=25，先根据name字段从辅助聚簇索引定位到哪一个叶子节点数据中，然后根据age节点在上述表格的前6行中，寻找age= 25的数据，然后找出所有符合的数据以及其对应的ID，然后根据ID来进行回表操作查询。这里返回了三条数据，就回了三次表。&lt;br&gt;
上述回表过程中，笔者引入一个&lt;strong&gt;索引下推&lt;/strong&gt;的一个功能，索引下推是MySQL在5.6版本后引入的一个查询优化。就拿上述的例子，在没有优化之前，据name字段查询“张三”后，会拿到6条结果，回表6次，然后从主键索引拿到6条数据后，根据age字段筛选数据；优化之后，先再辅助索引上面根据name字段和age字段筛选符合数据，也就是ID，然后再回表，这里回表了三次。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;组合索引注意事项&lt;/strong&gt;&lt;br&gt;
当然，联合索引的最重要的是注意联合索引的使用问题，要遵循最左匹配原则，才可以优化到整个SQL了。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;总结&#34;&gt;总结&lt;/h3&gt;
&lt;p&gt;以上，总结了MySQL的索引的基本原理，以及联合索引的存储和寻址过程，并且引入索引下推概念，还有使用联合索引的注意事项。&lt;/p&gt;
&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;MySQL索引背后的数据结构及算法原理——http://blog.codinglabs.org/articles/theory-of-mysql-index.html。&lt;/li&gt;
&lt;/ul&gt;
">MySQL联合索引在B+树的存储和查找</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://zhangyaoo.github.io/post/guan-yu-zookeeper-qi-shu-jie-dian-yi-ji-nao-lie-wen-ti/"" data-c="
          &lt;h3 id=&#34;前言&#34;&gt;前言&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;Zookeeper作为微服务分布式协调中间件，了解它的原理以及日常开发中的注意事项和可能会出现的问题是有必要的。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;前置知识zab协议&#34;&gt;前置知识：ZAB协议&lt;/h3&gt;
&lt;p&gt;ZAB：Zookeeper Atomic Broadcast（ZAB）崩坏恢复和原子广播协议&lt;br&gt;
1）崩坏恢复：在master节点宕机情况下，其他集群节点会重新选举master节点，快速领导者选举机制：选举规则会参照最大的分代年龄epoch&amp;gt;最大的事务zxid&amp;gt;server id来进行选举，选举过程就是将自己节点投票信息发给其他集群节点，投票信息附带zxid和serverid，&lt;strong&gt;判断是否超过一半的投票选同一个节点&lt;/strong&gt;，那么这个节点就会选举为master。&lt;br&gt;
2）选举完后，就会进行数据同步，将master节点数据同步到slave中，此时对外服务不可用。&lt;br&gt;
3）原子广播：ZAB协议保证消息的一致性和有序性&lt;br&gt;
 一致性：leader发送propasal事务请求（包含zxid），master判断过半机制ack，就认为事务可以提交了，master会提交事务，然后广播提交事务消息，从节点开始提交本事务。一半ack机制，可以看zookeeper是CP，但是不是强一致性；从节点接收propasal后，会将事务写入磁盘。&lt;br&gt;
 有序性：zxid事务id保证全局有序性，每一个slave服务器维持一个FIFO队列，维持局部有序性。&lt;/p&gt;
&lt;h3 id=&#34;zookeeper脑裂&#34;&gt;Zookeeper脑裂&lt;/h3&gt;
&lt;p&gt; Zookeeper脑裂都是出现在集群环境中的。指的是一个集群环境中出现了多个master节点，导致严重数据同步和写入问题，数据不一致等等，如果这种情况出现在线上分布式环境下，会导致服务不可用。&lt;/p&gt;
&lt;h3 id=&#34;出现原因&#34;&gt;出现原因&lt;/h3&gt;
&lt;p&gt; 可能就是网络环境有问题导致节点之间断开，或者节点假死等等，导致一部分slave节点会重新进入崩坏恢复模式，重新选举新的master节点，然后对外提供事务服务。由于心跳超时（网络原因导致的）认为旧的master死了，但其实旧的master还存活着。&lt;/p&gt;
&lt;h3 id=&#34;如何解决脑裂&#34;&gt;如何解决脑裂&lt;/h3&gt;
&lt;p&gt;过半机制，如果集群中某个节点的投票数量大于集群有效节点的一半，就会选出master。这里拿出关键代码：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;// 验证是否符合过半机制，如果符合就会选举新的master节点
public boolean containsQuorum(Set&amp;lt;Long&amp;gt; set){
    // half是在构造方法里赋值的
    // n表示集群中zkServer的个数（准确的说是参与者的个数，参与者不包括观察者节点）
    half = n/2;
    // set.size()表示某台zkServer获得的票数
    return (set.size() &amp;gt; half);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;笔者介绍几种情况，来说明一下几种脑裂的场景&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;比如集群中有6个节点，一个master和5个slave，分两个机房，每个机房分别三台，发生了机房不可通信的情况，如下图：&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1593419532309.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
然后机房B就会产生新的master，如图&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1593419550068.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
这个时候Zookeeper为了防止这样的情况发生，利用了&lt;strong&gt;过半机制&lt;/strong&gt;的这个特性。&lt;br&gt;
上图中，机房B节点为3 小于集群数量的一半，所以，最终上面图中机房B是不会选举出新的master节点的。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;我们再来看一种情况：比如集群中有5个节点，一个master和4个slave，分两个机房，如下图：&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1593419973725.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
如果发生了机房不能通信的情况，那么机房B因为节点是2个，没有超过一半，就不会产生出新的master节点了。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;再来看最后一种情况，比如集群中有5个节点，一个master和4个slave，分两个机房，不同的是master节点在机房B，如下图：&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1593420189914.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
如果发生了机房不能通信的情况，那么机房A节点是3个，超过了一半，就会进入崩坏恢复模式产生新的master节点，那么此时集群中就会出现两个master节点了。如下图所示&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1593420219104.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
那么遇到这种情况Zookeeper是如何处理的？答：旧的leader所有的写请求同步到其他followers节点是会被拒绝的。因为每当新leader产生时，会生成一个epoch，这个epoch是递增的，followers如果确认了新的leader存在，知道其epoch，就会拒绝epoch小于现任leader epoch的所有请求。这个时候旧的master进入恢复模式进行数据同步。&lt;br&gt;
所以按照上面的情况，机房A的所有followers节点正常通信，机房B的所有节点重新进入恢复模式进行数据同步。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;总结：通过Quorums机制来防止脑裂，当leader挂掉之后，可以重新选举出新的leader节点使整个集群达成一致；当出现假死现象时，通过epoch大小来拒绝旧的leader发起的请求，当出现这种情况，旧的leader 进入恢复模式进行数据同步。&lt;/p&gt;
&lt;h3 id=&#34;引出奇数节点&#34;&gt;引出奇数节点&lt;/h3&gt;
&lt;p&gt; 知晓以上场景后，我们知道，2台机器也能选举出master，只不过只要有1个死了zookeeper就不能用了，因为1没有过半。所以2个zookeeper的死亡容忍度为0。同理，要是有3个zookeeper，一个死了，还剩下2个正常的，过半了，所以3个zookeeper的容忍度为1。如果按照这样的机制推理，那么得出2-&amp;gt;0;3-&amp;gt;1;4-&amp;gt;1;5-&amp;gt;2;6-&amp;gt;2  左边是数量，右边是容忍度，所以2n和2n-1的容忍度是一样的，所以可以得出，集群是&lt;strong&gt;奇数个能够节省资源&lt;/strong&gt;。&lt;/p&gt;
&lt;!--下面的奇数节点的作用需要确认 TODO--&gt;
&lt;h3 id=&#34;总结&#34;&gt;总结&lt;/h3&gt;
&lt;p&gt;以上，笔者总结了ZAB协议，到Zookeeper防止脑裂的场景以及如何处理，以及结合例子，Zookeeper集群在奇数节点下的作用。&lt;/p&gt;
&lt;h3 id=&#34;参考&#34;&gt;参考&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;ZooKeeper集群的脑裂问题——https://www.cnblogs.com/shoufeng/p/10591526.html&lt;/li&gt;
&lt;/ul&gt;
">关于Zookeeper奇数节点以及脑裂问题</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://zhangyaoo.github.io/post/jin-rong-ji-ye-wu-xia-fen-bu-shi-shi-wu-bao-zheng-shu-ju-yi-zhi-xing/"" data-c="
          &lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;随着分布式服务架构的流行与普及，原来在单体应用中执行的多个逻辑操作，现在被拆分成了多个服务之间的远程调用。微服务化后，随着带来的服务之间的分布式事务问题，尤其是在金融业务下，分布式事务是保证数据一致性的重要保证。本文着重会讲分布式事务场景和业界主流的解决方案。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;一-引入&#34;&gt;一、引入&lt;/h2&gt;
&lt;p&gt; 资金转账在金融业务下是一个非常重要而且常见的场景，如果因为技术问题导致资金转账错误，导致数据不一致问题，那么就会造成无法预测的后果。&lt;br&gt;
 笔者这里拿银行转账的例子来说（这里的转账有很多场景比如银行卡之间充值提现、银行账户之间的转账等等），比如甲银行账户A向乙银行账户B转账1W：&lt;/p&gt;
&lt;p&gt;同步调用：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;A银行对转出账户执行检查校验，进行账户金额扣减。&lt;/li&gt;
&lt;li&gt;A银行同步调用B银行转账接口。&lt;/li&gt;
&lt;li&gt;B银行对转入账户进行检查校验，进行账户金额增加。&lt;/li&gt;
&lt;li&gt;B银行返回处理结果给A银行。&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1593745125729.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
同步调用问题：&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;如果B银行因为网络原因导致接口不通，那么A调用线程会长时间阻塞。&lt;/li&gt;
&lt;li&gt;如果A扣减后，发送请求后，在网络中丢失了，B银行没有收到请求，导致账户A扣减了，账户B没有加&lt;/li&gt;
&lt;li&gt;如果账户B扣减成功了，由于某种原因比如网络异常没有及时回调给甲银行，那么账户A就认为是异常请求，则会回滚事务，导致数据不一致。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;再来看一下异步调用：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;A银行对转出账户执行检查校验，进行账户金额扣减。&lt;/li&gt;
&lt;li&gt;主线程将请求数据异步写入队列MQ&lt;/li&gt;
&lt;li&gt;真正消费者程序对B银行进行远程调用&lt;/li&gt;
&lt;li&gt;B银行对转入账户进行检查校验，进行账户金额增加。&lt;/li&gt;
&lt;li&gt;B银行返回处理结果给A银行。&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1593743096206.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
异步调用问题：&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;如果账户A扣减本地事务成功了，但是消息发出后，因为网络原因或者其他宕机原因，导致消息未发送成功，没有进行B账户远程调用，导致本地事务和消息不一致性。&lt;/li&gt;
&lt;li&gt;MQ消费端程序如果消费消息成功，请求银行成功了，但是回传ACK给MQ失败了，那么回导致消费端程序重复消费问题，那么就会出现重复转账的问题。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;异步调用解决了同步调用的主线程阻塞问题，但还是没有解决数据一致性问题。而且引入MQ中间后，还要考虑到本地事务和MQ消息一致性问题，还有其他的引入后的维护工作，比如消息丢失，消息重发等等问题。&lt;/p&gt;
&lt;h2 id=&#34;二-分布式事务解决方案&#34;&gt;二、分布式事务解决方案&lt;/h2&gt;
&lt;p&gt; 讲到了分布式事务，自然离不开分布式系统的一些基本原则和定理：CAP原则和BASE理论，相信读者应该都知道，这里不做过多阐述。业界根据这些规则和理论，衍生出了各种分布式事务解决方案：XA规范，2PC，3PC，本地消息表方案，基于消息中间件的最终一致性方案，TCC方案，阿里的SEATA，SAGA方案和最大努力通知等等。&lt;br&gt;
 以上每个方案都有自己的应用场景，就拿2PC来说，MySQL的事务型日志redolog二段提交（redolog(prepare)--》binlog--》redolog(commit)）保证binlog和redolog数据一致性，Zookeeper的proposal事务二段提交（半数以上ack返回成功表示写入数据成功）保证leader和foller的数据一致性，这些都是2PC的应用。&lt;br&gt;
 金融场景下类似资金业务需要保证最终一致性解决分布式事务，不需要保证转账实时性。所以本地消息表、基于MQ中间件的最终一致性等柔性方案是首选的方案。这些基于消息的分布式事务，本质上就是，本地事务+从事务，从事务从消息中获取信息进行本地提交，这里保持&lt;strong&gt;异步事务机制、只能保证最终一致性&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&#34;21-利用本地消息表思想解决一致性问题&#34;&gt;2.1 利用本地消息表思想解决一致性问题&lt;/h3&gt;
&lt;p&gt; 一般来说，跨行转账的原理，会存在一个中国人民银行的中间人角色来操作转账，但不在本次讨论的范围内。&lt;br&gt;
 业界银行转账大部分都是同步转账，异步获取转账结果，包括第三方支付平台对接银行都是这样玩的。这里笔者就利用本地消息表思想来具体叙述数据一致性是如何保证的，老规矩先放图：&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1603274563955.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
其中交易记录表大概长这个样子：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;字段&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;id&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;自增ID，没有业务意义&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;trade_order_num&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;交易订单号，作为转账记录唯一标识&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;source_account_num&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;交易转出方账户ID&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;target_account_num&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;交易收款方账户ID&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;status&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;状态机，0=预创建，1=转账中，2=转账成功，3=转账失败&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;pay_success_time&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;记录转账成功时间&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;create_time&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;记录创建时间，可作为窗口时间内判断标准&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;update_time&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;记录 更新时间&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;账户表大概长这个样子：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;字段&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;id&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;自增ID，没有业务意义&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;account_num&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;账户ID&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;current_amt&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;当前账户余额&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;lock_amt&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;冻结金额，用来记录临时状态的核心转账数据 。真实余额=current_amt-lock_amt&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;图中的步骤大致分为8步，这里细致讲一下每一步的详细步骤，分别是：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;插入初始状态的交易数据。 这一步骤的目的是保证发起同步转账请求和本地初始事务一致性，还有一个目的就是生成转账记录唯一标识，用来标识本次转账&lt;/li&gt;
&lt;li&gt;同步发起转账请求，带上唯一标识以及其他的业务参数&lt;/li&gt;
&lt;li&gt;银行乙会校验参数信息，并且同步返回转账通知，类似“我接收到了你的请求了，我还有其他事情，我等会返回结果给你”&lt;/li&gt;
&lt;li&gt;会根据同步的转账通知来判断这次交易是否合法，然后会记录结果到交易表中。这里并且需要冻结账户的一部分金额，作为临时中间态数据。并且需要更新本地交易表状态为转账中&lt;/li&gt;
&lt;li&gt;银行乙需要记录本次交易记录，插入一条交易中的数据，直至回调转账结果给银行甲，将这条记录置为转账成功。并且银行乙自己生成的收款交易流号，然后放入到回调结果中，传给银行甲&lt;/li&gt;
&lt;li&gt;异步回调结果给银行甲，其中回调参数重要的有银行甲的唯一的转账标识，还有银行乙自己生成的收款交易流号&lt;/li&gt;
&lt;li&gt;根据异步回调的状态，更新交易状态数据，如果成功，那么会扣减账余额，并且释放冻结金额，如果失败，直接释放冻结金额。此时算是正常的一条&lt;strong&gt;流程闭环&lt;/strong&gt;走完&lt;/li&gt;
&lt;li&gt;当然不是所有的业务能够正常走完流程闭环，也会出现各种原因导致不能走完。为了保证数据一致性，会增加一个补偿程序，定时去拉取异常数据，异常数据指的是交易状态为0和1并且&lt;strong&gt;不在正常窗口业务&lt;/strong&gt;时间内的数据（0和1属于中间态，而2或者3数据终态），窗口时间指的是正常业务从开始到结束的时间。&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;如果异常数据状态是0，那么表示有可能是本地更新事务失败了，也有可能是请求或者返回在网络中丢失了，补偿程序里面会根据本地的表数据判断是哪个步骤除问题了，就比如说本地数据没有银行乙的交易流水号，那么就是网络出问题了，后面就可以进行补偿操作&lt;/li&gt;
&lt;li&gt;如果异常数据状态是1，那么表示可能是银行乙接口有问题或者网络有问题原因导致没有及时回调，这个时候补偿程序就用银行乙的交易流水号是去查询交易是否完成，然后更新自己本地的数据。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;以上流程是一次正常的交易过程，当然不是所有的交易流程都是这样走的，不过大部分转账流程和上述步骤相类似，其中的细致步骤在每个交易系统中略有不同。&lt;/p&gt;
&lt;p&gt;总结起来，利用本地消息表思想能够解决上面第一部分文章的同步调用的缺点，能够解决第二个第三 个问题，但是第一个问题就无法解决了，只要是同步调用都会出现这个问题，不过有其他方式去解决这个问题。以笔者认知来说，银行转账的业务都是同步调用的。出现接口阻塞这个问题，需要设置超时时间，如果超过超时时间，就记录下这条交易，异步放入&lt;strong&gt;重试队列&lt;/strong&gt;，一段时间后进行&lt;strong&gt;重试&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&#34;22-事务消息解决本地事务和mq消息一致性问题&#34;&gt;2.2 事务消息解决本地事务和MQ消息一致性问题&lt;/h3&gt;
&lt;p&gt; 转账业务，如果用异步的话，当出现MQ问题或者消费也者程序出现消息挤压或者消费者端出现问题 的话，那么整个业务时间线会拉的非常长。所以笔者认为异步不适合这种业务，异步&lt;strong&gt;本质上&lt;/strong&gt;是对下游服务的一个缓冲，适合在自己系统中使用，不适合跨系统或者三方调用。当然不是所有的场景都不合适，如果流量非常大话，对方系统有限流机制，使用MQ也算是一种解决方案，这还是看具体业务。&lt;/p&gt;
&lt;p&gt; 什么样的场景适合使用MQ？一般来说在需要限流削峰、异步解耦等场景使用，所以还是拿上面的图，图中标框的部分业务适合用MQ来解决&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1603790962781.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;p&gt; 如果用MQ来做的话，那么会有如下图步骤：&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1603792233049.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
图中的步骤大致分为6步，这里细致讲一下每一步的详细步骤，分别是：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;消息生成者发送消息，broker接受消息&lt;/li&gt;
&lt;li&gt;MQ broker收到消息，随即将消息进行持久化，并且存入库。这一步是防止MQ因为物理原因宕机导致的消息丢失，并且入库的时候要判断幂等，防止没有及时返回ack，导致生产者重发消息。&lt;/li&gt;
&lt;li&gt;返回ACK给生产者。如果不及时返回或者长时间没有返回，生产者会认为这条消息发送失败，会重新发送。&lt;/li&gt;
&lt;li&gt;MQ push消息给对应的消费者或者消费者主动来pull消息，然后等待消费者返回ACK&lt;/li&gt;
&lt;li&gt;如果消息消费者在指定时间内成功返回ack，那么MQ认为消息消费成功，在存储中删除消息，即执行第6步；如果MQ在指定时间内没有收到ACK，则认为消息消费失败，会尝试重新push或者pull消息,重复执行4、5、6步骤&lt;/li&gt;
&lt;li&gt;MQ删除消息&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt; 以上为一条正常的消息从生产到消费的过程，每一步都是不可或缺的。而且我们可以看到，当引入中间件MQ后，消费端业务需要保持幂等。&lt;/p&gt;
&lt;p&gt; 回到上面文章最开始的部分，并没有解决异步调用问题一。没有彻底解决本地事务和消息不一致性。所以这个时候，就需要事务消息解决本地事务和MQ消息一致性问题了，笔者重新画了一张图来说明一下事务消息是如何做的：&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1603873494446.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
图中的步骤大致分为几步，分别是：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;生产者发送一条prepare消息&lt;/li&gt;
&lt;li&gt;MQ接受到消息后，先进行持久化,状态为待确认的消息&lt;/li&gt;
&lt;li&gt;返回ACK给消息生产者&lt;/li&gt;
&lt;li&gt;执行本地事务：扣减账户余额，插入交易流水。如果这个事务执行失败，那么相当于业务执行失败，抛给用户交易失败&lt;/li&gt;
&lt;li&gt;执行完成后，将结果发送执行结果给MQ&lt;/li&gt;
&lt;li&gt;根据结果将消息commit或者rollback  commit：将消息状态置为已确认  rollback：将消息删除&lt;/li&gt;
&lt;li&gt;采用pull或者push消费已确认的消息 ，后面流程大致和普通的流程都一样&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt; 这里还没有体现另外一个流程，就是如果消息待确认状态在一定时间内没有转换为已确认，那么MQ会回查本地事务执行状态是否成功。这个是为了保证在第五步发送的消息在网络中丢失或者消费者宕机等情况下，能够回滚。&lt;br&gt;
 以上是事务消息大致的流程，能够解决本地事务和MQ消息一致性问题，这里强调的是，不管是是事务消息还是普通的消息，消费端都需要做幂等处理。&lt;br&gt;
 总结来说，&lt;strong&gt;ack+补偿+重试+幂等&lt;/strong&gt;是保证一致性的关键。&lt;/p&gt;
&lt;h4 id=&#34;221-事务消息常见问题&#34;&gt;2.2.1 事务消息常见问题&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;如果consumer消费失败，是否需要producer做回滚呢？&lt;br&gt;
不需要，MQ作用要保证的就是&lt;strong&gt;最终一致性&lt;/strong&gt;，如果consumer消费失败，就让它进行重试直至成功。如果重试超过一定次数的话，那么就人工介入。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;三-其他方式保证数据一致性&#34;&gt;三、 其他方式保证数据一致性&lt;/h2&gt;
&lt;p&gt; 当然，保持数据一致性不光是分布式事务来保证，业务上还要配合其他的辅助来保证，这里笔者就列举几种&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;全链路幂等&lt;br&gt;
全链路幂等保证不产生脏数据，保护核心流程正常执行。&lt;/li&gt;
&lt;li&gt;重试机制&lt;br&gt;
对异常业务进行重试，超过指定重试次数仍失败的进行人工介入。&lt;/li&gt;
&lt;li&gt;业务对账&lt;br&gt;
业务内部准实时对账，比如业务发生后充值提现，对比用户余额是否正确，用户业务流水是否正确。&lt;br&gt;
T+1日对账，程序或者人工定时扫描核心业务数据，保证当日数据准确。对账后自动检测并且修复重试业务&lt;/li&gt;
&lt;li&gt;业务指标监控&lt;br&gt;
监控数据库中的订单预占资金没有释放，状态机是不是最终态监控，单位窗口时间内业务状态是否异常，账户中的预扣减金额是否释放，业务重试次数是否超过阈值等等业务监控。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;四-总结&#34;&gt;四、总结&lt;/h2&gt;
&lt;p&gt; 分布式场景，要用分布式的思维去思考问题。要考虑任何的超时，断电，维护不同物理存储的数据的可能存在的状态不一致的场景，说白了要面向失败编程。&lt;/p&gt;
&lt;h2 id=&#34;五-参考&#34;&gt;五、参考&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;有赞出金系统——https://tech.youzan.com/build-a-withdraw-sys/&lt;/li&gt;
&lt;li&gt;分布式事务的思考——https://www.cnblogs.com/sujing/p/11006424.html&lt;/li&gt;
&lt;li&gt;阿里云RocketMQ文档——https://help.aliyun.com/document_detail/43348.html&lt;/li&gt;
&lt;/ul&gt;
">金融级业务下分布式事务保证数据一致性</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://zhangyaoo.github.io/post/er-jin-zhi-fan-zhuan/"" data-c="
          &lt;h4 id=&#34;题目描述&#34;&gt;题目描述&lt;/h4&gt;
&lt;p&gt;给定一个32位整数 . 输出二进制表示反转后的值.&lt;br&gt;
例如 input 43261596（二进制 00000010100101000001111010011100）&lt;br&gt;
返回 output 964176192（二进制 00111001011110000010100101000000）&lt;/p&gt;
&lt;p&gt;目前笔者就想到了时间复杂度在O(N)的解决思路：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;循环判断输入数据的低位是0还是1，具体判断方法是和1进行与操作&lt;/li&gt;
&lt;li&gt;如果判断是，返回的结果+1，不是1那么不做任何处理&lt;/li&gt;
&lt;li&gt;每次循环，input的数据向左移一位，output数据向右移动一位&lt;/li&gt;
&lt;li&gt;循环32次，返回结果&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;/**
    *  二进制数据反转
    */
public class BitReverse {

    public static int reverse(int n) {
        int result = 0;
        for (int i = 0; i &amp;lt; 32; i++) {
            result = result &amp;lt;&amp;lt; 1;
            if ((n &amp;amp; 1) == 1) {
                result++;
            }
            n = n &amp;gt;&amp;gt; 1;
        }
        return result;
    }

    public static void main(String[] args){
        System.out.println(reverse(1&amp;lt;&amp;lt;30));
        System.out.println(1&amp;lt;&amp;lt;30);
    }
}
&lt;/code&gt;&lt;/pre&gt;
">O(N)时间复杂度下，二进制反转</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://zhangyaoo.github.io/post/guan-yu-xi-tong-xing-neng-ping-jing-yu-ce-he-xi-tong-xing-neng-you-hua/"" data-c="
          &lt;h3 id=&#34;前言&#34;&gt;前言&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;对于任何系统，都会存在系统性能瓶颈，这里笔者作为一名Java工程师列出了自己在工作中的优化思路，仅供参考。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;一-系统性能预测&#34;&gt;一、系统性能预测&lt;/h2&gt;
&lt;p&gt; 任何一个系统都是从0到1慢慢发展的，当系统业务随着时间的推移，业务量和流量随之增大，系统性能就随着凸显出来。这个时候，开发人员和架构师要从架构层面、代码层面、产品业务层面等一一去演进业务系统来维持高流量下系统稳定性。&lt;/p&gt;
&lt;p&gt; 现在服务都是微服务部署开发，如果要模拟服务压测的话要在本地开启相同的服务，前提是机器配置是一样的。而且需要将线上的持久化数据同样copy到本地数据库中，这样才能真正模拟线上的环境。拿单台机器进行压测，压测的对象可以是某个核心的接口或者业务模块（这个接口可以是日志服务中统计的访问量比较高的具体的接口API），压测的指标可以是吞吐量，平均响应时间，最大响应时间，TPS，QPS等等。&lt;/p&gt;
&lt;p&gt; 通过性能指标可以度量目前存在的性能问题，同时作为性能优化的评估依据。具体的指标主要是要分析系统的QPS、TPS、平均响应时间以及最大响应时间，我们预测一个单体的应用能够承受多少的并发量，看这这些指标是否能够达到我们预期的值，比如作为一个健康的系统，最大响应时间不超过1s。后面进行压测时候，观察流量巅峰时刻观察系统的运行情况。以下就性能分析优化展开总结。&lt;br&gt;
&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;二-系统性能分析优化&#34;&gt;二、系统性能分析优化&lt;/h2&gt;
&lt;h3 id=&#34;1-硬件方面&#34;&gt;1、硬件方面：&lt;/h3&gt;
&lt;h5 id=&#34;cpu&#34;&gt;CPU：&lt;/h5&gt;
&lt;p&gt; 在压测的时候观察CPU的占用情况，是否长期处于100%状态，正常来说80%以下是正常的。如果非常低，那么说明系统不是在做IO密集型运算动作，性能瓶颈是在其他方面，不是在CPU上面，具体的操作方法可以用top命令查看。&lt;br&gt;
 以笔者经验来看，一般CPU飙高的原因无非三种：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;第一种就是代码中存在死循环，并且循环中有大量的CPU计算操作；&lt;/li&gt;
&lt;li&gt;第二种就是多线程并发下，竞争相同的资源导致大量线程获取不到资源，如果此时线程进行自旋操作，不释放CPU资源，那就导致CPU飙升；&lt;/li&gt;
&lt;li&gt;第三种就是代码中有内存泄漏，导致内存一直处于阈值状态，GC线程会持续GC，导致CPU飙高。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt; 上面三种情况中第二种和第三种情况在日常开发工作中会遇到，对于第二种情况对于自旋锁情况，一般会用CAS乐观锁去实现，并且设置一定的超时时间和重试次数，然后返回失败或者进入阻塞队列释放CPU分片，防止线程一直占用CPU资源。&lt;br&gt;
 对于第三种情况，就是代码的BUG，开发过程中要注意泄漏的问题，就比如多线程操作链表，如果没有做同步的锁，那么很有可能导致链表的引用指针混乱，引起内存泄漏。&lt;br&gt;
 以上，如果我们开发工作中避免了上述几种情况，CPU就能够发挥它应该有的能力，提升系统性能。同时，开发人员做好硬件CPU监控是非常有必要的。&lt;/p&gt;
&lt;h5 id=&#34;内存&#34;&gt;内存：&lt;/h5&gt;
&lt;p&gt;  在Java中，内存JVM是一个很重要的指标，这个关乎到系统是否可以稳定运行。我们可以借助三方工具可以查看系统的JVM内存的运行情况，笔者提供几个通用的预测内存的运行情况的思路：&lt;br&gt;
- 每秒占用多少内存？&lt;br&gt;
- 多长时间触发一次Minor GC？&lt;br&gt;
- 多长时间触发一次Major GC？&lt;br&gt;
- Minor  GC耗时多久？Major  GC耗时多久？&lt;br&gt;
- 会不会频繁因为Survivor放不下导致对象进入老年代？&lt;/p&gt;
&lt;p&gt;在日常开发中，开发人员需要关注的就是，判断系统JVM是否有频繁FULL GC和频繁YOUNG GC，如果有，那么会严重影响系统性能。笔者就这两个方面去分析一下&lt;br&gt;
   1、&lt;strong&gt;频繁FULL GC&lt;/strong&gt; ：首先我们应该要了解到频繁FULL GC危害，一般的中大型系统，系统的JVM会设置很大，比如会给堆内存分配4~8G的空间，因为遍历对象图的过程中堆越大，遍历时间就会长，而且如果垃圾越多，垃圾回收也会拉长整个GC的时间，这就导致每一次FULL GC会有长时间的STW，影响系统稳定性。然后我们要清楚导致触发Full GC的场景，这里列出了可能会导致的几个场景：&lt;br&gt;
  1）大对象&lt;br&gt;
  2）方法区meta space空间占满&lt;br&gt;
  3）年轻代的存活的生命周期长对象一直汇入老年代，导致GC&lt;br&gt;
  4）内存泄漏导致空间不足进而GC&lt;br&gt;
这里笔者就拿内存泄漏（内存泄漏指的是有引用无法被回收但是没有用的对象持续增长）来说，一般如果有内存泄漏。大概的内存监控图长这个样子&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1592463486063.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
这样导致的后果就是，频繁的FULL GC，最后内存一直持续增长到爆满，然后FULL GC执行间隔缩短，最终会导致GC线程持续GC，CPU使用率会直线飙升，导致系统瘫痪。&lt;br&gt;
    2、 &lt;strong&gt;频繁 YOUNG GC&lt;/strong&gt;  ：YOUNG GC如果过于频繁的话，一般是短周期小对象较多，这时候可以从 Eden 区/新生代设置的太小了这个方面考虑，看能否通过调整-Xmn、-XX:SurvivorRatio 等参数设置来解决问题&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;这里笔者以自己开发经验，提供一些“简单的”JVM优化拙见&lt;/strong&gt;：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;尽量将新生代的垃圾回收掉，不让存活对象进入老年代，因为老年代的GC代价比年轻代高，这里可以设置分代年龄-XX:MaxTenuringThreshold=XX&lt;br&gt;
  例子1：比如说业务上一分钟产生几百兆的数据，而且需要存活一分钟，如果一分钟YGC的次数少于默认分代年龄，那么对象会进去老年代引发FGC，FGC会引起更大的停顿时间&lt;br&gt;
  例子2：如果说对象都是一些短期对象，那么可以设置分代年龄更小，因为长期对象肯定是大对象或者单例对象永驻内存的，这样可以腾出空间给新生代GC，避免新生代频繁GC&lt;/li&gt;
&lt;li&gt;增加新生代内存的大小，防止导致频繁的minor GC，这样老年代的Major GC频率也会降低&lt;/li&gt;
&lt;li&gt;尽量将大内存的服务，拆分成几个相同服务，也就是多实例部署，分散堆内存资源，避免堆大内存导致GC时间过长（这个和G1分区回收思想相似）&lt;/li&gt;
&lt;li&gt;每个线程占用的内存不应过大或者过小，不然会导致OOM&lt;br&gt;
  如果线程内存过小，会导致线程里面的栈内存小，临时变量如果超出这个阈值就会无法分配栈，导致栈溢出，出现stackoverflow&lt;br&gt;
  如果线程内存过大，在多线程并发下，如果线程数量过多，会占用非常多JVM内存，有内存溢出的风险&lt;/li&gt;
&lt;li&gt;合理设置垃圾回收器，在大内存或者在内存碎片化环境下，G1垃圾回收器会有很好的效果&lt;br&gt;
  G1垃圾回收器是Java9默认回收器，G1能够在指定的停顿时间内，根据每个region的回收价值，选择可以去回收的region，并且存活对象移动复制是多线程进行的。这里要注意如果设置停顿时间的话，不能设置太小，因为太小会导致每次进行回收的region太少，导致垃圾回收速度更不上垃圾生产的速度，这样随着时间推移，系统垃圾对象会越来越多，占满JVM&lt;/li&gt;
&lt;li&gt;对象生命周期的分布情况：如果应用存在大量的短期对象，应该适当增大年轻代 -Xmn；如果存在相对较多的持久对象，老年代应该适当增大。-Xms -Xmx&lt;/li&gt;
&lt;li&gt;Xms和Xmx也设置为相同，这样可以减少内存自动扩容和收缩带来的性能损失&lt;/li&gt;
&lt;li&gt;设置大对象对象的大小，一般系统中大对象大部分都是一些系统的缓存，像这些对象尽早让它们的进入老年代，避免占用新生代的空间。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;以上，合理分配JVM内存资源以及做好系统内存的监控机制是我们系统稳定性运行的保障。&lt;/p&gt;
&lt;h5 id=&#34;网络负载和io&#34;&gt;网络负载和IO&lt;/h5&gt;
&lt;p&gt;来一张IO发生场景图片：&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1593333928024.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
 对于磁盘IO，我们可以用Linux下的iostat命令去查看当前IO负载的情况，比如r_wait和w_wait指标，这些指标较大则说明I/O负载较大，I/O等待比较严重，磁盘读写遇到瓶颈。这个时候我们要看压测的接口是否有文件读取和写入的操作，如果有说明接口性能瓶颈在于文件读写，这个时候可以利用文件buffer缓存API等功能进行优化，或者可以用异步的方式进行文件读写。&lt;br&gt;
 笔者在开发中就遇到因为IO问题带来的线程资源耗尽的线上问题：我们系统业务在借贷业务成功后，要生成借款协议，协议是一个PDF文件，当时主业务逻辑完成后同步调用生成PDF的逻辑，因为当时大流量并发，导致整个借贷业务性能瓶颈就在磁盘IO上，CPU处于空闲状态，借用网上的一个图，TOP命令可以看出IO花费的时间在76.6%，后面优化后就多线程异步处理。&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1593334249512.webp&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;p&gt; 对于网络负载，因为网络负载或者网络堵塞是不受控制的，这个涉及到底层的TCP通信的优化（比如利用滑动窗口和拥塞控制），这个就不展开讨论。工程师可控范围可以是选择IO读写高效率的中间件，比如redis、tomcat、activeMq、nginx、dubbo、netty等，这些中间件的底层IO模型的是多路复用IO，多路复用IO指的是一个IO线程能够服务于多个socket连接，线程监听每个连接的资源描述符。如下图所示：&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1593334346151.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;p&gt; 分布式微服务环境下，服务之间的RPC同步调用会非常频繁，随之服务之间的网络负载会影响到整个系统的服务性能，因此，每个服务的机器放置到同一个局域网下性能效果会很好。而且，对于服务之间的调用，最好利用自研或者第三方中间件去监控服务链路调用的整体情况（比如Zipkin或者SkyWalking ）,并且要合理设置服务与服务之间的超时时间，避免因为网络原因导致服务线程池耗尽，导致OOM。&lt;/p&gt;
&lt;h3 id=&#34;2-中间件层&#34;&gt;2、中间件层&lt;/h3&gt;
&lt;p&gt;  这里中间件，泛指数据存储层，以笔者经验来看，大多数系统性能问题和瓶颈都是与数据存储相关，这里笔者就拿这方面展开讨论总结。&lt;/p&gt;
&lt;h5 id=&#34;mysql&#34;&gt;MySQL&lt;/h5&gt;
&lt;p&gt;一般来说MySQL在很多线程更新同一行的场景下，TPS性能曲线如图所示，参考丁奇的《秒杀场景下MySQL的低效》&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1592893242022.png&#34; alt=&#34;秒杀场景下MySQL的低效&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
图中我们可以看到，线程数在6的时候TPS达到巅峰2W，随着线程数的增长，TPS会随之降低。在高并发场景下，可以根据这个结论来进行优化，比如，当有瞬间大流量冲击数据库时候，我们可以进行数据缓冲，比如用队列削峰，开启6个线程消费，然后访问数据库。&lt;br&gt;
当然这个看业务场景，如果是对同一个资源进行竞争的话，这个证削峰是可行的。但是，如果场景是每一个线程对不同资源进行访问修改时候，不涉及资源竞争的话，那么就不要进行削峰处理，直接访问数据库即可，当然这个也要考虑到MySQL的性能问题。&lt;br&gt;
举个例子，就拿光插入数据的性能测试来说（没有建唯一索引），4核4G的7200转的机械硬盘机器配置，最高能够承受7500的并发插入数。[参考MySQL性能压测]&lt;/p&gt;
&lt;p&gt;以上算是一种在特定场景下的优化的思路，下面笔者讨论一下日常开发中通用的MySQL优化：&lt;br&gt;
1、避免长期的事务锁占用，避免锁范围过大，避免单个资源的并发竞争&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;首先我们知道数据库Innodb存储引擎的RR和RC隔离级别下，类似update语句，锁的释放时机是在事务提交之后，这个叫做两阶段锁协议。所以为了避免事务之间锁同一行数据出现长时间的互相等待的场景，&lt;strong&gt;要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放&lt;/strong&gt;。&lt;br&gt;
举个例子，个人账户A转账给公共账户B，流程是：开启事务——》给 B 的账户余额增加钱；从账户 A 账户余额中扣除钱；记录一条交易日志——》结束事务。因为公共账户B可能被多个线程修改，所以可以优化为：从账户 A 账户余额中扣除钱；记录一条交易日志；给 B 的账户余额增加钱。&lt;/li&gt;
&lt;li&gt;然后，要尽量将锁细化，一个大锁可以分割为多个锁，类似&lt;strong&gt;分段锁机制&lt;/strong&gt;。拿笔者公司业务来说，比如APP上投资某一个产品标（包含了标的开始募集时间、结束时间、可投金额、年利率等等），在到达开始募集时间会有一段时间的高并发投标，这个时候会对具体标的行数据进行频繁的更新操作，就是扣减剩余可投金额，如果其他耗时操作中有对同一资源进行竞争的话，那么产品锁持有时间过长，导致性能低。如果有高并发秒杀下单等动作，会造成行锁抢占问题。&lt;br&gt;
这个时候，优化思路是，将这个产品标在数据库分为10份，每一份的可投金额减少10倍，每一个投标请求进行随机路由分配到这10个小的产品标中。这样就减少锁的并发竞争问题，优化性能。&lt;br&gt;
但是笔者因为遇到这种分段锁的问题导致的&lt;strong&gt;死锁&lt;/strong&gt;问题，场景是这样的，当一份投标的金额大于其中一份产品金额的话，会持有这份产品的锁，并且循环获取下一份小产品，这个时候如果有两个线程都大于小产品金额的话，有概率会产生死锁问题，笔者最终通过顺序加锁以及加上锁的过期时间解决了这个问题。&lt;/li&gt;
&lt;li&gt;最后，对同一个资源的并发竞争，举个例子，像12306抢票、商城活动秒杀等都是对同一个有限资源进行竞争的场景，笔者认为，这种场景是非常难处理的，需要考虑到锁同步数据安全、并发竞争性能瓶颈、超卖等问题，都是会影响C端用户实际的体验的。&lt;br&gt;
像这种场景，优化的思路就是——&amp;gt;&lt;strong&gt;能用分段锁的就不要用悲观锁，能用乐观锁的就不要用悲观锁，能用无锁编程的就不要用锁，能用异步的场景就不要用同步的场景，能在内存操作的就不要再放到数据库磁盘层面操作&lt;/strong&gt;。当然，有些对于数据安全性要求很高的场景，比如金融，加锁是必要的。这个就是业务一致性和并发的折中考虑，这个需要考虑具体的业务场景。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;2、关闭死锁检测&lt;br&gt;
MySQL默认开启死锁检测，概念：每当一个事务被锁的时候，就要看看它所依赖的线程有没有被别人锁住，如此循环，最后判断是否出现了循环等待，也就是死锁。死锁检测对数据库有非常大的性能影响，会消耗CPU资源，最后会压垮数据库。&lt;br&gt;
在这种并发场景下可以关闭死锁检测功能，会有明显的性能提升。当然关闭死锁检测也会带来问题，比如当死锁发生时，会一直持有锁资源，直至到超时时间后，释放，这段等待的时候可能会造成线程持续等待造成严重后果。所以为了避免死锁的发生，对行资源进行加锁的时候可以根据ID主键等进行&lt;strong&gt;顺序加锁&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;3、SQL优化&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SQL避免多表连接查询、in和exits合理应用、考虑索引失效场景&lt;/li&gt;
&lt;li&gt;在经常查询和排序的列上加索引，对离散度不高的不建议加锁，遵循索引规范&lt;/li&gt;
&lt;li&gt;在写场景多余读场景的索引选择，唯一索引和普通索引的选择&lt;/li&gt;
&lt;li&gt;尽量进行覆盖索引，避免回表查询&lt;/li&gt;
&lt;li&gt;尽量建立联合索引，来进行索引复用&lt;/li&gt;
&lt;li&gt;字符串的前缀索引的建立&lt;/li&gt;
&lt;li&gt;用explain分析整个SQL的执行情况，包括执行计划、索引分析&lt;/li&gt;
&lt;li&gt;修改数据比较多的字段场景尽量加索引，尽量使用行锁，避免表锁&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;4、在大数据量的情况下（一般单表超2000W）的优化思路：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;加缓存，对于高并发读场景用缓存，一级缓存Redis或者二级缓存Cache&lt;/li&gt;
&lt;li&gt;架构层面MySQL就做主从复制或主主复制，读写分离，可以在应用层做，效率高&lt;/li&gt;
&lt;li&gt;垂直拆分，根据你模块的耦合度，将一个大的系统分为多个小的系统，也就是分布式系统；&lt;/li&gt;
&lt;li&gt;水平切分，因为水平切分会增加代码开发复杂度，所以能尽量避免就不要做。针对数据量大的表，对于日志流水、配置型等类型数据，进行归档操作；对于状态业务数据进行分库分表，这里就不展开讨论。其次，要选择一个合理的sharding key，为了有好的查询效率，表结构也要改动，做一定的冗余；&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;redis&#34;&gt;Redis&lt;/h5&gt;
&lt;p&gt;Redis作为开发人员接触最频繁的中间件，首先，笔者先拿出官网给出的Redis性能测试结果：从下图可以得出结论：redis单机测试结果是TPS是7W,QPS只能比这个数据更高。&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1592983835284.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
当使用了管道pipline后性能大约提升了6倍，如下图所示&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1592986207480.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;p&gt;根据官网的文档，影响Redis性能有以下因素，笔者认为开发人员做一些基准测试压测以及日常开发中使用Redis的时候，注意这些优化点，就能高效使用Redis：&lt;br&gt;
1、网络延迟和网络带宽，作为运维人员，最好将服务器和Redis服务部署到同一个局域网内，降低网络延迟。作为开发人员，尽量不要使用大key和大value，因为随着这种数据越来越多，在网络传输的时候会占用大部分网络宽带，举个例子，如果一个redis对象大小超过1KB，当你的QPS达到100万，会把你的千兆路由器的带宽打满，因此网络带宽可能就会成为性能瓶颈。&lt;br&gt;
2、使用pipline，当使用以太网访问Redis时，保据大小保持在以太网数据包大小（约1500字节）以下时，使用流水线进行聚合的命令特别有效。&lt;br&gt;
3、延时删除，当某一个redisObject很大的时候，做删除操作会长时间占有线程持有时间，影响性能，redis新版本有延迟删除的功能。&lt;br&gt;
4、使用scan代替keys，keys会造成严重的性能问题&lt;br&gt;
5、设置内存的大小阈值并且设置好内存缓存淘汰的策略，线上设置LRU策略来淘汰缓存这样做是为了避免物理内存使用完后，造成卡顿的情况。并且线上要避免大量key同时失效的场景，因为redis删除失效的key是循环删除的，并且频繁的删除会促使内存管理器回收内存页，这样也会导致卡顿的现象。&lt;br&gt;
6、connection客户端连接数量，Redis作为一个事件驱动模型，因为base epoll能够实现O(1)时间复杂度的响应操作，因此能够提供很好性能。Redis已经以超过60000个连接为基准，并且在这些条件下仍能够维持50000 q / s的吞吐量，而且具有30000个连接的实例只能处理100个连接可达到的吞吐量的一半，可参考下图（来源官网）：&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1592991673063.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;h5 id=&#34;elasticsearch&#34;&gt;ElasticSearch&lt;/h5&gt;
&lt;p&gt;ElasticSearch可以解决大数据量下的搜索慢问题，这里笔者就拿 死磕ElasticSearch社区作者的优化建议，给出几点在日常开发ElasticSearch的优化方案：&lt;br&gt;
1、尽量将所有数据的一半都缓存在内存当中file cache system 当中&lt;br&gt;
2、将少量（查询字段比较频繁）字段放入ES，其他全量字段放入Hbase中，采用ES + Hbase方式提升查询效率，节省ES存储空间，file cache system的数据就会存的更多&lt;br&gt;
3、缓存预热，可以做一个缓存预热系统，定时查询热点数据将其缓存在filesystem cache 中&lt;br&gt;
4、冷热分离，将访问量高的和冷数据分别放置索引&lt;br&gt;
5、ES ducoment设计，尽量避免连接、父子文档等连接操作，将数据准备好后再存入ES&lt;br&gt;
6、不允许深度分页，页数越大，深度越深，从每一个shard返回的数据就越多，耗时越久。可以通过scroll api游标进行查询。&lt;br&gt;
7、必须限制模糊搜索的长度，不然CPU会飙高，可参考 https://elasticsearch.cn/article/171&lt;/p&gt;
&lt;h3 id=&#34;3-业务层方面&#34;&gt;3、业务层方面&lt;/h3&gt;
&lt;p&gt;每个公司业务层面优化不相同，要根据具体业务场景去优化，别人的方案只能作为参考。&lt;br&gt;
这里笔者就拿金融行业背景下，列举三个优化例子。&lt;br&gt;
1、背景：企业借贷，会从用户的投的银行某个产品的资金池中匹配查找合适的资金，然后进行资金占有，银行真实转账后，生成终态的债权关系。&lt;br&gt;
优化之前：使用同步锁，同一时间只能又一个线程去资金池中匹配资金，这种方案有严重的性能问题，其他线程没有拿到锁之前只能自旋尝试获取锁，损耗CPU资源。&lt;br&gt;
优化之后：去掉同步锁，改成乐观锁，放到数据库做，资金表的字段增加一个标识表示是否占用，线程进来尝试匹配资金，乐观锁去预占资金表，成功表示匹配成功。这里要注意的是，尽量一个借贷匹配一比资金，这样资金池里面的资金锁行范围会减少（因为有多线程抢占资金资源），资金匹配的速度会加快，并且这样优化这样银行转账的次数会减少（如果匹配一批资金就要进行相同数量转账次数），防止多个投资人账户进行银行转账，减少整个借款业务线的耗时，避免其中一个转账出错导致全部要回滚这样的情况。&lt;br&gt;
这里其实还可以进行优化，比如一笔一笔的占有资金，占有失败的continue继续下一笔资金含有，不用一次在一个事务里面占有大量资金，防止大事务执行失败以及出现其他会有死锁的可能性。这里优化的思想就是大事务拆成小事务，防止事务执行失败的概率。&lt;/p&gt;
&lt;p&gt;2、背景：企业借贷，同步请求转异步&lt;br&gt;
优化之前，三方企业借贷请求，是同步调用，因为一条完整的借贷业务线非常长，中间会RPC调用非常多的底层服务以及其他远程接口，这样的话请求到响应时间会拉的非常长，影响C端的用户体验。&lt;br&gt;
优化之后，同步改异步，具体做法是，借贷请求进入系统后，会先生成一个进行中的状态借贷数据插入数据库，然后将唯一标识丢入MQ中，然后就返回成功。这样吞吐量会增加，用户端体验会非常好。&lt;br&gt;
当然如果说要保证高可用，可以利用MQ的事务消息做，利用二阶段提交方式保证MQ能够收到消息。具体方案可以看笔者的这篇文章 &lt;a href=&#34;https://zhangyaoo.github.io/post/jin-rong-ji-ye-wu-xia-fen-bu-shi-shi-wu-bao-zheng-shu-ju-yi-zhi-xing//&#34;&gt;金融级业务下分布式事务保证数据一致性&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;3、背景：C端用户在APP上，某一个标开启募集资金后进行投标，这里的标类似支付宝的理财产品，开始募集的时候会有高并发流量涌入，当APP端用户同时投标，会有大量请求，这就形成了抢购的动作，因为一个产品标的可投金额是有限的，只有少数人能投标成功&lt;br&gt;
优化之前：笔者在上文中提到的，尽管说频繁将更新行锁的数据放到事务的最后， 会有性能提升，但是随着并发数增长，MySQL也会成为性能瓶颈。&lt;br&gt;
优化之后：利用redis的纯内存操作高性能的优点，将产品的可投金额放入缓存redis（这里redis里面的金额比数据库中少保证不超卖），利用redis的decrby命令或者lua脚本，保证产品标剩余可投金额能够进行原子减少，每一次减少成功后，将用户这一次投标的数据丢入MQ中异步处理，消费端做的就是将插入预状态的借款数据、冻结用户金额和减少产品的可投金额放入同一个事务中处理。&lt;br&gt;
上面做的优化能够保证C端用户的良好体验，但是引入各种中间件的话会出现各种问题需要去解决，比如重复投标怎么办，Redis挂了怎么？MQ挂了怎么办？消息丢失怎么办？等一系列问题。&lt;br&gt;
重复投标，可以利用用户标识的唯一token做，短信生成token，设置token失效时间（短信失效时间60s），投标时候校验token是否过期和使用过。&lt;br&gt;
Redis挂，这时候就要考虑持久化和集群哨兵保持redis高可用。&lt;br&gt;
MQ挂了，消息丢失，重复消费等，这时候就要考虑broker的持久化，生产端和消费端的重试机制和ack机制。&lt;br&gt;
以上需要开发人员去应对每一个可能出现问题的场景。&lt;/p&gt;
&lt;h2 id=&#34;三-后续流量增长系统性能优化思路&#34;&gt;三、后续流量增长系统性能优化思路&lt;/h2&gt;
&lt;p&gt;当流量激增的时候，首先要考虑到系统的稳定性和高可用，后续针对特定的场景，分析性能瓶颈，然后再去做并发的优化。这里笔者就&lt;strong&gt;简单的&lt;/strong&gt;列举一下业界的做法，下面每一条读者都可以自行扩展大篇幅深入去了解。&lt;/p&gt;
&lt;h4 id=&#34;高可用&#34;&gt;高可用&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;使用反向代理和&lt;strong&gt;负载均衡&lt;/strong&gt;实现分流，并且实现动态切换主备机器， 网关负载均衡，DNS多机房负载均衡&lt;/li&gt;
&lt;li&gt;通过&lt;strong&gt;限流&lt;/strong&gt;保护应用免受雪崩之灾&lt;/li&gt;
&lt;li&gt;通过&lt;strong&gt;降级&lt;/strong&gt;实现核心服务服务可用，牺牲非核心服务&lt;/li&gt;
&lt;li&gt;通过&lt;strong&gt;隔离&lt;/strong&gt;实现故障隔离和资源隔离，比如线程隔离，对方法或者类具体分配线程数量，防止相互影响&lt;/li&gt;
&lt;li&gt;通过设置合理的&lt;strong&gt;超时&lt;/strong&gt;调用与重试机制避免请求堆积造成雪崩&lt;/li&gt;
&lt;li&gt;通过&lt;strong&gt;回滚&lt;/strong&gt;机制快速修复错误版本&lt;/li&gt;
&lt;li&gt;Redis&lt;strong&gt;集群&lt;/strong&gt;保证高可用，&lt;strong&gt;哨兵&lt;/strong&gt;模式保证故障转移&lt;/li&gt;
&lt;li&gt;Redis MQ消息中间件开启&lt;strong&gt;持久化&lt;/strong&gt;，保证数据不丢；&lt;strong&gt;ack机制&lt;/strong&gt;和&lt;strong&gt;重试机制&lt;/strong&gt;保证数据的可靠性&lt;/li&gt;
&lt;li&gt;分布式服务环境&lt;strong&gt;链路跟踪&lt;/strong&gt;，监控整个服务的服务质量&lt;/li&gt;
&lt;li&gt;硬件资源&lt;strong&gt;监控&lt;/strong&gt;、CPU、内存、负载、IO、堆内存、JVM GC、线程池以及各种中间件监控等等&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;高并发&#34;&gt;高并发&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;利用MQ同步转异步，流量削峰，多线程异步消费&lt;/li&gt;
&lt;li&gt;读场景比较多的接口可以利用缓存Redis，包括热点key缓存预热，多级缓存，比如分布式缓存，本地缓存和CDN缓存。还可以做集群、哨兵、高可用保证Redis性能&lt;/li&gt;
&lt;li&gt;对于强一致的同步下单场景，可以将对MySQL的操作改为Redis，然后利用MQ做异步&lt;/li&gt;
&lt;li&gt;优化JVM，包括新生代和老年代的大小、GC算法的选择等，尽可能减少GC频率和耗时&lt;/li&gt;
&lt;li&gt;非核心业务逻辑、延迟任务逻辑、三方调用逻辑，可以做异步&lt;/li&gt;
&lt;li&gt;对于架构方面，可以做负载均衡集群部署，MySQL主从、分库分表或者归档、Redis集群、多级缓存、分布式垂直拆分部署、搜索场景引入ES等多个方面考虑&lt;/li&gt;
&lt;li&gt;对于程序方面，可以从For循环的计算逻辑优化、批处理机制减少IO、采用时间复杂度更小的数据结构和算法、乐观锁和分段锁和无锁编程减少锁冲突等方面考虑&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;四-总结&#34;&gt;四、总结&lt;/h2&gt;
&lt;p&gt;以上，笔者从硬件层、代码层、中间件层、业务层等不同方向，简单的分析了影响系统性能各个因素，以及提供了简单的优化的思路和例子。因笔者工作经验能力有限，无法做到全面的分析，还望读者能够指正错误以及提供建议。&lt;/p&gt;
&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;
&lt;p&gt;1、秒杀场景下MySQL的低效——丁奇&lt;br&gt;
2、死磕ElasticSearch社区——ElasticSearch优化&lt;br&gt;
3、MySQL性能压测——https://my.oschina.net/u/867417/blog/758690&lt;br&gt;
4、高可用系统方案——https://blog.csdn.net/hustspy1990/article/details/78008324&lt;br&gt;
5、Redis性能测试——https://redis.io/topics/benchmarks&lt;/p&gt;
&lt;!--参考 --&gt;
">系统性能优化的思考和总结</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://zhangyaoo.github.io/post/o1shi-jian-fu-za-du-xia-shuang-xiang-lian-biao-shi-xian-lru/"" data-c="
          &lt;h3 id=&#34;前言&#34;&gt;前言&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;笔者先从linkedHashMap源码中借鉴插入顺序访问的代码，然后然后自己实现了一个LRU&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;linkedhashmap底层的数据结构&#34;&gt;linkedHashMap底层的数据结构&lt;/h3&gt;
&lt;p&gt;linkedHashMap底层结构（顺序访问）：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;1、linkedHashMap维护了每个node的双向链表，初始化时候维护了空的entry header头，新加入的节点放到entry的头部header的next&lt;/li&gt;
&lt;li&gt;2、put还是get都会进行重排序，get entry1 还是put entry1都会先把Entry1从双向链表中删除，然后再把Entry1加入到双向链表的表尾。&lt;/li&gt;
&lt;li&gt;3、遍历访问的时候，会访问header的下一个next节点，这就形成了顺序访问&lt;/li&gt;
&lt;/ul&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1592968145044.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;链表实现&#34;&gt;链表实现&lt;/h3&gt;
&lt;p&gt;实现思路：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;1、数据是直接利用 HashMap 来存放的。&lt;/li&gt;
&lt;li&gt;2、内部使用了一个双向链表来存放数据，所以有一个头结点 header，以及尾结点 tailer。&lt;/li&gt;
&lt;li&gt;3、每次写入头结点，删除尾结点时都是依赖于 header tailer&lt;br&gt;
&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1592220507945.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;import com.google.common.collect.Maps;
import java.util.Map;

/**
 * 线程不安全，同步机制自行控制。
 */
public class LRUCacheV2 {
    /**
     * 缓存map
     */
    private final Map&amp;lt;String, Node&amp;gt; cacheMap;

    /**
     * 头指针
     */
    private Node head;

    /**
     * 尾指针
     */
    private Node tail;

    /**
     * 容量
     */
    private final int cacheSize;

    /**
     * 当前容量
     */
    private int currentCacheSize;

    LRUCacheV2(int capacity){
        cacheMap = Maps.newHashMapWithExpectedSize(capacity);
        cacheSize = capacity;
        currentCacheSize = 0;
    }

    public Object get(String key){
        Node node = cacheMap.get(key);
        if(node != null){
            // 移动到头指针
            move2head(node);
            return node.getData();
        }
        return null;
    }

    public void remove(String key){
        Node node = cacheMap.get(key);
        if(node != null){
            Node pre = node.getPre();
            Node next = node.getNext();
            if(pre != null){
                pre.setNext(next);
            }
            if(next != null){
                next.setPre(pre);
            }

            // 如果删除刚好是头节点或者尾节点，也要移动指针
            if(node.getKey().equals(head.getKey())){
                head = pre;
            }
            if(node.getKey().equals(tail.getKey())){
                tail = next;
            }

            cacheMap.remove(key);
        }
    }

    public void put(String key, Object value){
        Node node = cacheMap.get(key);
        if(node != null){
            // 存在节点的话，就覆盖，并且放到头
            node.setData(value);
            move2head(node);
            cacheMap.put(key, node);
        }else {
            // 不存在节点，构造并且放到头
            if(currentCacheSize == cacheSize){
                // 删除尾node
                String delKey = tail.getKey();
                cacheMap.remove(delKey);

                // 尾指针移动
                Node next = tail.getNext();
                if(next != null){
                    next.setPre(null);
                }
                tail.setNext(null);
                tail = next;

            }else{
                currentCacheSize++;
            }
            node = new Node();
            node.setData(value);
            node.setKey(key);
            // 头指针移动
            move2head(node);
        }
        cacheMap.put(key, node);
    }

    /**
     * 节点移到头
     */
    private void move2head(Node node){
        if(head == null){
            // 初始化head 和 tail
            head = node;
            head.setNext(null);
            head.setPre(null);
            tail = node;
        }else {
            // 如果是相同的Key，啥都不用动，node就是最新的头
            if(node.getKey().equals(head.getKey())){
                return;
            }

            // 截取node
            Node pre = node.getPre();
            Node next = node.getNext();
            if(pre != null){
                pre.setNext(next);
            }
            if(next != null){
                next.setPre(pre);
            }

            // 如果要截取的节点是尾节点，那么尾节点指针也要向前移动
            if(node.getKey().equals(tail.getKey())){
                tail = next;
            }

            // 放在头前面
            head.setNext(node);
            node.setPre(head);
            // node下个指针指向null
            node.setNext(null);
            head = node;
        }
    }

    @Override
    public String toString() {
        StringBuilder sb = new StringBuilder() ;
        Node node = head;
        while (node != null){
            sb.append(node.getKey()).append(&amp;quot;:&amp;quot;)
                    .append(node.getData())
                    .append(&amp;quot;--&amp;gt;&amp;quot;) ;
            node = node.getPre();
        }
        return sb.toString();
    }

    public static void main(String[] args) {
        LRUCacheV2 lruCacheV2 = new LRUCacheV2(4);
        lruCacheV2.put(&amp;quot;1&amp;quot;,&amp;quot;1&amp;quot;);
        lruCacheV2.put(&amp;quot;2&amp;quot;,&amp;quot;2&amp;quot;);
        lruCacheV2.put(&amp;quot;3&amp;quot;,&amp;quot;3&amp;quot;);
        lruCacheV2.put(&amp;quot;4&amp;quot;,&amp;quot;4&amp;quot;);
        lruCacheV2.put(&amp;quot;5&amp;quot;,&amp;quot;5&amp;quot;);
        //lruCacheV2.get(&amp;quot;2&amp;quot;);
        //lruCacheV2.put(&amp;quot;2&amp;quot;,&amp;quot;22&amp;quot;);
        lruCacheV2.remove(&amp;quot;5&amp;quot;);
        System.out.println(lruCacheV2.toString());
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;链表实现v2&#34;&gt;链表实现V2&lt;/h3&gt;
&lt;p&gt;2021.3.15更新&lt;br&gt;
上述的链表有点复杂，没有考虑到利用map的size，没有利用好头尾节点双向特性，笔者重新实现了下，参考leetcode146题&lt;br&gt;
实现的几个要点&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;构造函数中要构造好头尾节点，形成指针闭环，为后续的增删移做好准备&lt;/li&gt;
&lt;li&gt;删除节点的时候，可以根据map的value也就是Node的key，来删除map中的数据，也就是说，可以根据map的key来删除数据，也可以根据map的value中的key来删除数据&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;package com.zyblue.fastim.common.algorithm.distribute;

import java.util.HashMap;
import java.util.Map;

/**
 * @author will
 * @date 2021/3/15 10:18
 */
public class LRUCacheV3&amp;lt;K, V&amp;gt;{
    public static class Node&amp;lt;K,V&amp;gt;{
        public K key;
        public V value;
        public Node&amp;lt;K,V&amp;gt; pre;
        public Node&amp;lt;K,V&amp;gt; next;
        public Node(){}
        public Node(K key, V value) {
            this.key = key;
            this.value = value;
        }
    }

    /**
     * map这样设计的原因是
     * 1、
     */
    private Map&amp;lt;K, Node&amp;lt;K,V&amp;gt;&amp;gt; map = new HashMap&amp;lt;&amp;gt;();

    private int capacity;

    private Node&amp;lt;K,V&amp;gt; head;

    private Node&amp;lt;K,V&amp;gt; tail;

    public LRUCacheV3(int capacity){
        this.capacity = capacity;
        this.head = new Node&amp;lt;&amp;gt;();
        this.tail = new Node&amp;lt;&amp;gt;();
        head.pre = tail;
        tail.next = head;
    }

    private void remove2Head(Node&amp;lt;K,V&amp;gt; node){
        Node&amp;lt;K, V&amp;gt; pre = node.pre;
        Node&amp;lt;K, V&amp;gt; next = node.next;
        pre.next = next;
        next.pre = pre;

        add2Head(node);
    }

    private void removeTail(){
        Node&amp;lt;K, V&amp;gt; next = tail.next.next;
        tail.next = next;
        next.pre = tail;
    }

    private void add2Head(Node&amp;lt;K,V&amp;gt; node){
        Node&amp;lt;K, V&amp;gt; pre = head.pre;
        pre.next = node;
        node.next = head;
        node.pre = pre;
        head.pre = node;
    }

    public V get(K key){
        Node&amp;lt;K,V&amp;gt; node = map.get(key);
        if(node == null){
            return null;
        }
        remove2Head(node);
        return node.value;
    }

    public void put(K key, V value){
        Node&amp;lt;K,V&amp;gt; node = map.get(key);
        if(node == null){
            // 利用map的size
            if(map.size() &amp;gt;= capacity){
                // 去除尾部节点
                removeTail();
                // 删除map的node
                map.remove(tail.next.key);
            }
            Node&amp;lt;K,V&amp;gt; nodeAdd = new Node&amp;lt;&amp;gt;(key, value);
            add2Head(nodeAdd);
            map.put(key, nodeAdd);
        }else {
            node.value = value;
            remove2Head(node);
        }
    }
}

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;参考：&lt;br&gt;
1、https://www.iteye.com/blog/gogole-692103&lt;br&gt;
2、https://crossoverjie.top/2018/04/07/algorithm/LRU-cache/&lt;/p&gt;
">O(1)时间复杂度下，双向链表实现LRU</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://zhangyaoo.github.io/post/2019-nian-zong-jie/"" data-c="
          &lt;p&gt;小提示：阅读此篇文章大约需要三分钟时间，以下都是个人一些生活工作上碎碎念念，唠叨碎语，请斟酌阅读~&lt;/p&gt;
&lt;p&gt;目录&lt;br&gt;
开头&lt;br&gt;
学习&lt;br&gt;
工作&lt;br&gt;
运动&lt;br&gt;
生活&lt;br&gt;
游戏&lt;br&gt;
美食&lt;br&gt;
亲情&lt;br&gt;
爱情&lt;br&gt;
2020flag&lt;/p&gt;
&lt;p&gt;————————我是分割线——————&lt;/p&gt;
&lt;p&gt;开头&lt;br&gt;
又过了一年，记得上一次写年终总结还是在我狗窝(出租房)里面写的，这一次是在南京南站开始写的。&lt;br&gt;
深圳的天气就是这么神奇，一年到头穿短袖，曾和我朋友立下一个flag，说在深圳365天300天穿短袖，不然就洗一个月碗，似乎今年温度降的早，早早就穿上了短袖，(flag果然对于我来说就是打脸的)，所以明年来就给自己装逼行为付出代价（╯&#39; - &#39;)╯︵ ┻━┻&lt;br&gt;
这里一直都是夏天，不能像家乡一样能感受到四季的变化，感觉时间过的特别快，有一次在公司敲代码时候，听到了鸟鸣声，瞬间就想起了家乡田野中的鸟叫虫鸣，脑海里就浮现了那年夏天，吃着冰棍，听着蝉鸣的旧时光。&lt;br&gt;
这一年有许多值得写的东西，生活中的各个方面都有。用我老爹一句话，一年时间不管是进步多少，只要不是原地踏步走就可以。这次还是像2018年总结一样给自各做一些总结和一些（给自己打脸的）flag&lt;/p&gt;
&lt;p&gt;学习&lt;br&gt;
说起学习，这里放在最开始写，自认为学习是自己提升自己的最直接最有效的方式。从小学到高中以至于大学的知识，都是皮毛。重要是培养了快速学习能力和自学的习惯，这个可以说是自各学业生涯中获得最有价值的东西了。但是这是不够的，对于生活中认知和工作的方面，自我独立思考也是必不可少的。自各也在特意去注重，培养自各的独立思考的能力。&lt;br&gt;
在这感谢云智惠IPO所有后台同学，以及@陈秦圆 同学，让自己认识到独立思考和团队合作的重要性。&lt;/p&gt;
&lt;p&gt;这一年有学习到东西有：&lt;br&gt;
极客时间的数据结构和算法之美&lt;br&gt;
设计模式之美(只看了一章)&lt;br&gt;
牛客网的剑指offer(只刷了30道)&lt;br&gt;
力扣leetcode(只刷了60道)&lt;br&gt;
《netty实战》&lt;br&gt;
搭建开源项目fast-im脚手架&lt;br&gt;
金融业务知识&lt;br&gt;
沈剑的架构师之路（只看了二十篇）&lt;/p&gt;
&lt;p&gt;来年目标：&lt;br&gt;
继续完成开源项目&lt;br&gt;
经营好个人博客&lt;br&gt;
架构师之路学习&lt;br&gt;
《redis进阶》&lt;br&gt;
《剑指offer》&lt;br&gt;
大数据相关知识&lt;/p&gt;
&lt;p&gt;看了其他书籍：&lt;br&gt;
《亮剑》&lt;br&gt;
《寻路中国》&lt;/p&gt;
&lt;p&gt;画外音：一年时间学的这么少，还贴出来（脸皮有点厚😂，手动狗头）&lt;/p&gt;
&lt;p&gt;工作&lt;br&gt;
在云智惠的一年半时间里，自各学习了许多和工作相关的知识，认识了许多优秀的同学，成长了并且收获了许多，感谢云智惠提供的职场平台。虽然现在已经快要解散了，但是还是表示衷心感谢。江湖再见！&lt;/p&gt;
&lt;p&gt;运动&lt;br&gt;
唯一一个在2019年立得没有被打脸的flag，就是运动。每周一次篮球或者跑步。&lt;br&gt;
跑步呢，一般跑个4公里一次。大概跑了二十次，100公里左右，这里只记录了一半，另外一半没有记录（这句是真的）「哭笑:-D」&lt;/p&gt;
&lt;p&gt;篮球呢，现在投篮不准，运球辣眼睛，已然一副老年篮球的样子。但是还是阻挡不了我喜欢这一项运动，就像灌篮高手动漫中一句话“教练，我想打篮球”这样，源自于内心的热爱。&lt;/p&gt;
&lt;p&gt;生活&lt;br&gt;
这一年我想了很久，得到了什么失去了什么。。我想了很久，突然想起来，&lt;br&gt;
得到的当然是肚子的肥肉赘肉咯，，失去的你们也知道，肯定是我稀薄的头发。。&lt;/p&gt;
&lt;p&gt;当自各发际线越来越高的时候，就在思考人生，为什么长得这么帅，到要掉头发&lt;/p&gt;
&lt;p&gt;从此菊花茶➕枸杞已是标配，早睡早起已是人生箴言😂，狗命要紧&lt;/p&gt;
&lt;p&gt;游戏&lt;br&gt;
平常鸭梨大时候偶尔打打游戏放松放松，&lt;br&gt;
今年凭借自己的天赋(装一下B)和不懈努力，打到白金一。离自己的小目标又近了一步，争取今年上砖石，让我当个砖石守门员也行🤐。&lt;/p&gt;
&lt;p&gt;在这写上最喜欢英雄皇子的台词：“所到之处，无人能挡！”&lt;/p&gt;
&lt;p&gt;美食&lt;/p&gt;
&lt;p&gt;什么最重要，当然是吃。&lt;br&gt;
想想这一年做的美食，和同学一起做的，此处@肉和杨丽丽，感谢一起相处一年，学到了很多美食是如何做的，我身边的隐藏大厨😂。&lt;br&gt;
今年学到了有红烧鲫鱼，糖醋排骨，葱花饼，可乐鸡翅，红烧肉，自制凉菜，水煮肉片，自制烤鱼，回锅肉等等等等，就放一张和同学一起做饺子的图片，不多放了，免得晚上中毒太深。。。&lt;/p&gt;
&lt;p&gt;画外音：上面饺子（看起来像）真的不是我包的&lt;/p&gt;
&lt;p&gt;亲情&lt;br&gt;
特别喜欢《请回答1988》里面家庭亲情，整部片虽然不乏爱情友情等，但是我觉得核心是亲情，最有印象还是宝拉妈妈下雨天护着宝拉那段。&amp;quot;人真正变强大，不是因为守护着自尊心，而是抛开自尊心的时候，因为有需要守护的人&amp;quot;&lt;br&gt;
这句话还是需要自己去经历体会的。&lt;br&gt;
以前觉得，出省上学，出省工作，可以离家人远一点，就像是春天的燕子，长大了都想看看外面的世界，去闯荡去经历，去丰富自己的生活增长自己见识。可到了一定的年龄或者认知，会意识到，有家人在的地方，都觉得很知足。特别喜欢《四个春天》纪录片里面燕子归来之时，那种感觉，纪录片中父母看到燕子归来，心里念叨着，咱家小燕子也该回家了。&lt;/p&gt;
&lt;p&gt;爱情&lt;br&gt;
感谢党感谢国家给我发了一个女朋友，免费滴。&amp;lt;( ˘ ³˘)/💯&lt;br&gt;
今年最大收货，当然是遇到方小皮同学啦，（默默撒一下新鲜狗粮）希望在以后的日子里，你能够早睡早起，吃好喝好，身体棒棒。&lt;/p&gt;
&lt;p&gt;最后肯定是写一些打脸的东西。。&lt;br&gt;
2020年flag&lt;br&gt;
自信&lt;br&gt;
一周一次跑步或者篮球&lt;br&gt;
看完剩余书籍&lt;br&gt;
经营好个人博客&lt;br&gt;
洗脚城洗一次脚(有什么东西渗入进来了)&lt;br&gt;
体重不超130&lt;br&gt;
早睡早起，11点之前睡（虽然是不可能的）&lt;br&gt;
学习大数据相关知识&lt;br&gt;
保护眼睛&lt;/p&gt;
&lt;p&gt;以上，完&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://zhangyaoo.github.io/post-images/1593268924481.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
最后贴上自各最喜欢的照片，2015年于西藏拍&lt;/p&gt;
">2019年总结</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://zhangyaoo.github.io/post/about/"" data-c="
          &lt;blockquote&gt;
&lt;p&gt;欢迎来到我的小站呀，很高兴遇见你！🤝&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;关于本站&#34;&gt;🏠 关于本站&lt;/h2&gt;
&lt;p&gt;一些技术博客和一些闲言碎语&lt;/p&gt;
&lt;h2 id=&#34;博主是谁&#34;&gt;👨‍💻 博主是谁&lt;/h2&gt;
&lt;p&gt;还在打怪升级的菜鸟&lt;/p&gt;
&lt;h2 id=&#34;兴趣爱好&#34;&gt;⛹ 兴趣爱好&lt;/h2&gt;
&lt;p&gt;撸码、二次元、骑行、篮球、LOL&lt;/p&gt;
&lt;h2 id=&#34;联系我呀&#34;&gt;📬 联系我呀&lt;/h2&gt;
&lt;p&gt;手机（微信同）：15112342449&lt;/p&gt;
">关于</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://zhangyaoo.github.io/post/2018-nian-zong-jie/"" data-c="
          &lt;h2 id=&#34;写给自己的2018年总结&#34;&gt;写给自己的2018年总结&lt;/h2&gt;
&lt;h2 id=&#34;题记&#34;&gt;题记&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://img-blog.csdnimg.cn/20181231115831927.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3p5MTUxMTIzNDI0NDk=,size_16,color_FFFFFF,t_70&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
不觉中，2018年就快过了，在这之前从来没有写过一些总结性的文章，从小学初中日志作业，到高中的日复一夜的学习再到大学的浑浑噩噩的僵硬式的学习，一直都在进行流水账式的学习输入，从没有写过关于一年的计划甚至是一个月的小目标。&lt;/p&gt;
&lt;p&gt;至于为什么要做这个总结，我想是因为，年复一年的度过，有时候自己都不知道在这一年干过什么事情、收获了什么和失去了什么，包括对友情、亲情和事业等等。是因为我记性太差，还是说在这个娱乐信息爆炸的时代，我注意力都集中在快餐式的的认知上，很难有精力或者集中注意力去汲取自己想要的高质量的信息上，不得而知。所以今年我觉得有必要去总结自己的这一年。&lt;/p&gt;
&lt;p&gt;总结目录：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;关于技术&lt;/li&gt;
&lt;li&gt;关于认知&lt;/li&gt;
&lt;li&gt;关于为人处事&lt;/li&gt;
&lt;li&gt;关于友情爱情亲情&lt;/li&gt;
&lt;li&gt;2019展望&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;1-关于技术&#34;&gt;1、关于技术&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://img-blog.csdnimg.cn/20181231120336118.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3p5MTUxMTIzNDI0NDk=,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
1、技术积累&lt;br&gt;
师范专业毕业的我从大三开始接触计算机，大三那年学的网络工程，还考了个CCNA，目前发现没有什么用，对于现在的我来说。然后被住在上铺的兄弟67代入坑里学习code搬砖，从那开始便一发不可收拾，埋头苦学，连教师资格证都不考，跑出去公司里面当小弟实习。至此就开始技术积累之路了。&lt;/p&gt;
&lt;p&gt;当小弟那一段时间，就像刚萌发的种子一样疯狂吸收营养，学些了python爬虫、python web开发、Java公众号开发，SSM Java全家桶开发。这些都是在学校学不到的东西，当时感觉自己很牛逼，直到毕业找工作。&lt;/p&gt;
&lt;p&gt;毕业那一刻起，因为技术发展瓶颈，我又背上行囊横跨大半个中国从山东去南方一线城市漂。拿这自以为高大上的简历去投递，然后面试，惨遭面试官的啪啪打脸，连一个hashmap的底层原理都不知道，最有印象的是Java 循环删除list怎么删除，回答完后别面试官一脸嫌弃-。-&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;只会拿着现成的框架和应用去用，而不知道底层的实现方式和原理，那么工作性质就和网管差不多&lt;/strong&gt;。&lt;br&gt;
不会举一反三，如果又有新的框架出来又必须要学习一遍，如果说掌握了底层工作原理，那么用起来会舒服很多。&lt;/p&gt;
&lt;p&gt;2、技术分享&lt;br&gt;
&lt;img src=&#34;https://img-blog.csdnimg.cn/20181231124820725.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3p5MTUxMTIzNDI0NDk=,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
&lt;strong&gt;分享的乐趣，从一开始就停不下来。&lt;/strong&gt;&lt;br&gt;
公司会周期性的选一些当下热门的技术让我们去研究，然后去把自己研究的内容分享出来。我认为这是非常棒的一种学习方式。为什么这么说。因为这个是非常具体挑战性的，你理解了是一个层次，如果说要给别人将明白又是另外一个层次，这是两个不同层次的概念。如果说你的语言表达性不行，那么这个就是更加难上加难了。&lt;/p&gt;
&lt;p&gt;分享的乐趣不仅是这个，当你给别人讲完后，你还可以通过别人提供的问题和建议方案，和你自己的理解进行碰撞，然后产生新的认知元素，到下一次分享就可以融入上次分享的认知进来。&lt;/p&gt;
&lt;p&gt;到现在为止，我还在想，怎么在给别人讲解分享的时候能够更能让别人听懂，而且愿意去听。我最怕还是在分享的时候别人在玩手机。因为有了这个现象就表明你的分享做的不够好。&lt;/p&gt;
&lt;p&gt;3、书籍&lt;br&gt;
&lt;strong&gt;在这个手机万能的时代，能够静下心来看完一本书并理解是非常不容易的&lt;/strong&gt;。&lt;br&gt;
或许你们都说哪有时间看书，都忙工作任务了，甚至有时候我自己都不敢说一个月看完一本书，不管是文学还是专业技术性书籍。&lt;/p&gt;
&lt;p&gt;今年，我看了以下几本书，有的只看了一本书中的一部分，大部分都是涉及专业技术的：Netty权威指南、深入理解Java多线程、JavaEE互联网轻量级技术整合开发、Java高并发程序设计。还有其他的一些非技术书就不一一列举了。一年才看这几本书真是有点丢人-。-&lt;/p&gt;
&lt;p&gt;自认为网络技术博客和纸质书还是有各有各自的存在的意义的。就拿纸质书来说，它能够通过一系列的目录，能够从基本来源、基本原理、使用场景、底层原理技术、工作应用场景来一一进行有顺序的给人以真正理解和掌握。不需要自己从网上搜分散的知识点。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;不是看完书后就完了，还需要自己通过实践去证明你自己的理解是否正确&lt;/strong&gt;，这也是个不可欠缺的过程。&lt;/p&gt;
&lt;p&gt;为什么还需要读书呢，我认为网上一句话还是不错的，是《物演通论》作者王东岳说的：“因为通过电视或者其他方式搜集的信息，即那种通过直观方式接受的知识，是最浅显、最粗疏且没有经过精密逻辑证明的东西”。&lt;/p&gt;
&lt;p&gt;4、思考&lt;br&gt;
&lt;img src=&#34;https://img-blog.csdnimg.cn/20181231141547586.png&#34; alt=&#34;在这里插入图片描述&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
关于程序员技术深度和广度的选择，也是从网上看的一句话，Oracle技术大牛杨晓峰指出：“&lt;strong&gt;技术人免不了要构建广泛的知识体系，但终究还是要克制住诱惑，将某个领域做到精深&lt;/strong&gt;。水桶的水量取决于最短板，但是大多数情况下，我们在工作中的回报，更多的源自于自身的长处，甚至某种程度上还决定了我们是拥有自己选择的自由，还是疲于奔命，必经我们每个人的体力、经历有现实的上限的”。&lt;br&gt;
自认为还是很有道理的，先建立自己广度网，然后专门找一项自己喜欢的方向，然后放开手脚去研究。至少要有一个非常深的领域知识，所谓知识体系的搭建是基于多个扎实的知识点汇集而成，点不扎实不深入。&lt;/p&gt;
&lt;h2 id=&#34;2-关于认知&#34;&gt;2、关于认知&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://img-blog.csdnimg.cn/20181231154812245.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3p5MTUxMTIzNDI0NDk=,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
1、&lt;strong&gt;人与人最大的不同：认知不同&lt;/strong&gt;&lt;br&gt;
我认为的成长就是认知成长，是对一间事物的理解和处理方法。由于每个人的出生家境不同，生活环境不同，也就影响了每个人的认知，所以人才会有各自的想法，做事准则和处世方式。&lt;/p&gt;
&lt;p&gt;2、&lt;strong&gt;不断学习，使自己更值钱。&lt;/strong&gt;&lt;br&gt;
都说2018年是互联网寒冬，但是对我们技术人来说，难以构成影响，因为只要你有足够的技术底子，在哪都可以养活自己。用我们家乡话来说，”学好技术，走到天下都不怕“，这里我私自把物理化改成技术，哈哈。&lt;br&gt;
经常都能在网上看到一句话，”&lt;strong&gt;人生最重要的投资是自己。使自己更值钱才是立身之本。&lt;/strong&gt;“&lt;/p&gt;
&lt;p&gt;3、&lt;strong&gt;高质量的输入重要，输出比输入更重要&lt;/strong&gt;&lt;br&gt;
就拿看书写文章来说，当我们要写类似高考那种作文题目时候，如果这时读武侠小说，那么肯定是对于写作文是无益的，这就是低质量的输入，如果看一些文学方面的书的话，那么对于写作是非常有好处的。&lt;br&gt;
但是一味的输入，提升的意义不高，个人观点。比如我从小学到大，到现在都没写过文章的话，以前在高中学习的写文章的能力都没有了。所以如果不去输出，那么学习到的东西将在以后某个时刻都会忘记。&lt;/p&gt;
&lt;h2 id=&#34;3-关于为人处事&#34;&gt;3、关于为人处事&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://img-blog.csdnimg.cn/20181231150512794.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3p5MTUxMTIzNDI0NDk=,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
我这举两个例子：&lt;br&gt;
例1：上学那会，我爸送我去火车站，到了马路上准备叫出租车。这时对面马路上来了一辆空车，司机师傅看到我们招手，就准备到不远处掉头，然后这时候另外一辆出租车就刚好停在我们面前，我准备上眼前这辆车的时候，我爸就把我拉住叫我等之前那一辆车掉头坐那辆车，而且那辆车已经拐弯马上到我们这边来了。之后结果就是，我和我爸坐上了之前一辆车，而且和停在我们面前的后一辆车师傅说“不好意思我们已经叫了马路对面那一辆车了“。&lt;/p&gt;
&lt;p&gt;这件事到现在我还有记忆深刻，这里我想说的是，&lt;strong&gt;我们在方便自己的同时，也要换位思考考虑别人的感受&lt;/strong&gt;。&lt;br&gt;
或许对于你来说是一件小事情，直接图方便坐上离自己最近的车。那也无可厚非，换作以前的我也是，没有换位思考过。但是现在我觉得换位思考也是一个成年人应具备的素质。&lt;/p&gt;
&lt;p&gt;例2：上一次公司技术联调，我这边需要远程和另一个分公司同事联调，我这边完事后需要通知他那边，他那边才能继续完成工作，由于自己的原因，这边做完，没有及时通知到他们，导致他们那边延期。&lt;/p&gt;
&lt;p&gt;这件事我想说的是，&lt;strong&gt;我们在做事的时候，无论是工作还是生活，都不能去因为自己耽搁别人&lt;/strong&gt;，因为别人的时间也是时间，和我们自己是一样的。&lt;/p&gt;
&lt;h2 id=&#34;4-关于友情爱情亲情&#34;&gt;4、关于友情爱情亲情&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://img-blog.csdnimg.cn/20181231151002819.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3p5MTUxMTIzNDI0NDk=,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
关于友情：想对远方的朋友说 &lt;strong&gt;当你辉煌时候，我祝贺你，当你落魄的时候，我随时帮助你&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;关于爱情：到现在我还在想自己真正想去拥有的是什么。&lt;/p&gt;
&lt;p&gt;关于亲情：只有别人关心你飞的高不高，没有人会关心你飞的累不累，除了家人。&lt;/p&gt;
&lt;h2 id=&#34;5-2019年展望&#34;&gt;5、2019年展望&lt;/h2&gt;
&lt;p&gt;立个flag，毕竟是未来的事&lt;br&gt;
1、一周一次跑步+篮球&lt;br&gt;
2、两个月至少看完一本书&lt;br&gt;
3、保护好视力&lt;br&gt;
4、熟悉金融核心业务&lt;br&gt;
5、体重不超140&lt;/p&gt;
&lt;h2 id=&#34;总结一下&#34;&gt;总结一下&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://img-blog.csdnimg.cn/20181231162952878.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3p5MTUxMTIzNDI0NDk=,size_16,color_FFFFFF,t_70&#34; alt=&#34;在这里插入图片描述&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
人的成长是不断认识到以前的自己是一个傻X的过程，希望明年的我认为今年的我是一个傻X。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;2018-12-31 于张遥出租屋写&lt;/em&gt;&lt;/p&gt;
">2018年总结</a>
      </div>
      
    </div>
    <div class="page">
      <div id="page_ul"></div>
    </div>
  </div>
</div>
<script>
  !function () {
    let searchMask = document.querySelector('#search_mask');
    let result = document.querySelector('#result');
    let items = document.querySelectorAll('.item');
    let searchBox = document.querySelector('#search');
    let statCount = document.querySelector('#stat_count');
    let statTimes = document.querySelector('#stat_times');
    let pageUl = document.querySelector('#page_ul');
    let close = document.querySelector('#close');
    
    close.addEventListener('click', function() {
      searchMask.style = 'display: none;'
    })

    let finds = [];
    let contents = [];
    let pageSize = 10;
    items.forEach(item => {
      let a = item.querySelector('a');
      contents.push({
        title: a.innerText,
        details: a.dataset.c,
        link: a.href
      })
      item.remove();
    })

    function insertStr(soure, start, count) {
      let newStr = soure.substr(start, count);
      return soure.slice(0, start) + '<em>' + newStr + '</em>' + soure.slice(start + count);
    }

    pageUl.addEventListener('click', function(event) {
      let target = event.target;
      if (target.__proto__ === HTMLSpanElement.prototype) {
        appendResults(parseInt(target.dataset.i));
      }
    })

    function appendResults(index) {
      let htmlResult = '';
      let start = index || 0;
      let end = Math.min(start + pageSize, finds.length);
      for (let i = start; i < end; i++) {
        const current = finds[i];
        let html = current.title;
        let sum = 0;
        let positions = current.positions;
        positions.forEach(position => {
          html = insertStr(html, position.start + sum, position.count);
          sum += 9;
        })
        htmlResult += `<div class="item"><a class="result-title" href="${current.link}">${html}</a></div>`;
      }
      result.innerHTML = htmlResult;
      pageUl.innerHTML = '';
      let count = finds.length / pageSize;
      let lis = '';
      if (start !== 0) {
        lis += `<span class="fa fa-angle-left" data-i='${start - 1}'></span>`;
      }
      for (let i = 0; i < count; i++) {
        lis += `<span class='${i === start?'current':''}' data-i='${i}'>${i+1}</span>`;     
      }
      if (start+1 < count) {
        lis += `<span class="fa fa-angle-right" data-i='${start+1}'></span>`;  
      }
      pageUl.innerHTML = lis;
    }

    function search(delay) {
      let timer = null
      return function () {
        clearTimeout(timer)
        timer = setTimeout(() => {
          let start = Date.now();
          let segments = searchBox.value.split(' ').filter(c => c != '');
          if (segments.length <= 0) {
            return;
          }
          finds = [];
          let htmlResult = '';
          contents.forEach(content => {
            let title = content.title;
            let positions = [];
            let find = false;
            segments.forEach((segment) => {
              if (content.title.includes(segment)) {
                find = true;
                positions.push({
                  start: content.title.indexOf(segment),
                  count: segment.length
                })
              } else if (content.details.includes(segment)) {
                find = true;
              }
            });
            if (find) {
              finds.push({
                title: content.title,
                link: content.link,
                positions
              });
            }
          })
          appendResults(0);
          statCount.textContent = finds.length;
          statTimes.textContent = Date.now() - start;
        }, delay)
      }
    }
    searchBox.addEventListener('input', search(200));
  }()
</script>

<input hidden id="copy" />
<script>
  let language = '';
  if (language !== '') {
    let map = new Map();
    if (language === 'en') {
      map.set('search', 'Search');
      map.set('category', 'Categories');
      map.set('article', 'Articles');
      map.set('tag', 'Tags');
      map.set('top', 'Top');
      map.set('publish', 'published');
      map.set('minute', ' minutes');
      map.set('read-more', 'Read More');
      map.set('view', 'View');
      map.set('words', ' words');
      map.set('category-in', 'category in');
      map.set('preview', 'Meta');
      map.set('index', 'Toc');
      map.set('no-archives', "You haven't created yet");
      map.set('archives', " articles in total");
      map.set('cloud-tags', " tags in total");
      map.set('copyright', "Copyright: ");
      map.set('author', "Author: ");
      map.set('link', "Link: ");
      map.set('leave-message', "Leave a message");
      map.set('format', "Links Format");
      map.set('site-name', "Name: ");
      map.set('site-link', "Link: ");
      map.set('site-desc', "Desc: ");
      map.set('stat', " related results, taking ");
      map.set('stat-time', " ms");
      map.set('site-img', "Image: ");
    }

    if (map.size > 0) {
      let lanElems = document.querySelectorAll('.language');
      lanElems.forEach(elem => {
        let lan = elem.dataset.lan, text = map.get(lan);
        if (elem.__proto__ === HTMLInputElement.prototype) {
          elem.placeholder = text
        } else {
          if (elem.dataset.count) {
            text = elem.dataset.count + text;
          }
          elem.textContent = text;
        }
      })
    }
  }
  //拿来主义(真香)^_^，Clipboard 实现摘自掘金 https://juejin.im/post/5aefeb6e6fb9a07aa43c20af
  window.Clipboard = (function (window, document, navigator) {
    var textArea,
      copy;

    // 判断是不是ios端
    function isOS() {
      return navigator.userAgent.match(/ipad|iphone/i);
    }
    //创建文本元素
    function createTextArea(text) {
      textArea = document.createElement('textArea');
      textArea.value = text;
      textArea.style.width = 0;
      textArea.style.height = 0;
      textArea.clientHeight = 0;
      textArea.clientWidth = 0;
      document.body.appendChild(textArea);
    }
    //选择内容
    function selectText() {
      var range,
        selection;

      if (isOS()) {
        range = document.createRange();
        range.selectNodeContents(textArea);
        selection = window.getSelection();
        selection.removeAllRanges();
        selection.addRange(range);
        textArea.setSelectionRange(0, 999999);
      } else {
        textArea.select();
      }
    }

    //复制到剪贴板
    function copyToClipboard() {
      try {
        document.execCommand("Copy")
      } catch (err) {
        alert("复制错误！请手动复制！")
      }
      document.body.removeChild(textArea);
    }

    copy = function (text) {
      createTextArea(text);
      selectText();
      copyToClipboard();
    };

    return {
      copy: copy
    };
  })(window, document, navigator);

  function copyCode(e) {
    if (e.srcElement.tagName === 'SPAN' && e.srcElement.classList.contains('copy-code')) {
      let code = e.currentTarget.querySelector('code');
      var text = code.innerText;
      if (e.srcElement.textContent === '复制成功') {
        console.log('复制操作频率过高');
        return;
      }
      e.srcElement.textContent = '复制成功';
      (function (elem) {
        setTimeout(() => {
          if (elem.textContent === '复制成功') {
            elem.textContent = '复制代码'
          }
        }, 1000);
      })(e.srcElement)
      Clipboard.copy(text);
    }
  }

  let pres = document.querySelectorAll('pre');
  pres.forEach(pre => {
    let code = pre.querySelector('code');
    let copyElem = document.createElement('span');
    copyElem.classList.add('copy-code');
    copyElem.textContent = '复制代码';
    pre.appendChild(copyElem);
    pre.onclick = copyCode
  })

</script>
<script src="/media/js/motion.js"></script>

<script src="https://cdn.jsdelivr.net/gh/cferdinandi/smooth-scroll/dist/smooth-scroll.polyfills.min.js"></script>
<script>
  var scroll = new SmoothScroll('a[href*="#"]', {
    speed: 200
  });
</script>


<script src="/media/js/mouse/love.js"></script>


</html>